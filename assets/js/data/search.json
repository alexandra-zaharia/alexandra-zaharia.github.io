[ { "title": "Getting a functional layout in Linux for the 8BitDo Retro Mechanical Keyboard", "url": "/posts/getting-a-functional-layout-8bitdo-linux/", "categories": "Linux, keyboard", "tags": "linux, keyboard, bluetooth", "date": "2023-12-30 00:00:00 +0100", "snippet": "Confession time: I still hoard mech keyboardsIt’s been more than a year since I last posted here (things got… complicated). Incidentally, the last post was about getting the Azio Retro Compact Keyboard to work properly under Linux. Well, I still have this thing for mechanical keyboards, only now I have one extra keyboard, another one on the way and yet another one that I’m dead set on buying.This post is about the most recent addition to my collection: the 8BitDo Retro Mechanical Keyboard, N edition.It’s awesome! It has great looks if you’re into the retro gaming aesthetic, great build quality, PBT key caps, Kailh box white switches (so much better than blue switches!), volume knob, old-style power LED, magnetic USB dongle, extra controller pad (“dual pad”) with two big fat red buttons. Connectivity-wise, it can be used wired, with a 2.4 GHz USB dongle, or via bluetooth. Also, the price tag is insane (in a good way)!What I don’t like about it: The extra pad with the two big buttons has to be physically wired to the keyboard (it is using a 3.5 mm jack) The software :roll_eyes: Some macros don’t work properly when the keyboard is connected via bluetooth Unlike the Azio RCK and other keyboards, it can only be paired to a single device at a time in bluetooth modeThat being said, I still think it’s awesome and would totally buy it again :grin:The planThe 8BitDo Retro Mechanical Keyboard comes with two extra keys labeled “A” and “B”, in between the right-hand Alt and Ctrl keys. Neither them, nor the big buttons on the dual pad emit any keycodes out of the box (I used xev to check that).What I wanted to do was: Get the keyboard B button to be the Menu key (the context menu that you get on some keyboards). Get the keyboard A button to be Play/Pause (so that it can work with Spotify for example). Get the screen lock macro assigned to the big B on the dual pad (it’s Ctrl + Alt + L for me). Get my user password followed by a line feed assigned to the big A on the dual pad. Get the volume knob “fixed” because for some strange reason turning it to the right to increase the volume wouldn’t do anything.The softwareThe 8BitDo Ultimate Software V2 is Windows only. I couldn’t get it to run with wine or lutris, so I ultimately installed it in a VirtualBox Windows VM.Oddly enough, I couldn’t get it to run inside a Windows 10 VM with USB passthrough, even though it’s supposed to work with Windows 10. So I ended up installing Windows 11 in VirtualBox (with some registry edits during the install to bypass the hardware checks, otherwise it wouldn’t install for me).Key mappingsAfter a firmware update I could finally start mapping the keys under a new profile: For the Super Button 1 (keyboard “A”) I chose Shortcut then Play/Pause. This works great with either Youtube or Spotify even if it’s playing on another screen, which is great. For the Super Button 2 (keyboard “B”) I chose Shortcut then Mail (more on this later).For the dual pad, I spent some time realizing that if you only have a single dual pad, it is only recognized if plugged into the X port on the keyboard. You see, the keyboard accepts up to 4 dual pads through its A, B, X and Y ports, but if you only have one, then only port X specifically seems to work.For both dual pad buttons I assigned macros (one of them would lock my screen and the other one would unlock it by typing in my user password and hitting enter).Some Linux-specific adjustmentsRemapping a keyLet’s get back to that weird Mail mapping. Remember the extra buttons have no keycode assigned to them, or nothing that xev can see anyway. Moreover, I couldn’t just map the Menu key directly to one of the buttons, because the software didn’t offer this key as a mapping option :shrug: So I figured I’d just map to something I would never use, such as the Mail shortcut that you get on some “multimedia” keyboards. Such a seemingly useless button mapping turns out to be useful in the end because it can be changed later via xmodmap.I first looked at the keycodes I have by running:xmodmap -pke &amp;gt; ~/.xmodIn the generated ~/.xmod file, I found the keycode 163 for XF86Mail. To assign the Menu key to this otherwise useless keycode, I added this to my ~/.Xmodmap:keycode 163 = MenuAnd then I loaded it with:xmodmap ~/.XmodmapProblem solved: now I get the Menu key whenever I hit the red B button on the keyboard.Fixing the knob for volume upFor some strange reason, turning the volume knob to decrease the volume worked as expected, but turning the volume up wouldn’t do anything. What I settled on doing was to increase the volume through pactl when the volume knob is turned right, and have the whole thing handled by the Xfce keyboard shortcuts. The one I added was running this command for the XF86AudioRaiseVolume “key”:pactl set-sink-volume @DEFAULT_SINK@ +5%Random failuresFactory resetI thought I got permanently locked out of the software because it would yell at me in Chinese and not even allow me to check the existing profiles. I have no idea why that happened. I guess the software didn’t like my dual pad macros because it removed them without me asking it to do so, so I basically ended up with a useless dual pad and a non-working software.Fortunately, there is a factory reset, although it’s not documented anywhere. To reset to factory settings, just hold down all 3 round buttons together (pair, fast mapping and profile) for a few seconds. Then there’s some blinking going on as your profile is erased and the software should work again if it ever gets stuck like it did for me.Sucky bluetoothAnother pain point is the way the macros work (or rather don’t work) via bluetooth. The short one to lock my session (Ctrl + Alt + L) is alright, but the other one to type in my password is just broken because it repeats certain keystrokes. It works flawlessly wired and via the 2.4 GHz dongle though so I assume it has something to do with the delays between keystrokes not working well with bluetooth delays. And we all know that bluetooth just sucks, period. Sure, I could try to edit the delays between keystrokes with the software, but that’s what got me in trouble as described above, being locked out of the software. I’ll just call it a day and accept a slow macro for the time being :grin:ConclusionAll in all, the 8BitDo is a very nice keyboard with a decent extent of customisability, but the software kind of sucks. I’m glad I got it though! :nerd_face:" }, { "title": "Getting the Azio RCK to work under Linux", "url": "/posts/getting-the-azio-rck-to-work-under-linux/", "categories": "Linux, keyboard", "tags": "linux, keyboard, bluetooth", "date": "2022-04-26 01:00:00 +0200", "snippet": "Confession time: I hoard mech keyboardsSo I have this thing (call it a slight obsession) for mechanical keyboards. I’m fascinated by them. My daily driver until now was a 60% keyboard (a Filco Minila with MX Browns) but in the past I’ve used a few IBM Model Ms on a daily basis, especially my cherished “little” SSK. I also have a Unicomp with custom Tux keycaps and another Filco Minila with MX Blues, just in case the one with MX Browns breaks down :grin: I caught this virus back in 2014.Fast forward to 2022: new apartment, new job, new desk (WFH FTW!). Out of the blue, the best thrift opportunity that I could have hoped for comes up: somebody was selling their Azio Retro Compact Keyboard in its elwood edition! Meaning exactly what I’ve been longing to get my hands on for over a year.It’s a gorgeous-looking bluetooth keyboard with Kailh switches that emulate the feel of MX Blues. It can also work via USB and, for what it’s worth, it is also backlit if you care for that sort of thing. Without backlight, a single charge lasts for a long time. I’ve been using it daily for 2 weeks and I’m still at 60% battery. It has the ability to pair to up to three different devices via bluetooth. Which is perfect, because I can use it on my home computer, on my work laptop as well as on my Android phone.That ain’t workingExcept… well, certain manufacturers such as Azio (and also Keychron) seem to purposefully make beautiful keyboards just to spite Linux users.The first problem I encountered was that I couldn’t even detect the keyboard using the blueman applet :angry:The second problem, once I got the keyboard paired, trusted and connected, was that the numlock was enabled by default on Manjaro :roll_eyes:The third problem was that the function keys were spitting out gibberish :confounded:That’s the way you do itFortunately, solutions exist!Detect and connect the keyboardIf the blueman applet doesn’t see the Azio RCK, or any other bluetooth device for that matter, you will need to launch bluetoothctl (provided by the package bluez-utils on Arch Linux and Manjaro, or simply by the bluez package on Ubuntu):bluetoothctlAgent registered[bluetooth]#Now we instruct bluetoothctl that it should scan for devices as they become available:[bluetooth]# scan onAt this point, the keyboard should be in pairing mode. For the Azio RCK, first choose which device to pair among the possible three by pressing Fn + 1/2/3. Then enter pairing mode by pressing and holding Fn+Ins. As the device becomes available, bluetoothctl will signal this by showing the device address (it’s like a MAC address).Using the 12:34:56:78:90:AB placeholder, you can now pair with the device, trust it and connect to it:[bluetooth]# pair 12:34:56:78:90:AB[bluetooth]# trust 12:34:56:78:90:AB[bluetooth]# connect 12:34:56:78:90:ABNow you’re good to go.Turn off the numeric lockIn case only the right part of the keyboard seems to work but it only outputs numbers, it means the numlock is on. Turn it off by installing the numlockx package and by running:numlockx offEnable function keysEarlier in this post I mentioned Keychron because the solution comes from somebody having experienced the same problem with their keyboards on Debian.The solution is to write 2 in /sys/module/hid_apple/parameters/fnmode, as root:echo 2 | sudo tee /sys/module/hid_apple/parameters/fnmodeThis file describes how fn keys behave: more info here.If this solves the problem, the change can be made permanent by creating /etc/modprobe.d/hid_apple.conf with the following contents:options hid_apple fnmode=2Then runsudo update-initramfs -u -k allTL;DRYes, the Azio RCK works under Linux with a bit of tinkering :relieved:" }, { "title": "How to detect modified files across two directories", "url": "/posts/detect-changes-across-two-directories/", "categories": "Linux, command line", "tags": "linux, md5, bash", "date": "2022-03-29 01:00:00 +0200", "snippet": "Suppose you have two directories old and new containing the same files, but some of them have changed in the new directory. Further suppose that source control is not used :scream: This post explains how to detect the modified files based on their MD5 sums through a simple bash script.For this example, suppose the file types we are interested in are Python scripts (.py files). Note that we define the variables NEW_DIR and OLD_DIR (representing the paths to the new and the old directories, respectively) using absolute paths (i.e. paths that start from the root of the filesystem).#!/usr/bin/bashNEW_DIR=&quot;/path/to/new&quot;OLD_DIR=&quot;/path/to/old&quot;cd $NEW_DIRfiles=`find . -name &quot;*.py&quot;`for file in $files ; do filename=`echo $file | sed &#39;s/\\.\\///g&#39;` orig=&quot;${OLD_DIR}/${filename}&quot; md5_orig=`md5sum $orig | awk &#39;{ print $1 }&#39;` md5_new=`md5sum $file | awk &#39;{ print $1 }&#39;` if [[ &quot;${md5_orig}&quot; != &quot;${md5_new}&quot; ]] ; then echo $file $md5_orig $md5_new fidoneIn lines 6-7, we search for all the files ending in .py in the $NEW_DIR. For each matching file, we transform its filename into orig, i.e. the corresponding path and file name in the $OLD_DIR (lines 9-10). We then compute the MD5 sum of the two files (lines 11-12) and display only files where the MD5 sums differ (lines 13-15)." }, { "title": "VirtualBox USB and serial woes", "url": "/posts/virtualbox-usb-serial-woes/", "categories": "Linux, virtualization", "tags": "linux, manjaro, vm", "date": "2022-03-14 00:00:00 +0100", "snippet": "Enabling USB and serial devices in a VirtualBox VM is not straightforward. For reference, the host is a Manjaro Linux machine and the guest OS is a Ubuntu VM.Enable USB 2.0 and USB 3.0 controllersIn order for VirtualBox to propose USB 2.0 and 3.0 controllers for the VM, install the virtualbox-ext-oracle extension package.Configure serial ports on the VMIf the device that the guest VM needs to access is a serial device, go to the VM’s settings under Serial Ports &amp;gt; Enable Serial Port and choose Host Device as Port Mode with the proper path/address (e.g. /dev/ttyACM0).Add your user to the vboxusers groupIf your current user does not belong to the vboxusers group, VirtualBox will be unable to show the USB devices currently in use. Run the following command:sudo usermod -a -G vboxusers $USERLogout or restart.Add USB device filtersFrom the VM’s settings under USB, add a USB device filter for each USB (or serial) device that you want to render accessible to the guest VM. It should look something like this:DoneNow start the VM. The USB and/or serial devices added as USB device filters in the VM’s settings will now be accessible in the VM." }, { "title": "Fix disabled A2DP profile for bluetooth headset in Linux", "url": "/posts/fix-disabled-a2dp-profile-for-bluetooth-headset-in-linux/", "categories": "Linux, audio", "tags": "linux, audio, bluetooth", "date": "2022-03-10 00:00:00 +0100", "snippet": "AudioPulse has died on me. RIP PulseAudio. I can no longer select the A2DP profile for my bluetooth headset (Sony WH-1000XM4) under Manjaro Linux. I tried everything: switching between kernels (5.15 through 5.17), the ArchLinux wiki and demon worshipping among others, but nothing helped.“No A2DP profile” means that everything sounds as if coming out of a tin can (also known as HSP/HFP, i.e. headset/hands-free profile).Replace PulseAudio with PipeWireWhat ultimately worked for me was to replace PulseAudio with PipeWire. When installing the metapackage manjaro-pipewire, the installer will automatically flag PulseAudio packages as conflicting with the PipeWire equivalents. In other words, if everything works smoothly, the following command should replace PulseAudio with PipeWire:sudo pacman -S manjaro-pipewireIf some unresolved dependencies remain, remove them with pacman -R first.Finally, reboot:sudo rebootBluetooth headset profile cleanupIf everything works well, the bluetooth device corresponding to your headset should have a selectable A2DP profile:If this is not yet the case, there’s a final cleanup step that may be required: Unpair the headset Remove old settings: sudo rm -fr /var/lib/bluetooth Re-pair the headsetAutomatically switch to the bluetooth headsetIn a previous post, we’ve seen how to automatically switch to the bluetooth headset once it’s on. That was valid for PulseAudio. For PipeWire it’s a bit different. To achieve this, edit the file /usr/share/pipewire/pipewire-pulse.conf and, under content.exec, uncomment the following line:{ path = &quot;pactl&quot; args = &quot;load-module module-switch-on-connect&quot; }After this step, if restarting PipeWire is not sufficient, just reboot a last time and everything should be well. The bluetooth headset should be switched to when it is turned on." }, { "title": "Resize and compress a PDF in Linux", "url": "/posts/resize-and-compress-pdf/", "categories": "Linux, command line", "tags": "pdf, boox", "date": "2022-02-26 00:00:00 +0100", "snippet": "I recently got my Onyx Boox Note Air2 and I’m loving it! It’s an e-ink Android tablet that can be used as a classical e-reader, but it also allows taking notes with a stylus. Boox notebooks can be exported to PDF, and these PDFs can then be retrieved through BooxDrop on your PC.The only problem is that these PDFs are huge. A 15-page notepad I exported weighs 29 Mb. Here is my solution to this problem: First, I scale the PDF to 50% size. While this does not impact the file size significantly, it reduces the physical paper size to something more reasonable (the Boox Note Air2 is approximately A5 size). Then, I compress the PDF by specifying the DPI to be something that I still find readable while the file size is greatly reduced (by a factor 10 from my tests).First, install the required packages: cpdf and imagemagick.Scale PDF to 50%:cpdf -scale-page &quot;0.5 0.5&quot; in.pdf -o in_scaled.pdfCompress PDF (100 DPI, specified below as 100x100, works fine for me):convert -density 100x100 -compress jpeg in_scaled.pdf out.pdfWith the above, I managed to shrink my 15-page notebook from 29 Mb to only 2.8 Mb." }, { "title": "Concurrency crash course. Part 2&amp;#58; Threads and the Python GIL", "url": "/posts/concurrency-crash-course-part-2/", "categories": "Computer science, concurrency", "tags": "python, thread, process", "date": "2022-01-09 00:00:00 +0100", "snippet": "This is a multi-part post: Part 1 establishes terminology (tasks, threads and processes and how they relate to concurrency and parallelism) and gives an overview of challenges faced in concurrent programming. Part 2 (this article) shows what can go wrong when using threads without synchronization and explains the role and effects of the Global Interpreter Lock (GIL) in Python. Part 3 (TODO) explains some common thread synchronization primitives, accompanied by Python examples. Part 4 (TODO) explains some common process synchronization primitives (inter-process communication mechanisms), accompanied by Python examples. Part 5 (TODO) tackles parallel algorithm design and performance evaluation.ThreadsRemember from our last post that threads are the smallest set of instructions that can be managed by the scheduler. Unlike processes, multiple threads of a program share the same address space and are capable of accessing the same data.Each thread has its own program counter and registers. The program counter is a special register that tracks the instruction that is currently being executed (or the next instruction to be executed). When the scheduler switches between two threads running on a single CPU, a context switch takes place in which the state of the registers of the thread being switched from are stored and the registers of the thread being switched to are restored.Here’s an inspirational quote from OSTEP (Remzi H. Arpaci-Dusseau and Andrea C. Arpaci-Dusseau, chapter 26, Concurrency and threads) to get us started: Computers are hard enough to understand without concurrency. Unfortunately, with concurrency, it simply gets worse. Much worse.In Python, we can create and manage threads using the threading module. In the following example we create and start two threads that run the method my_task() (which essentially does nothing of interest beside sleep for a given amount of time):import threadingimport timedef my_task(x, y): print(&#39;{} got x={}, y={}&#39;.format(threading.current_thread().getName(), x, y)) time.sleep(x + y) print(&#39;{} finished after {:.2f} seconds&#39;.format( threading.current_thread().getName(), x + y))def main(): thr1 = threading.Thread(target=my_task, name=&#39;Thread 1&#39;, args=(1, 2,)) thr2 = threading.Thread(target=my_task, name=&#39;Thread 2&#39;, args=(.1, .2,)) thr1.start() thr2.start() thr1.join() thr2.join() print(&#39;Main thread finished&#39;)if __name__ == &#39;__main__&#39;: main()In main(), we create the threads, then actually start() them, and finally join() them. Joining a thread means to wait until it terminates. Unsurprisingly, here is the output of the above program:Thread 1 got x=1, y=2Thread 2 got x=0.1, y=0.2Thread 2 finished after 0.30 secondsThread 1 finished after 3.00 secondsMain thread finishedWhy do we need synchronization?But everything works fine. Why do we need synchronization? Glad you’ve asked! Concurrency can be tricky. Remember that we have discussed some common concurrency pitfalls in Part 1 of this series. It might have all seemed a bit abstract, so let us now look at an example where things don’t go according to plan. Suppose we have two threads and each one increments a global counter:import threadingcounter = 0def increment(n): global counter for _ in range(n): counter += 1def main(): thr1 = threading.Thread(target=increment, args=(500000,)) thr2 = threading.Thread(target=increment, args=(500000,)) thr1.start() thr2.start() thr1.join() thr2.join() print(f&#39;counter = {counter}&#39;)if __name__ == &#39;__main__&#39;: main()The result is not what we expect. Even worse, it is inconsistent from run to run:$ python 02_b_sum_without_synchronization.pycounter = 793916$ python 02_b_sum_without_synchronization.pycounter = 1000000$ python 02_b_sum_without_synchronization.pycounter = 697999$ python 02_b_sum_without_synchronization.pycounter = 872864Let us understand what just happened:Critical sectionA critical section refers to code that can result in a race condition when executed by multiple threads, because a a shared resource is involved.In our example, both threads attempt to modify the global counter variable by incrementing it. In other words, both threads access a shared resource in a critical section in write mode, without using thread synchronization.Race conditionA race condition occurs when several threads execute a critical section without synchronization mechanisms in place. Depending on the order in which the threads execute the critical section, the result of the program is different.In our example, both threads attempt to increment the global counter; as we’ve seen, not all increments are successful.Atomic operationsA series of actions is atomic if the actions are “all or nothing”, meaning they either all occur, or none occur. (You might be familiar with database transactions: by definition, they are atomic.)In our example, increments do not succeed because the increment operation itself is not atomic. Suppose the counter contains the value 3. In order to increment it, the first step is to read its current value (3) into a temporary location. The second step is to increment this temporary value (it now becomes 4). The final step is to copy the new value from the temporary location (4) into the counter. However, if a second thread accesses the counter concurrently, it can change its value while the “lagging” thread uses the stale value from the temporary location.This problem can be solved by rendering critical sections atomic through thread synchronization primitives such as locks or semaphores. What we mean by that is that we allow one thread to execute the critical section while the others are denied access to the critical section until the thread that is in control releases it. We will look into thread synchronization primitives in detail in the next post.Thread communicationApart from thread synchronization, concurrency can also involve thread communication. While thread synchronization and thread communication are related, in thread communication the focus is shifted to threads waiting on other threads to finish before executing. In the next part of this series we will see how condition variables help us achieve thread communication.The Global Interpreter Lock (GIL) in PythonNow that we’ve seen why thread synchronization is necessary, we cannot simply jump right in without first mentioning the dreaded Python GIL, short for the Global Interpreter Lock.Python interpretersBefore properly defining the GIL, we need to take a step back and talk about… Python. In the strictest sense, Python is “just” a programming language specification. Python interpreters are different implementations of the Python language specification. The most popular implementation is CPython (written in C), commonly called python by language abuse. Alternative Python implementations exist.The image below summarizes the relationship between language specification and implementation:CPython and the GILWhen we run a Python script using the python (i.e. CPython) interpreter, the source code is first compiled into byte code, a low-level platform-independent representation that is executed by the Python virtual machine. You have probably already seen the .pyc files in the __pycache__ directory – that is byte code. The Python virtual machine is not a separate component, but rather a loop running inside the Python interpreter. It simply executes the generated byte code line by line.The GIL is a mechanism that limits Python (remember we’re talking about the CPython interpreter) to execute only one thread at a time. Below you can see a GIL visualisation showing the main thread and 4 additional threads running on a single CPU; the green blocks represent the time when threads are executing:The reason behind the GILWhy would Python designers restrict the CPython interpreter to only be able to execute a single thread at a time? When CPython was being developed, its garbage collector was designed to use reference counting. This means that an object is released from memory when its reference count reaches zero.We can get the reference count of an object in memory using sys.getrefcount(). In the example below, notice that when we assign the object to a new variable, the reference count increases:In [46]: import sysIn [47]: z = &quot;this is a string variable&quot;In [48]: sys.getrefcount(z)Out[48]: 8In [49]: z2 = zIn [50]: sys.getrefcount(z)Out[50]: 9If several threads are running, race conditions may modify the reference count if it is not protected by a simple synchronization mechanism called “lock” (that we will be looking into in the next post). The solution was to impose a global lock providing exclusive access to the Python interpreter. This way, the Python interpreter executes byte code using the GIL, which in turn means that only one thread is active at any given time. The advantage is that reference counting becomes thread-safe. The drawback is that the remaining threads from the byte code must wait for the GIL to become available.You can also check out the article over at RealPython for more context.Effects of the GILThe dreaded effect of the Python GIL that we’ve hinted at earlier is that, no matter how many CPUs there are, since only a single thread can run at a time, the extra CPU cores remain unused. In other words, I/O-bound problems can be sped up through multithreading, albeit the threads run one at a time, in interleaved fashion. However, because the GIL prevents threads from running in parallel, no speed-up is possible unfortunately for CPU-bound problems (which, as we’ve seen in Part 1, require parallel execution).Do not despair though: multiple CPUs can be used in Python if we create processes instead of threads. Since every process comes with its own interpreter, the GIL issue is effectively side-stepped. We will be looking into processes in a later article in this series.ConclusionIn this post we’ve seen: How to launch separate threads in Python That launching threads without synchronizing them is rarely a good idea. We need to: control how threads access a critical section have threads wait on other threads to finish How the Python GIL (Global Interpreter Lock) complicates things further by only allowing a single thread to be active at a timeThe next post in this series will present thread synchronization primitives and show how they can be used in Python. In subsequent posts we will also be discussing processes, asynchronous programming, as well as parallel algorithm design and evaluation.Resources threading (Python documentation) Garbage collection (Wikipedia) Python GIL visualizations (David Beazley) Global Interpreter Lock (Python wiki) Global Interpreter Lock (Abhinav Ajitsaria @ RealPython, 2018) Operating systems: Three easy pieces (Arpaci-Dusseau &amp;amp; Arpaci-Dusseau) Python concurrency for senior engineering interviews (educative.io course)" }, { "title": "My 2022 dev resolutions", "url": "/posts/my-2022-dev-resolutions/", "categories": "Meta, career", "tags": "meta, personal development", "date": "2022-01-01 00:00:00 +0100", "snippet": "I’m working on improving my habits so I’ll be writing yearly resolutions… starting today! This is what I’d like to achieve in 2022, professionally-wise:Soft skillsI need to focus more on communicating in the corporate world (might need to look into emotional intelligence and diplomacy). I’ll also be continuing to network with like-minded people and to keep up-to-date with tech news.Personal brandIn 2021 I’ve managed to blog somewhat consistently, averaging one post every two weeks. This year I’d like to bring that average up to one post per week.Career2021 was markedly back-end focused and I plan to keep it that way. In addition, I would like to get a wider exposure to system design and architecture. If all else fails, this might require to actually communicate with the DevOps team. :scream: I’ll do my best.WorkI want to keep it back-end focused. And do some tech demos of those cool techs I’m tinkering with. This might even change a few ideas, who knows?Tech skillsI’m just a soul whose intentions are good, as the song goes: Dig deeper into back-end: Build REST APIs with flask Learn the Go programming language (and tech demo it!) Get a better understanding of system design and architecture Familiarize myself with cloud computing Project-wise, do the following for Gal4xy: Finish porting it from C to C++ Build multiplayer support using Protocol Buffers and gRPC Add a Qt GUI ConclusionWhew, that’s quite the list! :sweat_smile: I’ll come back to review my progress in one year’s time when I’ll be doing the 2022 wrap-up. I’m both a bit nervous and a bit excited as it’s the first time I’m doing this kind of exercise. Everything’s gonna be OK." }, { "title": "My 2021 dev retrospective", "url": "/posts/my-2021-dev-retrospective/", "categories": "Meta, career", "tags": "meta, personal development", "date": "2021-12-31 00:00:00 +0100", "snippet": "I’m working on improving my habits so I’ll be writing yearly retrospectives… starting today! This is what 2021 brought about, professionally-wise:Soft skillsI’m slowly navigating corporate world, organizationally-wise as well as human-wise. I strive to ask the right questions to the right people. I try to engage people on subjects of general interest (being up-to-date with business and technical decisions, learning opportunities etc). I try to engage management on subjects of personal interest (learning opportunities). Currently failing at it, but I’ll get better :grinning:I’ve also started networking a bit in order to keep in touch with ex-colleagues and acquaintances, as well as to keep up-to-date with tech trends that interest me.Personal brandI’ve managed to blog (somewhat) consistently throughout 2021, averaging one blog post every two weeks. There have been entire months where I haven’t published anything, and months where I published 9 posts.I finally created my LinkedIn profile and started getting in touch with people in my past and present professional networks.CareerI have a career plan, yay! It’s not that I didn’t have one before; it’s just that I realized I prefer back-end engineering to embedded engineering. More on the actual plan in the New Year’s Dev Resolutions post.WorkThroughout 2021, my work has gotten more back-end oriented, which is right on track with my career plan. I also got to design an awesome hardware testing framework for our products, written in Python and loosely modeled upon OpenHTF. It makes writing tests a breeze with an intuitive API, and it strives to minimize time spent by test operators at the test bench. I hope to get the management’s agreement to publish it under an open-source license sometime during 2022.Tech skillsSo much to learn!… So little time!… –&amp;gt; My motto and the story of my life. :joy:I didn’t have a proper learning plan for 2021 (which is something I intend to correct for 2022) but I managed to learn a thing or two during this past year: Early 2021 I played around with Unreal Engine 4. Just because it’s cool. I haven’t finished the course yet but I was able to make a playable level for a puzzle game where the player has to escape from a creepy dungeon. At work, Python kept me good company. I got the chance to intimately discover asyncio and flask. I’ve also had a lot of fun with selectors, which allowed me to implement some groovy finite state machines for a TCP-based protocol using raw sockets. During autumn 2021, I got up to speed with modern C++ (C++11, C++14 and C++17 standards). I started porting my C-based Gal4xy turn-based game to C++. During winter 2021, I familiarized myself with Protocol Buffers and gRPC. The plan is to use both in the Gal4xy C++ port in order to render it multiplayer. Throughout the year I’ve read bits and pieces on architecture and system design. Scalability, reliability, microservices, load balancing, that sort of stuff. I still lack context. It will be one of my main focus points for 2022.ConclusionIt’s been a good year. I grew a bit. I’ll strive to do better in 2022. I still don’t understand why I’ve waited so long to start writing yearly wrap-ups and to plan for the year ahead. Humans are weird, and I’m one of them. :smirk:" }, { "title": "Concurrency crash course. Part 1&amp;#58; Terminology, usage and pitfalls", "url": "/posts/concurrency-crash-course-part-1/", "categories": "Computer science, concurrency", "tags": "thread, process", "date": "2021-12-30 00:00:00 +0100", "snippet": "This is a multi-part post: Part 1 (this article) establishes terminology (tasks, threads and processes and how they relate to concurrency and parallelism) and gives an overview of challenges faced in concurrent programming. Part 2 shows what can go wrong when using threads without synchronization and explains the role and effects of the Global Interpreter Lock (GIL) in Python. Part 3 (TODO) explains some common thread synchronization primitives, accompanied by Python examples. Part 4 (TODO) explains some common process synchronization primitives (inter-process communication mechanisms), accompanied by Python examples. Part 5 (TODO) tackles parallel algorithm design and performance evaluation.I’m writing this for my frustrated past self, who couldn’t wrap her head around these concepts. Moreover, my future self will likely benefit as well (I’m inferring this by extrapolating my current self’s goldfish-grade memory). And last but not least, I’m also writing this post for anybody out there still struggling. :hugs:Tasks, processes and threadsFirst things first: let’s establish some terminology.Not everybody agrees on the definition of a task, but this term is so ubiquitously used that it is worth mentioning. A task refers to a set of instructions that are executed. For the purpose of this post, tasks can be seen as roughly equivalent to functions of a computer program.A thread is the smallest set of instructions that can be managed by a scheduler. At the operating system (OS) level, a scheduler assigns resources (e.g. CPUs) to perform tasks.A process is an instance of a running program. A process has at least one thread. However, programs can spawn multiple processes (e.g. a webserver may have a master process and several worker processes). To complicate things further, it is also possible to launch multiple instances of the same program (e.g. your favorite text editor).I will attempt to give a more intuitive understanding of these terms in the following figure:In this example, we have a program that launches three processes. Processes 1, 2 and 3 have 2, 1, and 3 threads, respectively. Each thread runs a given task A through F.There is an important distinction to consider: the threads of a given process all share that process’s address space, but come with their own stacks and registers. In other words: A thread has its own stack and registers A thread has access to the code, data and resources of its owner processTherefore, in terms of resource sharing: Threads (of a given process) share the same resources. Care must be taken as to how threads access those resources. Thread synchronization primitives such as condition variables, semaphores, mutexes or barriers allow to control the way in which threads access shared resources and will be discussed in a future post. Processes do not share the same resources, by default. Process synchronization, also known as Inter-Process Communication (IPC), must be used if resource sharing is necessary. Some of the most common mechanisms for achieving IPC are signals, sockets, message queues, pipes and shared memory. IPC will be discussed in a future post.It is worthwhile to note that thread creation is lightweight in comparison to spawning a new process. This is an added benefit to the fact that threads have access to shared resources in the address space of their owner process.How are tasks executed with respect to one another? How are processes executed with respect to the CPUs? Here’s where the next part comes in, where we discuss concurrency vs parallelism.Concurrency and parallelismHere’s what Rob Pike (best known as being one of the three creators of the Go programming language) has to say (slides, talk): Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once. Not the same, but related.He also goes on to say: Concurrency is about structure, parallelism is about execution. Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable.(emphasis mine)In operating system terms, the “things” Rob Pike refers to are tasks. Concurrency simply means that the operating system will schedule the tasks to run in an interleaved fashion, thus creating the illusion of them being executed at the same time:Whereas parallelism means that tasks are run on actually distinct CPUs:Make sure to also check out Jakob Jenkov’s post on concurrency vs parallelism to get a broader picture (and to see how he defines parallelism in a stricter sense than what I have conveyed here).What is concurrency used for?Concurrency is useful for two types of problems: I/O-bound and CPU-bound.I/O-bound problems are affected by long input/output wait times. The resources involved may be files on a hard drive, peripheral devices, network requests, you name it. In the above diagram, red blocks show how much time is spent for I/O operations. When downloading files from the internet, for instance, an important speedup can be attained if we download concurrently instead of sequentially. The speedup comes from overlapping the I/O-bound wait times (the red blocks in the diagram). Therefore, concurrency (launching more threads) can improve I/O-bound problems.For CPU-bound problems, on the other hand, the limiting factor is the CPU speed. These are generally computational problems. If such programs can be decomposed into independent tasks (with the typical example being matrix multiplication), then an important speedup can be attained if we throw more CPUs at the problem. Therefore, parallelism (launching more processes) can improve CPU-bound problems.Challenges in concurrent programmingWriting a concurrent program is more difficult than writing its sequential version. There are many things to consider and account for. Often times, isolation testing is a nightmare. Here we will discuss some of the most common challenges.Race conditionA race condition leads to inconsistent results that stem from the order in which threads or processes act on some shared state. via Imgflip GIF MakerFor example, suppose the shared state is the string &quot;wolf&quot;. We have two threads, each prefixing the shared state with a different word: thread A prefixes the shared string with &quot;bad&quot; and thread B prefixes it with &quot;big&quot;. If A runs before B, the shared state becomes wolf =&amp;gt; bad wolf =&amp;gt; big bad wolf If B runs before A, the shared state becomes wolf =&amp;gt; big wolf =&amp;gt; bad big wolfWe can try to isolate race conditions using sleep() statements that will hopefully modify timing and execution order.Race conditions occur because access to the shared state happens outside of synchronization mechanisms. A possible mitigation strategy is to use barriers (see the next post in the series on Thread synchronization primitives).DeadlockA deadlock occurs when several tasks are blocked indefinitely while holding a shared resource and while waiting for another one.Deadlocks occur when the Coffman conditions below are satisfied simultaneously: Mutual exclusion: at least two shared resources are held without sharing them with other tasks. Hold and wait: a task that holds a resource is requesting another resource which is held by another task. No preempt: the task is responsible to release the resource voluntarily. Circular wait: each task is waiting for a resource that is held by another task, for all tasks involved up to the last one which is, in turn, waiting for a resource held by the first task.LivelockA livelock is similar to a deadlock: it involves tasks that need at least two resources each, however none of them is blocked. Unlike a deadlock, tasks in a livelock are overly polite: they acquire a resource, they test whether another resource is available, they release the first resource if the second one is not available, wait for a given amount of time, then repeat the whole process all over again. If bad timing is involved, none of the tasks involved in a livelock can ever progress. The irony is that livelocks often occur while attempting to correct for deadlocks…StarvationResource starvation occurs when a task never acquires a resource it needs. It can usually be resolved by improving the scheduling algorithm such that tasks that has been waiting for a long time get assigned a higher priority.Priority inversionPriority inversion occurs when a task with low priority holds a resource required by a task with high priority. This results in the low-priority task finishing before the high-priority task. It can also get more subtle than this, involving a task with medium priority that preempts the low priority task, thus indirectly blocking the high-priority task indefinitely. Several protocols can be used to avoid priority inversion, one of them being priority inheritance. This is how the Mars Pathfinder priority inversion bug from 1997 was fixed.ConclusionThis post takes a bird’s eye view of concurrency by: Establishing some necessary terminology (task, thread, process, concurrency, parallelism) Taking a look at two classes of problems (I/O-bound and CPU-bound) and how they relate to concurrency Explaining some common pitfalls in concurrent programming (race conditions, deadlock, livelocks, starvation and priority inversion)The next posts in this series will illustrate synchronization primitives (for threads and processes), list principles to keep in mind when designing concurrent programs, and show how to evaluate parallel implementations.Resources Concurrency vs parallelism (Jakob Jenkov) Concurrency is not parallelism (Rob Pike, 2012) [slides] Concurrency is not parallelism (Rob Pike, 2012) [talk] Inter-process communication (Wikipedia) Priority inversion" }, { "title": "Bitwise nuggets&amp;#58; flip bit to win", "url": "/posts/bitwise-nuggets-flip-bit-to-win/", "categories": "C/C++, bitwise", "tags": "c/c++, algorithms, binary", "date": "2021-12-26 00:00:00 +0100", "snippet": "Given an integer, suppose we can flip exactly one of its bits from 0 to 1. We need to determine the longest sequence of 1s that can be obtained.Let us first see some examples: For number 183 (10110111), the answer is 6. Explanation: there are two 0 bits; going from MSB to LSB: If we flip the first 0 bit to 1, we get a sequence of 1s of length 4. If we flip the second 0 bit to 1, we get a sequence of 1s of length 6. For number 182 (10110110), the answer is 5. Explanation: there are three 0 bits; going from MSB to LSB: If we flip the first 0 bit to 1, we get a sequence of 1s of length 4. If we flip the second 0 bit to 1, we get a sequence of 1s of length 5. If we flip the third 0 bit to 1, we get a sequence of 1s of length 3. How do we solve this problem? The idea is to first count the runs of 0s and 1s in the input number. Since the number is an integer, we assume that its MSB bits up to the 32nd one are all 0s. We then traverse these sequences and decide which is the longest one that we can obtain if we only flip one bit from 0 to 1.For example, for number 183, we start from the LSB and we count: a sequence of 1s of length 3; a sequence of 0s of length 1; a sequence of 1s of length 2; a sequence of 0s of length 1; a sequence of 1s of length 1; a sequence of 0s of length 24.Examining this sequence, we decide that since we have a sequence of 1s of length 3 and a sequence of 1s of length 2 separated by a single 0 bit, the longest sequence of 1s that we can obtain by flipping a single bit is 3 + 1 + 2 = 6.Here is how we can implement this is C:// Returns the longest sequence of 1s that can be obtained from `number`// by flipping one of its bits from 0 to 1.int flip_bit_to_win(int number){ int seq_lengths[32][2]; // will store lengths of sequences of 0s and 1s int seq_counter = 0; // number of sequences in `seq_lengths` + 1 int current_value = number &amp;amp; 1; // current bit value (0 or 1) for (size_t i = 0; i &amp;lt; 32; i++) // all sequence lengths are initially 0 seq_lengths[i][0] = seq_lengths[i][1] = 0; seq_lengths[0][0] = current_value; for (size_t i = 0; i &amp;lt; 32; i++) { if ((number &amp;amp; 1) == current_value) { // still in the same sequence as before seq_lengths[seq_counter][1]++; } else { // reading a different sequence now seq_lengths[++seq_counter][1] = 1; current_value = number &amp;amp; 1; seq_lengths[seq_counter][0] = current_value; } number &amp;gt;&amp;gt;= 1; // move on to the next bit } ++seq_counter; // add the MSBs that are 0 // Determine the longest sequence of 1s that can be obtained by flipping 1 bit int max_len = 0; for (int i = 0; i &amp;lt; seq_counter; ++i) { int curr_max = seq_lengths[i][0] == 0 ? 1 : seq_lengths[i][1]; if (i &amp;lt; seq_counter - 1) curr_max += seq_lengths[i][0] == 1 ? 1 : seq_lengths[i+1][1]; if (seq_lengths[i][0] == 1 &amp;amp;&amp;amp; seq_lengths[i+1][1] == 1 &amp;amp;&amp;amp; i &amp;lt; seq_counter - 2) curr_max += seq_lengths[i+2][1]; if (max_len &amp;lt; curr_max) max_len = curr_max; } return max_len;}Here are the variables that we use: At line 5, we declare seq_lengths, a 2D array where values in the first column are either 0 or 1 (the type of sequence), and values in the second column are the counts of 0s or 1s. At line 6, seq_counter represents the number of sequences in seq_lengths. At line 7, current_value represents the type of the current sequence: 0 or 1, depending on the value of the LSB in the input number.At lines 9-11 we initialize the seq_lengths array. We must remember to set the type of the first sequence (line 11) to the current value of the LSB.We traverse the input number once from its LSB to its MSB and fill in the seq_lengths array (lines 13-22). At each step, we determine the least significant bit (either 0 or 1) and we compare it to the current value. If it is the same as before (lines 14-15), we increment the count of that particular sequence. If it is a different value than before, it means we’re done reading the previous sequence so we update the seq_counter and the curr_value (lines 16-20). We “traverse” the input number bit by bit by right-shifting it at each step (line 21).In order to properly account for the MSBs that are 0, we need to increment seq_counter once we’re done traversing the input number (line 24).We now have the runs of 0s and 1s properly stored in the seq_lengths array. At lines 27-39, we determine the longest sequence of 1s that can be obtained by flipping one bit from 0 to 1. We traverse seq_lengths and we determine the current maximum length at each step: Line 30: the current maximum is 1 if we’re in a sequence of 0s, or the count of 1s if we’re in a sequence of 1s. Lines 31-32: if we’re not handling the last sequence, then we add 1 to the current maximum if we’re in a sequence of 1s (since we know at least a 0 follows) or the number of 1s in the next sequence if we’re in a sequence of 0s (since we know the next sequence has only 1s). Lines 33-34: if we’re in a sequence of ones followed by a single 0 bit and there are at least 2 more sequences, then the we add the number of 1s in the next sequence of 1s to the current maximum. Lines 35-36: we update the maximum sequence length according to the value of the current maximum.Here are some test cases:flip_bit_to_win( 183) =&amp;gt; 6flip_bit_to_win( 182) =&amp;gt; 5flip_bit_to_win( 615) =&amp;gt; 4flip_bit_to_win( 9967) =&amp;gt; 8flip_bit_to_win(52975) =&amp;gt; 8flip_bit_to_win( 0) =&amp;gt; 1flip_bit_to_win( 1) =&amp;gt; 2flip_bit_to_win( 2) =&amp;gt; 2flip_bit_to_win( 30) =&amp;gt; 5flip_bit_to_win( 31) =&amp;gt; 6flip_bit_to_win( -1) =&amp;gt; 32flip_bit_to_win( -2) =&amp;gt; 32Want to see more bitwise logic? There’s a whole repository on my GitHub on bit fiddling." }, { "title": "Set up an automatic SSH login on Linux", "url": "/posts/set-up-automatic-ssh-login-on-linux/", "categories": "Linux, security", "tags": "linux, ssh", "date": "2021-12-10 00:00:00 +0100", "snippet": "Suppose you want to connect to/from a remote Linux machine (that might as well be a virtual machine) via SSH, but without having to type in the password each time.In the following, I will be referring to: the main machine: the machine from which you want to SSH to the remote machine without typing in the password; the remote machine: the machine you are SSH-ing into from the main machine.Create a pair of SSH keysIn order to log in via SSH without typing in the password, the remote machine only needs to know the main machine via its public SSH key.From the main machine, generate a SSH key pair to use for logging in to the remote machine:ssh-keygen -t rsaSave the key pair as ~/.ssh/id_rsa and ~/.ssh/id_rsa.pub.Do NOT provide a passphrase if the intention is to use this automatic login for automated tasks (e.g. for scripts where SSH is used indirectly, such as when copying files or pushing to a git repository).Make the remote know the main machineThis is done by copying the public key of the main machine to the remote machine.If the ~/.ssh directory does not exist on remote, create it first. Then append the public key that was generated during the previous step to the list of known hosts for remote. From main:cat ~/.ssh/id_rsa.pub | ssh user@remote &#39;cat &amp;gt;&amp;gt; ~/.ssh/authorized_keys&#39;Test the automatic loginNow, from main, you should be able to SSH to the remote machine without having to type in the password:ssh user@remoteCaveatCreating a SSH key pair without a passphrase means the private key remains unencrypted. If somebody has access to the main machine or manages to exploit a vulnerability and gains access to it, the private SSH key is just out there in plain sight." }, { "title": "Use cases for Python environment variables", "url": "/posts/use-cases-for-python-environment-variables/", "categories": "Python, configuration", "tags": "python, environment, software design", "date": "2021-11-25 00:00:00 +0100", "snippet": "Today’s post focuses on environment variables in Python. They are one of several possible mechanisms for setting various configuration parameters. We can: read environment variables (through os.environ or dotenv) [the current post] have the script accept command-line arguments (use argparse) load configuration settings from a file, such as: a JSON file (use json) a YAML file (use pyyaml) a XML file (use lxml, ElementTree or minidom) an INI file (use configparser) [check out this post] your DIY file format (for which you will be rolling your own parser) What is the best solution?The answer is… it depends.There is no one-size-fits-all solution. It depends on what you’re trying to achieve and on how the current software architecture looks like. If you’re working on a command-line tool that must accommodate a plethora of options, chances are you’ll be using argparse. For other types of projects (such as a server or a client), a configuration file might be more practical. Yet in other situations you may also want to consider using environment variables.We will be looking in more detail at three such use cases in this post, where we will see how environment variables can be a good choice.But first, let’s get the next point out of the way:But environment variables are evil, right?Well… it depends.Indeed, using environment variables for non-sensitive information that you could just as well transmit via command-line arguments or via a configuration file is not ideal. Why? Because being environment variables, they actually live outside of the code base. Sure, you can access them based on their key (their name) and attach some meaning to them, but this is neither the most Pythonic, nor the most effective way, to do things (if this can be avoided).Nevertheless, there are also legit cases where environment variables are preferable: when setting execution mode (e.g. debug or development mode vs production mode) when they improve security practices when they are the only way to get some values into a “black box” (more on that later)Before diving into the use cases, let us first briefly see how to access environment variables in Python.Accessing environment variables in PythonEnvironment variables are read through os.environ. Although they can also be modified or cleared, such changes are only effective in the current Python session (and for subprocesses started with os.system(), popen(), fork() and execv()). In other words, if you change an environment variable in a Python script, the change will not be reflected in the environment once that script exits.os.environIn the most simple form, you can export an environment variable through the shell:export foo=&#39;bar&#39;Then you can read its value through os.environ:In [1]: import osIn [2]: os.environ.get(&#39;foo&#39;)Out[2]: &#39;bar&#39;Note that, for non-existent keys, os.environ.get() returns None.Also note that the values of all environment variables are strings. To address this, you may want to roll your own small environment parser. Mine looks like this:import osdef parse_string(value): if value.lower() == &#39;true&#39;: return True if value.lower() == &#39;false&#39;: return False try: value = int(value) return value except ValueError: try: value = float(value) finally: return valuedef get_env_setting(setting): if setting not in os.environ: return None return parse_string(os.environ[setting])I use get_env_setting() to retrieve a value from os.environ (if the key exists) and I try to convert it to different data types: first, as a bool (this is because if I set boolean environment variables in Python, I store their str() representation, meaning &#39;True&#39; for True and &#39;False&#39; for False); if this fails, the value is converted to an int; if this fails as well, the value is converted to a float: if successful, parse_string() returns a float; if not, it returns a str. dotenvTo set multiple environment variables, you could create a bash script and ensure you run it before starting the Python script that needs these environment variables. But there is something more effective than this: dotenv allows you to load environment variables from a .env file having the following format:# Development settingsDOMAIN=example.orgADMIN_EMAIL=admin@${DOMAIN}ROOT_URL=${DOMAIN}/appNotice the .env file understands UNIX expansion (e.g. ${DOMAIN}).dotenv loads the environment variables from .env into the environment:from dotenv import load_dotenvload_dotenv()Now the environment variables DOMAIN, ADMIN_EMAIL and ROOT_URL are accessible to the Python script and may be retrieved via os.environ.get() as shown above.Use case: setting execution modeHere is a classic use case for environment variables. Suppose you don’t want to add an explicit -d / --debug flag for your app. Then you could just export an environment variable to do the trick:export MY_APP_DEBUG=1The app would behave differently depending on the value of MY_APP_DEBUG.Taking this idea one step further, you could use an environment variable MY_APP_MODE to choose between development, staging and production modes.Use case: securing access tokensMany applications require access tokens: they can be API tokens, database passwords and so on. Storing such sensitive information inside the code base is just an accident waiting to happen, no matter how sure you are that you’re never going to commit that special extra line to version control.Here’s where environment variables come in handy. You could add your secret tokens to the .env file and load it with dotenv as we’ve seen above. Of course, you’d need to make sure that your .gitignore or .hgignore contains the .env file.In short, instead of:# NOTE TO SELF: DO ***NOT*** COMMIT THIS TO VERSION CONTROL!SECRET_TOKEN = &#39;56a682c4d000c676f543124b332a2921&#39;# ...do_stuff_with(SECRET_TOKEN)prefer adding your SECRET_TOKEN to .env, adding .env to your version control’s ignore file, and finally:dotenv.load_dotenv()# ...SECRET_TOKEN = os.environ.get(&#39;SECRET_TOKEN&#39;)do_stuff_with(SECRET_TOKEN)Use case: injecting configuration into a black boxThis final use case is something you’re not going to come across very often in internet discussions. It’s something I call a “black box”, meaning code that you have no control over: you didn’t write it, you cannot change it but you have to run it. Along these lines, remember how I wrote in a previous post about creating a Python script that runs user code from other Python scripts. That’s the kind of use case I am referring to.OK, you may ask, but why??? Why would you want to run code that you have no control over? Well, suppose you’re writing a testing framework that other people may use to write tests for… well, testing stuff. The tests are not relevant, only the part about having to run them is. There are two aspects at play here: the framework is a library that users import from in order to write their tests; the framework is also a framework, meaning a master runner script that runs the user scripts.For the users’ sake, their only task should be to read and understand the framework’s well-documented API. They should not have to fiddle around with passing configuration options into their code. The configuration options for running their scripts through the framework may be sent through the command line and/or through configuration files.What a user script typically does is to import abstractions from the framework and to use them for creating and executing tests. For example:# user_script.pyfrom fancy_framework import Test, PhaseResultdef a_test_phase(api): do_stuff() # assume this existsdef another_test_phase(api): if not check_stuff(): # assume this exists return PhaseResult.FAILmy_test = Test(a_test_phase, another_test_phase, name=&#39;My Test&#39;)my_test.execute()Let us suppose that if the user script is ran with verbosity off (default), it only shows the test result:$ fancy_framework user_script.py====================== Running test My Test (attempt #1) =======================Finished running test My Test ......................................... [ FAIL ]________________________________________________________________________________$When the script is ran with the --verbose flag, it displays phase results as well:$ fancy_framework --verbose user_script.py====================== Running test My Test (attempt #1) =======================Phase a_test_phase .................................................... [ PASS ]Phase another_test_phase .............................................. [ FAIL ]Finished running test My Test ......................................... [ FAIL ]________________________________________________________________________________$Now remember that what the fancy_framework does among other things is to simply run the provided user_script.py. How should a fancy_framework.Test object know whether verbosity is on when its execute() method is called? Here is where environment variables step in to save the day: The fancy_framework exports an environment variable FANCY_FRAMEWORK_VERBOSITY according to the user’s choice (whether the --verbose flag was used). When a Test object is initialized, it reads the value of FANCY_FRAMEWORK_VERBOSITY from os.environ and stores it in an instance variable self._verbose. When the execute() method of the Test instance is called, details are printed to stdout only if self._verbose is true.Here is a simplified version (using the get_env_setting() helper we’ve seen above):class Test: def __init__(self, *phases, name=None): self._phases = create_phases(phases) # assume this exists self._name = name self._verbose = get_env_settings(&#39;FANCY_FRAMEWORK_VERBOSITY&#39;) def execute(self): print_running_test(self) # assume this exists for phase in self._phases: phase.run() if self._verbose: print_phase_outcome(phase) # assume this exists print_test_outcome(self) # assume this existsIsn’t that neat? In this use case we’ve seen how environment variables can be used to inject configuration into a black-box system.Check out this article for a discussion of passing configuration options in Python in such a way as to only use identifiers instead of strings for the configuration keys." }, { "title": "The overloaded insertion operator in C++ exceptions", "url": "/posts/overloaded-insertion-operator-in-cpp-exceptions/", "categories": "C/C++, operators", "tags": "c/c++, exception, stringstream", "date": "2021-11-14 00:00:00 +0100", "snippet": "The &amp;lt;&amp;lt; operator, when applied to streams, is called the insertion operator. (Likewise, the extraction operator is &amp;gt;&amp;gt;). If we overload it for a class (as non-member), we can output instances of that class. That’s very handy.Note that in order for the overloaded operator&amp;lt;&amp;lt;() method to have access to private members of the class, we need to declare it as friend.Take the very basic example of 2D coordinates:#include &amp;lt;iostream&amp;gt;class Coords { uint16_t _x; uint16_t _y;public: Coords(uint16_t x, uint16_t y): _x(x), _y(y) { } friend std::ostream&amp;amp; operator&amp;lt;&amp;lt;(std::ostream&amp;amp; out, const Coords&amp;amp; coords) { out &amp;lt;&amp;lt; &quot;(&quot; &amp;lt;&amp;lt; coords._x &amp;lt;&amp;lt; &quot;, &quot; &amp;lt;&amp;lt; coords._y &amp;lt;&amp;lt; &quot;)&quot;; return out; }};int main(){ Coords c(0, 1); std::cout &amp;lt;&amp;lt; c &amp;lt;&amp;lt; std::endl;}This produces, as expected:(0, 1)The problem with operator&amp;lt;&amp;lt;() (through my Python-tinted glasses, of course) is that it cannot unfortunately be used directly to create a custom exception description :confused:We must use a stringstream instead:#include &amp;lt;exception&amp;gt;#include &amp;lt;sstream&amp;gt;class Coords { // ... void move_left() { if (_x == 0) { std::stringstream ss; ss &amp;lt;&amp;lt; &quot;Coords: cannot move left from &quot; &amp;lt;&amp;lt; *this; throw std::invalid_argument(ss.str()); } }};This produces:Coords: cannot move left from (0, 1)" }, { "title": "Merge Mercurial branch into default", "url": "/posts/merge-mercurial-branch-into-default/", "categories": "Tools, Mercurial", "tags": "mercurial, version control", "date": "2021-11-10 00:00:00 +0100", "snippet": "In a previous post I wrote a quick recipe for doing a merge in Mercurial when pulling from the remote repository.This post is another quick Mercurial merge recipe, but this time for merging a development branch (let’s call it dev) into the default branch.First things firstSave yourself some heart ache by ensuring there’s nothing left to commit to the default branch before creating the new dev branch. And absolutely do a hg pull from the remote repository beforehand! Personal experience… :fearful:Branch awaySo you finally created the branch:hg branch devAnd happily started deving. Some 9,000 hours later, the new branch is squeaky clean and you want to merge it into default. Same as before, make sure there’s nothing left to commit in dev. Check this with hg status.The actual mergeSwitch back to the default branch:hg up defaultDo the merge and commit:hg merge devhg ci -m &quot;merge with branch dev&quot;Close the branchIf you think there’s no need to keep the dev branch open any longer, you can close it:hg up devhg ci -m &quot;close branch dev&quot; --close-branch" }, { "title": "Python color enum class for ANSI color codes", "url": "/posts/python-color-enum-class-for-ansi-color-codes/", "categories": "Python, color", "tags": "python, ansi codes", "date": "2021-11-07 00:01:00 +0100", "snippet": "When you want to print something with color and/or styling in a terminal, you can use one of the existing modules, such as colorama or sty. They are well-documented, flexible and easy to use.Enum classA very good guideline in software engineering is to avoid reinventing the wheel :upside_down_face:But let’s face it, for some projects you really don’t want to bring in an external dependency. If the task is simple enough, you can just roll your own implementation. In this case, you’d just need to look into ANSI escape codes and find some examples.For my very limited use cases when printing with color in a terminal, I just need to define a few foreground colors as well as the bold and the blink styles. I’m using an Enum class such that color names are class members, thus avoiding any possible misspelling issues:from enum import Enum, autoclass Color(Enum): RED = 31 GREEN = auto() YELLOW = auto() BLUE = auto() MAGENTA = auto() CYAN = auto() LIGHTRED = 91 LIGHTGREEN = auto() LIGHTYELLOW = auto() LIGHTBLUE = auto() LIGHTMAGENTA = auto() LIGHTCYAN = auto() _START = &#39;\\u001b[&#39; _BOLD = &#39;;1&#39; _BLINK = &#39;;5&#39; _END = &#39;m&#39; _RESET = &#39;\\u001b[0m&#39; @staticmethod def colored(color, msg, bold=False, blink=False): if not(isinstance(color, Color)): raise TypeError(f&#39;Unknown color {color}&#39;) fmt_msg = Color._START.value + str(color.value) if bold: fmt_msg += Color._BOLD.value if blink: fmt_msg += Color._BLINK.value return fmt_msg + Color._END.value + str(msg) + Color._RESET.valueWe can use this class as follows:from color import Colorfor item in Color: if item.name.startswith(&#39;_&#39;): continue print(Color.colored(item, item.name)) if item.name.startswith(&#39;LIGHT&#39;): print(Color.colored(item, &#39;{} bold == {} bold&#39;.format( item.name[5:], item.name), bold=True))Here’s the output:Accompanying codeThe full code accompanying this post can be found on my GitHub repository." }, { "title": "Custom logger in Python for stdout and/or file log", "url": "/posts/custom-logger-in-python-for-stdout-and-or-file-log/", "categories": "Python, logging", "tags": "python, logging", "date": "2021-11-07 00:00:00 +0100", "snippet": "The Python logging module may be used to build your own custom logger featuring specialfunctionality according to your use case, such as: Adding both console and file handlers (i.e. logging to both stdout and to a file) Temporarily disabling console logging (e.g. if a global verbose flag is False) Temporarily disabling file logging (e.g. if we want to print with color to stdout using ANSI codes, but without color to the log file) Adding an extra logging level that logs to both console and log file (e.g. even if a global verbose flag is False)This post will show how to build such a custom logger for the above use cases, that we will be going through incrementally. The full code is available on GitHub.Custom logger with stdout and file handlersWe will be creating a CustomLogger class based on logging.getLoggerClass() (the logger used in Python’s logging module) with a default stdout handler. If the user of the class specifies a log directory, then a file handler will also be added. The format of the logs is also different: we use the bare message to log for the stdout handler we show the date, time, logging level, file and line number for the file handlerclass CustomLogger(logging.getLoggerClass()): def __init__(self, name, log_dir=None): # Create custom logger logging all five levels super().__init__(name) self.setLevel(logging.DEBUG) # Create stream handler for logging to stdout (log all five levels) self.stdout_handler = logging.StreamHandler(sys.stdout) self.stdout_handler.setLevel(logging.DEBUG) self.stdout_handler.setFormatter(logging.Formatter(&#39;%(message)s&#39;)) self.enable_console_output() # Add file handler only if the log directory was specified self.file_handler = None if log_dir: self.add_file_handler(name, log_dir) def add_file_handler(self, name, log_dir): &quot;&quot;&quot;Add a file handler for this logger with the specified `name` (and store the log file under `log_dir`).&quot;&quot;&quot; # Format for file log fmt = &#39;%(asctime)s | %(levelname)8s | %(filename)s:%(lineno)d | %(message)s&#39; formatter = logging.Formatter(fmt) # Determine log path/file name; create log_dir if necessary now = datetime.datetime.now().strftime(&#39;%Y%m%d_%H%M%S&#39;) log_name = f&#39;{str(name).replace(&quot; &quot;, &quot;_&quot;)}_{now}&#39; if not os.path.exists(log_dir): try: os.makedirs(log_dir) except: print(&#39;{}: Cannot create directory {}. &#39;.format( self.__class__.__name__, log_dir), end=&#39;&#39;, file=sys.stderr) log_dir = &#39;/tmp&#39; if sys.platform.startswith(&#39;linux&#39;) else &#39;.&#39; print(f&#39;Defaulting to {log_dir}.&#39;, file=sys.stderr) log_file = os.path.join(log_dir, log_name) + &#39;.log&#39; # Create file handler for logging to a file (log all five levels) self.file_handler = logging.FileHandler(log_file) self.file_handler.setLevel(logging.DEBUG) self.file_handler.setFormatter(formatter) self.addHandler(self.file_handler)Notice that we store both the stdout handler and the file handler as members of the CustomLogger, through the instance variables self.stdout_handler and self.file_handler. This is to facilitate the forthcoming tasks, namely to check whether the logger has such handlers and to be able to enable and disable them individually.At lines 28-36, when adding a file handler, we try to create the log directory if it does not exist. If this fails due to a missing permissions issue, we default to writing log files to /tmp on Linux or to the current directory for other operating systems.Check whether the logger has a stream handler and/or a file handlerThe Python logging documentation explains that logging.StreamHandler is the base class for logging.FileHandler. We therefore need to take special care when checking whether the logger has a file handler, since the isinstance check will not be enough:In [159]: sh = logging.StreamHandler()In [160]: fh = logging.FileHandler(&#39;x&#39;)In [161]: isinstance(sh, logging.StreamHandler)Out[161]: TrueIn [162]: isinstance(fh, logging.StreamHandler)Out[162]: TrueIn [163]: type(sh) == logging.StreamHandlerOut[163]: TrueIn [164]: type(fh) == logging.StreamHandlerOut[164]: FalseIn [165]: type(fh) == logging.FileHandlerOut[165]: TrueArmed with this knowledge, we can now add methods to our CustomLogger class to find out whether the logger instance has a console logger and/or a file logger:def has_console_handler(self): return len([h for h in self.handlers if type(h) == logging.StreamHandler]) &amp;gt; 0def has_file_handler(self): return len([h for h in self.handlers if isinstance(h, logging.FileHandler)]) &amp;gt; 0Disable logger console outputUsing the has_console_handler() check to ensure internal API consistency, we can now write methods for our CustomLogger class to temporarily enable/disable console output. Since the logger retains the instance variable self.stdout_handler, we can add it and remove it as we please:def disable_console_output(self): if not self.has_console_handler(): return self.removeHandler(self.stdout_handler)def enable_console_output(self): if self.has_console_handler(): return self.addHandler(self.stdout_handler)Disable logger file outputSimilarly to what we’ve seen above, via the has_file_handler() check in order to ensure internal API consistency, we can now write methods for our CustomLogger class to temporarily enable/disable file output. Since the logger retains the instance variable self.file_handler, we can add it and remove it as we please:def disable_file_output(self): if not self.has_file_handler(): return self.removeHandler(self.file_handler)def enable_file_output(self): if self.has_file_handler(): return self.addHandler(self.file_handler)Verbosity setting for the custom loggerIn certain situations, you way need to create a more quiet or a more verbose logger. If the logger needs to be quiet, you may want to skip logging altogether. This means we need to override the info(), debug(), warning(), error() and critical() methods of the base class and make them behave differently according to the verbosity setting. (Your use case might be different and you may want to keep logging enabled for ERROR and CRITICAL levels for example.)First, we introduce a verbose boolean flag to the __init__() method of our CustomLogger class and store its value in the logger instance. Then, we override the logging methods:class CustomLogger(logging.getLoggerClass()): def __init__(self, name, verbose, log_dir=None): ... self.verbose = verbose def debug(self, msg, *args, **kwargs): self._custom_log(super().debug, msg, *args, **kwargs) def info(self, msg, *args, **kwargs): self._custom_log(super().info, msg, *args, **kwargs) def warning(self, msg, *args, **kwargs): self._custom_log(super().warning, msg, *args, **kwargs) def error(self, msg, *args, **kwargs): self._custom_log(super().error, msg, *args, **kwargs) def critical(self, msg, *args, **kwargs): self._custom_log(super().critical, msg, *args, **kwargs) def _custom_log(self, func, msg, *args, **kwargs): &quot;&quot;&quot;Helper method for logging DEBUG through CRITICAL messages by calling the appropriate `func()` from the base class.&quot;&quot;&quot; # Log normally if verbosity is on if self.verbose: return func(msg, *args, **kwargs) # If verbosity is off and there is no file handler, there is # nothing left to do if not self.has_file_handler(): return # If verbosity is off and a file handler is present, then disable # stdout logging, log, and finally reenable stdout logging self.disable_console_output() func(msg, *args, **kwargs) self.enable_console_output()Custom logging level that overrides the verbosity settingWell all this is fine, but what if you do want to display certain messages after all, even if verbosity is off? Think of them as “system” or “framework” messages that should not be silenced.The solution to this is to add a new logging level to the CustomLogger class. Let’s call it FRAMEWORK and have it log at INFO priority (for the purpose of illustration). We just need to add the level and to write the corresponding framework() method:class CustomLogger(logging.getLoggerClass()): def __init__(self, name, verbose, log_dir=None): ... logging.addLevelName(logging.INFO, &#39;FRAMEWORK&#39;) def framework(self, msg, *args, **kwargs): &quot;&quot;&quot;Logging method for the FRAMEWORK level. The `msg` gets logged both to stdout and to file (if a file handler is present), irrespective of verbosity settings.&quot;&quot;&quot; return super().info(msg, *args, **kwargs)For neat display in the file logs, we should also think of changing the formatter to accommodate 9 characters instead of 8:fmt = &#39;%(asctime)s | %(levelname)9s | %(filename)s:%(lineno)d | %(message)s&#39;Putting the custom logger to useWe can now test the logger in both quiet and verbose mode.Quiet modeIn quiet mode this is really straightforward:def test_quiet(): quiet_log = CustomLogger(&#39;quiet&#39;, verbose=False, log_dir=&#39;logs&#39;) quiet_log.warning(&#39;We now log only to a file log&#39;) quiet_log.framework(&#39;We now log everywhere irrespective of verbosity&#39;)On stdout we get:We now log everywhere irrespective of verbosityIn the file log we get:cat logs/quiet_20211107_131512.log2021-11-07 13:15:12,540 | WARNING | custom_logger.py:124 | We now log only to a file log2021-11-07 13:15:12,540 | FRAMEWORK | custom_logger.py:108 | We now log everywhere irrespective of verbosityVerbose modeIn verbose mode we can try to spice things up a little bit: we disable file output and we log a colored message to stdout, only if stdout is a true TTY (e.g. if the output is not redirected to a file using &amp;gt; or &amp;gt;&amp;gt; in Linux). Note that in this example I’m using my custom Color enum class, available in the GitHub repo through color.py.from color import Color # see accompanying file color.pydef test_verbose(): verbose_log = CustomLogger(&#39;verbose&#39;, verbose=True, log_dir=&#39;logs&#39;) verbose_log.warning(&#39;We now log to both stdout and a file log&#39;) verbose_log.disable_file_output() msg = &#39;Use color in a true TTY&#39; if sys.stdout.isatty(): verbose_log.info(Color.colored(Color.LIGHTYELLOW, msg)) else: verbose_log.info(msg + &#39;, but not here&#39;) verbose_log.enable_file_output() verbose_log.framework(&#39;We now log everywhere irrespective of verbosity&#39;)On stdout we get:In the file log we get:cat logs/verbose_20211107_131512.log2021-11-07 13:15:12,539 | WARNING | custom_logger.py:115 | We now log to both stdout and a file log2021-11-07 13:15:12,540 | FRAMEWORK | custom_logger.py:108 | We now log everywhere irrespective of verbosityAccompanying codeThe full code accompanying this post can be found on my GitHub repository." }, { "title": "Python configuration and data classes", "url": "/posts/python-configuration-and-dataclasses/", "categories": "Python, configuration", "tags": "python, dataclass, software design", "date": "2021-11-05 00:00:00 +0100", "snippet": "I stumbled upon an interesting article in which the author describes best practices for working with configuration files in Python. One of the points he makes is that configuration settings should be handled through identifiers rather than strings. This is very good advice, since hacking away at a raw dictionary to extract (key, value) pairs is a risky and error-prone endeavor. Spelling mistakes and type errors come to mind.Enter data classesFortunately, Python 3.7 introduced dataclasses. Check this article for an in-depth guide. In a nutshell, a data class is a class that essentially holds data (although it can have methods as well), and it comes with mandatory type hints. Data classes are kinda like structs in C++.Here is how we could encapsulate a simple server configuration using a data class:from dataclasses import dataclass@dataclassclass ServerConfig: host: str port: int timeout: floatThis data class may be instantiated and used as follows:In [246]: config = ServerConfig(&#39;example.com&#39;, 80, 0.5)In [247]: configOut[247]: ServerConfig(host=&#39;example.com&#39;, port=80, timeout=0.5)In [248]: config.hostOut[248]: &#39;example.com&#39;Data classes are fortunately not limited to attributes. They can have methods, and all the built-in methods including __init__() are present. Additionally, there’s __post_init__() which is used to post-process the instance after __init__() is done.The data class in the previous example can be modified to accept configuration from a dictionary:@dataclassclass ServerConfigFromDict: host: str port: int timeout: float def __init__(self, conf: dict): self.host = conf[&#39;host&#39;] self.port = conf[&#39;port&#39;] self.timeout = conf[&#39;timeout&#39;]If we try to access a non-existing key from the conf dict, a KeyError is raised. Notice in this example that we do not check whether the value for &#39;port&#39; is an int, nor whether the value for &#39;timeout&#39; is a float.This data class may be instantiated as follows:In [263]: config = ServerConfigFromDict({&#39;host&#39;: &#39;example.com&#39;, &#39;port&#39;: 80, &#39;timeout&#39;: 0.5})In [264]: configOut[264]: ServerConfigFromDict(host=&#39;example.com&#39;, port=80, timeout=0.5)In [265]: config.hostOut[265]: &#39;example.com&#39;Another solution is to use the dacite package:In [344]: data = {&#39;host&#39;: &#39;example.com&#39;, &#39;port&#39;: 80, &#39;timeout&#39;: 0.5}In [345]: config = dacite.from_dict(data_class=ServerConfig, data=data)In [346]: configOut[346]: ServerConfig(host=&#39;example.com&#39;, port=80, timeout=0.5)In [347]: config.hostOut[347]: &#39;example.com&#39;Dynamically creating a configuration classThe previous examples have shown how to transform a dict-based configuration into a data class. However, we had to make assumptions regarding the configuration itself (what keys it actually contains). There may be situations where you just want to load the whole dict without knowing what keys it contains.We can do this using the Python setattr built-in method. We don’t even need a data class for this, a “dumb” class can cut it just as well:class DynamicConfig: def __init__(self, conf): if not isinstance(conf, dict): raise TypeError(f&#39;dict expected, found {type(conf).__name__}&#39;) self._raw = conf for key, value in self._raw.items(): setattr(self, key, value)config = DynamicConfig({&#39;host&#39;: &#39;example.com&#39;, &#39;port&#39;: 80, &#39;timeout&#39;: 0.5})print(f&#39;host: {config.host}, port: {config.port}, timeout: {config.timeout}&#39;)Output:host: example.com, port: 80, timeout: 0.5Dynamic configuration with INI filesThe dynamic configuration class we’ve seen above works well for dicts. However, when parsing certain configuration file formats, the output might be something dict-like, i.e. close to but not quite a dict.Take the INI format for instance. Suppose we have a config.ini file with the following contents:[server]host = example.comport = 80timeout = 0.5[user]username = adminlevel = 10INI files may be parsed with configparser, but the object we get is a configparser.ConfigParser. We can create a class to encapsulate such an object and provide identifiers for keys. For the key = value part of the INI file, we can reuse our previous DynamicConfig class above, but we need to handle the [sections] in the INI file separately.class DynamicConfigIni: def __init__(self, conf): if not isinstance(conf, configparser.ConfigParser): raise TypeError(f&#39;ConfigParser expected, found {type(conf).__name__}&#39;) self._raw = conf for key, value in self._raw.items(): setattr(self, key, DynamicConfig(dict(value.items())))Here is DynamicConfigIni in action:parser = configparser.ConfigParser()parser.read_file(open(&#39;config.ini&#39;))config = DynamicConfigIni(parser)print(&#39;server:&#39;, config.server.host, config.server.port, config.server.timeout)print(&#39;user:&#39;, config.user.username, config.user.level)Output:server: example.com 80 0.5user: admin 10ConclusionIn this post we’ve seen how to encapsulate configuration settings in Python such that we get identifiers instead of strings for the configuration keys. For a simple usage where we know in advance what keys the configuration contains, we can use data classes. For more advanced use cases it is also possible to use setattr() to “objectify” the configuration keys. We have looked at a case study for the INI file format, that may be parsed with configparser.Check out this article for a discussion of passing configuration options in Python through environment variables." }, { "title": "Standalone Python script to run other Python scripts", "url": "/posts/standalone-python-script-to-run-other-python-scripts/", "categories": "Python, packaging", "tags": "python, exec, runpy", "date": "2021-11-04 00:00:00 +0100", "snippet": "In the previous post we’ve seen how to use setuptools to package a Python project along with a standalone executable that can be invoked on the command-line, system-wide (or rather environment-wide).Now, what if you need that standalone script to be a runner, sort of like a master script running other Python scripts that import modules from the newly installed package?Although it seems straightforward, there might be some issues with getting the Python scripts to actually run, as my recent Stack Overflow experience has shown.What we want to obtainHere is how a script using your package might look like:# my_script.pyfrom mypackage import capitalizeprint(f&#39;Running {__file__}&#39;)print(capitalize(&#39;my text&#39;))print(f&#39;Done running {__file__}&#39;)You would invoke your standalone script, let’s call it runner, as follows:runner my_script.pyAnd you’d obtain:runner v1.0.0 started on 2021-11-04 00:11:26Running my_script.pyMY TEXTDone running my_script.pyrunner v1.0.0 finished on 2021-11-04 00:11:26Making the necessary adjustmentsWe start off by editing setup.py to which we add a new console script entry point. There is no need to have the function pointed at by the entry point to reside in a different file than the __main__.py that we already have:from setuptools import setup, find_packagessetup( name=&quot;mypackage&quot;, # [snip] entry_points = {&#39;console_scripts&#39;: [ &#39;capitalize = mypackage.__main__:main&#39;, &#39;runner = mypackage.__main__:runner&#39;, # this gets added ]},)The __main__.py file gets a new runner() function:import argparsefrom datetime import datetimeimport sysdef now(): return datetime.now().strftime(&#39;%Y-%m-%d %H:%m:%S&#39;)def runner(): version = &#39;1.0.0&#39; parser = argparse.ArgumentParser(prog=&#39;runner&#39;) parser.add_argument(&#39;script&#39;, help=&#39;Python script to run&#39;) parser.add_argument(&#39;-v&#39;, &#39;--version&#39;, help=&#39;display version&#39;, action=&#39;version&#39;, version=f&#39;%(prog)s {version}&#39;) args = parser.parse_args() if args.script: print(f&#39;{parser.prog} v{version} started on {now()}&#39;) exec(open(args.script).read()) print(f&#39;{parser.prog} v{version} finished on {now()}&#39;) else: parser.print_usage() sys.exit(1)But does it work?However, in the cases I’ve tested, this will not work. The exec() call does not seem to have any effect. One way to deal with this is to compile the script specified via command-line and execute the resulting code:import os...def runner(): ... # exec(open(args.script).read()) exec(compile(open(args.script).read(), os.path.basename(args.script), &#39;exec&#39;))While this does work, it has the disadvantage that the __file__ builtin of the executed script gets overwritten. You might get something like this:runner v1.0.0 started on 2021-11-04 00:11:26Running /full/path/to/mypackage/mypackage/__main__.pyMY TEXTDone running /full/path/to/mypackage/mypackage/__main__.pyrunner v1.0.0 finished on 2021-11-04 00:11:26The solutionThere is still hope, thanks to the runpy module in the standard library:...def runner(): ... # exec(open(args.script).read()) # exec(compile(open(args.script).read(), os.path.basename(args.script), &#39;exec&#39;)) argparse.Namespace(**runpy.run_path(args.script))Now we finally get the expected output, with __file__ in my_script.py not being overwritten since runpy takes care to set it along with several other special global variables before exec()ing the code.Accompanying codeThe full code accompanying this post can be found on my GitHub repository." }, { "title": "Distribute a Python package with a standalone script using setuptools", "url": "/posts/distribute-a-python-package-with-a-standalone-script-using-setuptools/", "categories": "Python, packaging", "tags": "python, setuptools", "date": "2021-11-03 00:00:00 +0100", "snippet": "Suppose you’ve written a Python package that you want to be able to pip install locally. Additionally, you also want to be able to run one of the scripts in the package via its name, without the .py extension and without explicitly using the Python interpreter to launch it. In other words, you want to be able to runstandalone_scriptinstead ofpython /path/to/my/package/standalone_script.pyThis post explains how to achieve this using setuptools.A world without setuptoolsSuppose the package is a simple one, containing only a readme file and a single module core.py. There is also going to be a __init__.py file detailing the imports from core.py that you would want to have available when you import mypackage. The starting project structure may look something like this:mypackage/ README.md __init__.py core.pyFor the purpose of illustration, let us suppose that core.py contains a function capitalize() that takes a string and returns it in all caps (uppercase):# core.pydef capitalize(text): if not isinstance(text, str): raise ValueError(&#39;Need string to capitalize&#39;) return text.upper()The __init__.py file imports the only thing it can, i.e. the capitalize() function:# __init__.pyfrom mypackage.core import capitalizeThis way, each time you want to use the mypackage module, capitalize() becomes available. But you would need to go through the very tedious and error-prone approach of manually adding the path to mypackage every time you want to use it:# some_script.pyimport syssys.path.append(&#39;/path/to/mypackage&#39;)from mypackage import capitalizeprint(capitalize(&#39;this&#39;))That’s pretty lame, but fortunately we can do better.Enter setuptoolsYou can package the project and then install it via pip locally. Then any script that needs the newly installed package can simply import it:# some_script.pyfrom mypackage import capitalizeprint(capitalize(&#39;this&#39;))In order to achieve this, only two steps are involved: reorganize the project structure create a setup.py fileFor the project structure, simply create a subdirectory with the same name as the package name and move modules i.e. .py files inside it:mypackage/ README.md setup.py mypackage/ __init__.py core.pyThe setup.py file has the following contents:from setuptools import setup, find_packagessetup( name=&#39;mypackage&#39;, version=&#39;1.0.0&#39;, description=&#39;Capitalize strings&#39;, author=&#39;John Doe&#39;, author_email=&#39;doe@example.com&#39;, packages=find_packages(),)We can then install the package locally using pip:pip install -e /path/to/mypackageThe /path/to/mypackage above refers to the top-level mypackage/ directory.The package may be uninstalled with:pip uninstall mypackageStandalone scriptWhat if we wanted a standalone script to be installed along with mypackage that would run the capitalize() function on any string that we pass through the command line? Here is how the script would be used:$ capitalizeusage: capitalize [-h] [-v] [string [string ...]]$ capitalize my textMY TEXTIn order to achieve this, we need to: create the script that runs the capitalize() function on the string that gets passed to it via the command line edit setup.py to instruct it how to “install” the script (i.e. how to make it accessible system-wide)We will be creating the standalone script in a file called __main__.py that we place in the subdirectory containing the other Python modules:mypackage/ README.md setup.py mypackage/ __init__.py __main__.py core.pyThen we write the script in the main() method of __main__.py:import argparseimport sysfrom mypackage import capitalizedef main(): parser = argparse.ArgumentParser(prog=&#39;capitalize&#39;) parser.add_argument(&#39;string&#39;, nargs=&#39;*&#39;, help=&#39;string to capitalize&#39;) parser.add_argument(&#39;-v&#39;, &#39;--version&#39;, help=&#39;display version&#39;, action=&#39;version&#39;, version=f&#39;%(prog)s 1.0.0&#39;) args = parser.parse_args() if args.string: text = &#39; &#39;.join(word for word in args.string) print(capitalize(text)) else: parser.print_usage() sys.exit(1)if __name__ == &#39;__main__&#39;: sys.exit(main())At lines 7-11, we add an argument parser. It can either display the program version (through -v or --version) or consume all the command line arguments (nargs=&#39;*&#39;) in order to pass them to the capitalize() function (lines 13-15).The only thing left to do now is to point setup.py to the main() function of the __main__.py module and to ask it to add it as a console script “entry point” called capitalize:from setuptools import setup, find_packagessetup( name=&quot;mypackage&quot;, # [snip] entry_points = {&#39;console_scripts&#39;: [&#39;capitalize = mypackage.__main__:main&#39;]},)That’s it! Now the package may be installed with pip as shown above and the capitalize script becomes available system-wide in the current Python environment. You might want to read the next post for a special tricky situation involving the use of the standalone script as a runner.Accompanying codeThe full code accompanying this post can be found on my GitHub repository." }, { "title": "Bitwise nuggets&amp;#58; XOR swap", "url": "/posts/bitwise-nuggets-xor-swap/", "categories": "Algorithms, bitwise", "tags": "c/c++, algorithms, swap, xor", "date": "2021-11-02 00:00:00 +0100", "snippet": "XOR swap is a kind of in-place swap that only uses XOR operations. No temporary variable nor addition/subtraction operation is needed. However, it only works for integers.Reminder: XOR (short for exclusive or) is a logical operation that yields true only if its arguments differ (one argument is true, the other one is false). Substitute 0 for false and 1 for true in the following: 0 XOR 0 = 0 0 XOR 1 = 1 1 XOR 0 = 1 1 XOR 1 = 0The following C++ program illustrates the use of the XOR swap to exchange two integers (passed as pointers to the function):#include &amp;lt;iostream&amp;gt;void xor_swap(int *a, int *b){ if (*a == *b) return; *a ^= *b; *b ^= *a; *a ^= *b;}int main(){ int x = 5, y = 7; std::cout &amp;lt;&amp;lt; &quot;x = &quot; &amp;lt;&amp;lt; x &amp;lt;&amp;lt; &quot;, y = &quot; &amp;lt;&amp;lt; y &amp;lt;&amp;lt; std::endl; xor_swap(&amp;amp;x, &amp;amp;y); std::cout &amp;lt;&amp;lt; &quot;x = &quot; &amp;lt;&amp;lt; x &amp;lt;&amp;lt; &quot;, y = &quot; &amp;lt;&amp;lt; y &amp;lt;&amp;lt; std::endl; return 0;}Not that it’s very useful in practice since modern compilers optimize swapping when using a temporary variable (and there’s also the XCHG assembler instruction), but it’s fun to know about it :upside_down_face:Want to see more bitwise logic? There’s a whole repository on my GitHub on bit fiddling." }, { "title": "std::map with pointers as keys", "url": "/posts/std-map-with-pointers-as-keys/", "categories": "C/C++, pointers", "tags": "c/c++, pointers, stl, map", "date": "2021-10-31 01:00:00 +0200", "snippet": "When the keys in a std::map are pointers, find() will fail unless the search query is one of the actual pointers in the map. However, in most cases this might not be exactly what we want to achieve.Consider the following example: we want to map coordinates to planets at those coordinates using std::map. Here are the Coords and Planet classes:#include &amp;lt;iostream&amp;gt;#include &amp;lt;map&amp;gt;class Coords { uint16_t _x; uint16_t _y;public: Coords(uint16_t x, uint16_t y) : _x(x), _y(y) { } friend std::ostream&amp;amp; operator&amp;lt;&amp;lt;(std::ostream&amp;amp; out, const Coords&amp;amp; coords) { out &amp;lt;&amp;lt; &quot;(&quot; &amp;lt;&amp;lt; coords._x &amp;lt;&amp;lt; &quot;, &quot; &amp;lt;&amp;lt; coords._y &amp;lt;&amp;lt; &quot;)&quot;; return out; }};class Planet { const Coords* _coords; std::string _name;public: Planet(const Coords* coords, std::string name) : _coords(coords), _name(name) { } const Coords* get_coords() const { return _coords; } friend std::ostream&amp;amp; operator&amp;lt;&amp;lt;(std::ostream&amp;amp; out, const Planet&amp;amp; planet) { out &amp;lt;&amp;lt; &quot;Planet &quot; &amp;lt;&amp;lt; planet._name &amp;lt;&amp;lt; &quot; @ &quot; &amp;lt;&amp;lt; *planet._coords; return out; }};Let’s create a map and add some coordinates and planets to it:Coords c11{1, 1};Coords c22{2, 2};Coords c33{3, 3};Coords c44{4, 4};Planet proxima{&amp;amp;c11, &quot;Proxima&quot;};Planet arrakis{&amp;amp;c22, &quot;Arrakis&quot;};Planet remulak{&amp;amp;c33, &quot;Remulak&quot;};Planet regulus{&amp;amp;c44, &quot;Regulus&quot;};std::map&amp;lt;const Coords *, Planet *&amp;gt; planet_map;planet_map.insert(std::make_pair(proxima.get_coords(), &amp;amp;proxima));planet_map.insert(std::make_pair(arrakis.get_coords(), &amp;amp;arrakis));planet_map.insert(std::make_pair(remulak.get_coords(), &amp;amp;remulak));planet_map.insert(std::make_pair(regulus.get_coords(), &amp;amp;regulus));for (auto it = planet_map.begin(); it != planet_map.end(); ++it) { std::cout &amp;lt;&amp;lt; *it-&amp;gt;first &amp;lt;&amp;lt; &quot;: &quot; &amp;lt;&amp;lt; *it-&amp;gt;second &amp;lt;&amp;lt; std::endl;}We obtain:(1, 1): Planet Proxima @ (1, 1)(2, 2): Planet Arrakis @ (2, 2)(3, 3): Planet Remulak @ (3, 3)(4, 4): Planet Regulus @ (4, 4)The problemWe can also search for (const Coords *, Planet *) pairs if we use one of the already existing Coords objects:auto it = planet_map.find(&amp;amp;c33);if (it == planet_map.end()) { std::cout &amp;lt;&amp;lt; &quot;Coordinates &quot; &amp;lt;&amp;lt; query &amp;lt;&amp;lt; &quot; are not present in the map&quot; &amp;lt;&amp;lt; std::endl;} else { std::cout &amp;lt;&amp;lt; *it-&amp;gt;first &amp;lt;&amp;lt; &quot;: &quot; &amp;lt;&amp;lt; *it-&amp;gt;second &amp;lt;&amp;lt; std::endl;}As expected, we obtain:(3, 3): Planet Remulak @ (3, 3)But watch what happens if we use another object created through the default Coords copy constructor:Coords query = c33;auto it = planet_map.find(&amp;amp;query);if (it == planet_map.end()) { std::cout &amp;lt;&amp;lt; &quot;Coordinates &quot; &amp;lt;&amp;lt; query &amp;lt;&amp;lt; &quot; are not present in the map&quot; &amp;lt;&amp;lt; std::endl;} else { std::cout &amp;lt;&amp;lt; *it-&amp;gt;first &amp;lt;&amp;lt; &quot;: &quot; &amp;lt;&amp;lt; *it-&amp;gt;second &amp;lt;&amp;lt; std::endl;}This is the same code as above, except that now we declare a new Coords variable query to which we assign the c33 variable. Internally, the assignment uses the Coords copy constructor Coords(const Coords&amp;amp; coords). In this case, the query is not found:Coordinates (3, 3) are not present in the mapThis happens because, remember, the keys in the std::map are pointers to (const) Coord objects, and what find() does is try to match the pointers in the map against the pointer we pass to it (&amp;amp;query in our example).The solutionWe need a way to tell find() to compare the actual coordinates, and not the Coords pointers. There are two steps involved: We need to add custom logic to the coordinate comparison: in technical terms, we need to overload operator&amp;lt; for the Coords class; We need to create the std::map using a custom comparator. There are actually two ways to do this, we’ll get there in just a minute.Overload the less-than operatorHere we just need to define how two coordinates (x1, y1) and (x2, y2) are compared, returning true if (x1, y1) is less than (x2, y2) and false otherwise. In order to do this, we add the following member method to the Coords class:bool operator&amp;lt;(const Coords&amp;amp; other) const{ if (_x == other._x) return _y &amp;lt; other._y; return _x &amp;lt; other._x;}Custom comparator for the std::mapThe comparator is the function object or predicate that gets to use our shiny new operator&amp;lt; overload. As hinted here and as mentioned above, there are two ways to do this: We can use a function object, basically a struct with an overloaded operator(); We can use a lambda expression.Using a function objectWe can define a struct CmpCoordsFunctor overloading its operator().struct CmpCoordsFunctor { bool operator()(const Coords *lhs, const Coords *rhs) const { return *lhs &amp;lt; *rhs; }};A functor is simply a function object i.e. a class or struct that overloads operator(). When creating the std::map, we add CmpCoordsFunctor as comparator as follows:std::map&amp;lt;const Coords *, Planet *, CmpCoordsFunctor&amp;gt; planet_map;Using a lambda expressionInstead of using a functor as we’ve seen above, we can also use a lambda expression to achieve the same result:auto CmpCoordsLambda = [](const Coords *lhs, const Coords *rhs) { return *lhs &amp;lt; *rhs;};std::map&amp;lt;const Coords *, Planet *, decltype(CmpCoordsLambda)&amp;gt; planet_map(CmpCoordsLambda);The end resultRegardless of the method used for adding the custom comparator (function object or lambda expression), the end result is the same. We can now search whether a given set of coordinates is present in the map by only examining the value of the coordinates, not the pointer itself. With the same query variable that was used at the beginning of this post, we now obtain the correct answer:(3, 3): Planet Remulak @ (3, 3)That’s it, happy planet mapping! :stars::telescope:" }, { "title": "Const and pointers in C++", "url": "/posts/const-and-pointers-in-cpp/", "categories": "C/C++, pointers", "tags": "c/c++, pointers, const", "date": "2021-10-30 01:00:00 +0200", "snippet": "The possible uses of the const qualifier with C++ pointers: pointer to const variable const pointer to variable const pointer to const variableAll examples below will be using the same struct MyType defined below:struct MyType { int _x; MyType(int x): _x(x) {} friend std::ostream&amp;amp; operator&amp;lt;&amp;lt;(std::ostream&amp;amp; out, const MyType &amp;amp;my_type) { out &amp;lt;&amp;lt; my_type._x; return out; }};We declare two variables of type MyType as follows:MyType a{1};MyType b{2};Pointer to const variableWhen using a pointer to a const variable, we cannot change the value of the variable pointed to by the pointer. However, we can reassign the pointer itself:// pointer to const variableconst MyType *ptr1 = &amp;amp;a;std::cout &amp;lt;&amp;lt; &quot;ptr1: &quot; &amp;lt;&amp;lt; *ptr1 &amp;lt;&amp;lt; std::endl;// ptr1-&amp;gt;_x = 33; // errorptr1 = &amp;amp;b;std::cout &amp;lt;&amp;lt; &quot;ptr1: &quot; &amp;lt;&amp;lt; *ptr1 &amp;lt;&amp;lt; std::endl;Output:ptr1: 1ptr1: 2Const pointer to variableWhen using a const pointer to a variable, we can change the value of the variable pointed to by the pointer. However, we cannot reassign the pointer. It is the opposite of the situation above:// const pointer to variableMyType* const ptr2 = &amp;amp;a;std::cout &amp;lt;&amp;lt; &quot;ptr2: &quot; &amp;lt;&amp;lt; *ptr2 &amp;lt;&amp;lt; std::endl;ptr2-&amp;gt;_x = 10;std::cout &amp;lt;&amp;lt; &quot;ptr2: &quot; &amp;lt;&amp;lt; *ptr2 &amp;lt;&amp;lt; std::endl;// ptr2 = &amp;amp;b; // errorOutput:ptr2: 1ptr2: 10Const pointer to const variableWhen using a const pointer to a const variable, we can neither change the value of the variable pointed by the pointer, nor reassign the pointer:// const pointer to const variableconst MyType* const ptr3 = &amp;amp;b;std::cout &amp;lt;&amp;lt; &quot;ptr3: &quot; &amp;lt;&amp;lt; *ptr3 &amp;lt;&amp;lt; std::endl;// ptr3-&amp;gt;_x = 33; // error// ptr3 = &amp;amp;a; // errorOutput:ptr3: 2ConclusionHere is the recap in table form:   variable const variable pointer can change value;can reassign pointer cannot change value;can reassign pointer const pointer can change value; cannot reassign pointer cannot change value;cannot reassign pointer " }, { "title": "Remove every occurrence of an item from a list in Python", "url": "/posts/remove-every-occurrence-of-an-item-from-a-list-python/", "categories": "Python, data structures", "tags": "python, occurrence", "date": "2021-09-20 01:00:00 +0200", "snippet": "A problem that I come across quite often is having to remove every occurrence of a given item from a Python list. While built-in mutable types have a remove() method, my_list.remove(x) only removes the first occurrence of item x from my_list.Here is the pattern I use for removing every occurrence of a given item from a list:def remove_all(items, item_to_remove): if not isinstance(items, list): raise TypeError(f&#39;invalid list type {type(items).__name__}&#39;) last_occurrence = False while not last_occurrence: try: items.remove(item_to_remove) except ValueError: last_occurrence = TrueThe documentation states that remove() raises a ValueError when the item to remove is not found in the list.In remove_all(), we take advantage of this. When a ValueError is raised, it means the item is no longer in the list or, in other words, that we have managed to remove every occurrence of that item from the list.Example:In [217]: items = [1, 2, 3, 1, 4, 5, 1, 6, 1, 7]In [218]: remove_all(items, 1)In [219]: itemsOut[219]: [2, 3, 4, 5, 6, 7]As can be seen above, remove_all() changes the input list items." }, { "title": "How to return a result from a Python thread", "url": "/posts/how-to-return-a-result-from-a-python-thread/", "categories": "Python, thread, timeout", "tags": "python, thread", "date": "2021-08-24 01:00:00 +0200", "snippet": "The problemSuppose you have a Python thread that runs your target function. Simple scenario: That target function returns a result that you want to retrieve. A more advanced scenario: You want to retrieve the result of the target function if the thread does not time out.There are several ways to retrieve a value from a Python thread. You can use concurrent.futures, multiprocessing.pool.ThreadPool or just threading with Queue.This post proposes an alternative solution that does not require any other package aside from threading.The solutionIf you don’t want to use anything else beside the threading module, the solution is simple: Extend the threading.Thread class and add a result member to your new class. Make sure to take into account positional and keyword arguments in the constructor. Override the base class’s run() method: in addition to running the target function as expected (with its args and kwargs intact), it has to store the target’s result in the new member result. Override the base class’s join() method: with args and kwargs intact, simply join() as in the base class but also return the result. Then when you instantiate your new thread class, intercept the result returned by join().Note the stress placed upon preserving the target’s positional and keyword arguments: this ensures that you can also join() the thread with a timeout, as you would a with a threading.Thread instance.The following section illustrates these steps.Implementation: ReturnValueThread classBelow, the class ReturnValueThread extends threading.Thread (lines 4-19). In the constructor, we declare a result member that will store the result returned by the target function (lines 6-8). We override the run() method by storing the result of the target in the result member (lines 10-16). We override the join() method such as to return the result member (lines 18-20).import threadingimport sysclass ReturnValueThread(threading.Thread): def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) self.result = None def run(self): if self._target is None: return # could alternatively raise an exception, depends on the use case try: self.result = self._target(*self._args, **self._kwargs) except Exception as exc: print(f&#39;{type(exc).__name__}: {exc}&#39;, file=sys.stderr) # properly handle the exception def join(self, *args, **kwargs): super().join(*args, **kwargs) return self.resultUsage example for ReturnValueThreadHere is how to use the ReturnValueThread class defined above. Imagine that the target functions both compute and return the square of the argument that gets passed to them: square() returns the square of its argument instantly (lines 4-5); think_about_square() returns the square of its argument after having… thought about it for a while (lines 8-10).Why do we have two target functions in this example? Remember the scenarios mentioned at the beginning of this post: A simple scenario is to simply retrieve the value returned by the target function (lines 16-19); A more advanced scenario is to retrieve the value if the function finishes running before a specified timeout (lines 21-27).import timedef square(x): return x ** 2def think_about_square(x): time.sleep(x) return square(x)def main(): value = 3 thread1 = ReturnValueThread(target=square, args=(value,)) thread1.start() result = thread1.join() print(f&#39;square({value}) = {result}&#39;) thread2 = ReturnValueThread(target=think_about_square, args=(value,)) thread2.start() result = thread2.join(timeout=1) if thread2.is_alive(): print(&#39;Timeout in think_about_square&#39;) # properly handle timeout else: print(f&#39;think_about_square({value}) = {result}&#39;)if __name__ == &#39;__main__&#39;: main()thread1 is the thread running square() (instant result, retrieved as expected). thread2, on the other hand, runs think_about_square(), and it just so happens that it does not finish within the allotted time. We test whether the thread finished at line 24 via thread2.is_alive().CaveatThe more observant types have probably noticed that although ReturnValueThread returns the result of the target function, our thread2 in the above example (the thread that times out) does not exit cleanly. In fact, it runs until the sleep() ends. In a previous post we have seen how to exit a Python thread cleanly. Another solution is to use a process instead of a thread, but this comes with its own set of complications. The most notable difficulty is the fact that, unlike threads, processes run in separate memory spaces, which tends to complicate things since resources now have to be shared.Further reading How to exit a Python thread cleanly (using a threading event) Multiprocessing in Python with shared resources concurrent.futures (Python documentation) multiprocessing.pool.ThreadPool (Python documentation) threading (Python documentation) Queue (Python documentation)" }, { "title": "Connect a bluetooth headset automatically in Linux", "url": "/posts/connect-bluetooth-headset-automatically-linux/", "categories": "Linux, audio", "tags": "linux, audio, bluetooth", "date": "2021-07-14 01:00:00 +0200", "snippet": "I can never remember how to automatically connect to my bluetooth headset so here is a very short recipe.Make sure your bluetooth headphones are already paired and trusted. Then proceed according to the sound server system you’re using (PulseAudio or PipeWire).PulseAudioAssuming you are using PulseAudio, edit /etc/pulse/default.pa as explained here and add the following to it:### Automatically switch to newly-connected devicesload-module module-switch-on-connectPipeWireSee this post for the equivalent PipeWire configuration.ConclusionNow, the next time you switch on your bluetooth headphones, they will automatically connect and become the default device." }, { "title": "How to stop a Python thread cleanly", "url": "/posts/how-to-stop-a-python-thread-cleanly/", "categories": "Python, concurrency, thread", "tags": "python, thread", "date": "2021-07-06 01:00:00 +0200", "snippet": "Suppose a Python thread needs to be stopped cleanly (it might need to perform cleanup).For illustration, we will take a very simple program in with a single “worker” thread that displays a message when it is done. The message is a placeholder for real cleanup, and the thread itself sleeps for a given number of iterations (as a placeholder for significant work). In our example, we want to stop the thread through a keyboard interrupt (Ctrl + C).By default, the thread is not stopped cleanlyIn this first version, the program can be stopped by hitting Ctrl + C, but the thread keeps running. Here is the program:import threadingimport timedef do_some_work(n_iter): for i in range(n_iter): print(f&#39;iteration {i + 1}/{n_iter}&#39;) time.sleep(0.5) print(&#39;Thread done&#39;)if __name__ == &#39;__main__&#39;: n_iter = 10 thread = threading.Thread(target=do_some_work, args=(n_iter,)) thread.start() thread.join() print(&#39;Program done&#39;)Here is what happens when stopping it via a keyboard interrupt (... denotes output that was snipped for readability purposes):iteration 1/10iteration 2/10^CTraceback (most recent call last): ...KeyboardInterruptiteration 3/10iteration 4/10^CException ignored in: &amp;lt;module &#39;threading&#39; from &#39;/home/alex/miniconda3/lib/python3.7/threading.py&#39;&amp;gt; ...KeyboardInterruptThe first Ctrl + C stops the main program, but not the thread. The second time, the thread is stopped as well.Using a daemon thread is not a good ideaThe Python threading documentation explains that a thread may be started as a daemon, meaning that “the entire Python program exits when only daemon threads are left”. The main program itself is not a daemon thread.While this approach has the merit of effectively stopping the thread, it does not allow to exit it cleanly. From the Python documentation: Note: Daemon threads are abruptly stopped at shutdown. Their resources (such as open files, database transactions, etc.) may not be released properly. If you want your threads to stop gracefully, make them non-daemonic and use a suitable signalling mechanism such as an Event.A clean thread exit using events and signalsFollowing on the previous note, a threading Event is a simple object that can be set or cleared. It can be used to signal to the thread that it needs perform its cleanup and then stop.The idea is to use such an event here (let us call it a stop event). Initially not set, the stop event becomes set when a keyboard interrupt is received. The worker thread then breaks out from the loop if the stop event is set and performs its cleanup.Creating the stop event is straightforward (it can take any name):stop_event = threading.Event()The worker thread checks whether the stop event is set:if stop_event.is_set(): breakThe stop event needs to be set when a keyboard interrupt is intercepted. This is done by registering the SIGINT signal with a handler function. The registration is done in the main program:signal.signal(signal.SIGINT, handle_kb_interrupt)The handler function handle_kb_interrupt must have two arguments, the signal and the frame, even though the second argument is not used:def handle_kb_interrupt(sig, frame): stop_event.set()Here is the full program:import signalimport threadingimport timedef do_some_work(n_iter): for i in range(n_iter): if stop_event.is_set(): break print(f&#39;iteration {i + 1}/{n_iter}&#39;) time.sleep(0.5) print(&#39;Thread done&#39;)def handle_kb_interrupt(sig, frame): stop_event.set()if __name__ == &#39;__main__&#39;: stop_event = threading.Event() signal.signal(signal.SIGINT, handle_kb_interrupt) n_iter = 10 thread = threading.Thread(target=do_some_work, args=(n_iter,)) thread.start() thread.join() print(&#39;Program done&#39;)Here is the output when hitting Ctrl + C in the new version of the program:iteration 1/10iteration 2/10iteration 3/10^CThread doneProgram doneNotice that when the thread is stopped it now finally gets to the print(&#39;Thread done&#39;) line (a placeholder for an actual cleanup task). Moreover, the main program also gets to the print(&#39;Program done&#39;) line. Clean exit from a thread can therefore be achieved using a threading event and a signal handler.Further reading threading (Python documentation) signal (Python documentation) Signals (Wikipedia)" }, { "title": "Kill a Python subprocess and its children when a timeout is reached", "url": "/posts/kill-subprocess-and-its-children-on-timeout-python/", "categories": "Python, subprocess, timeout", "tags": "python, process, subprocess, signal", "date": "2021-07-05 01:00:00 +0200", "snippet": "Suppose a Python script needs to launch an external command. This can be done using the subprocess module in one of two ways: either use the “convenience” function subprocess.run() or use the more flexible Popen interfaceStopping a subprocess on timeoutThe “convenience” function subprocess.run() allows to do quite a number of useful things, such as capturing output, checking the external command’s return code or setting a timeout, among others.If we are simply interested in stopping the execution of the external command after a given timeout has been reached, it is sufficient to subprocess.run() the command and catch the TimeoutExpired exception if it is raised:import subprocesscmd = [&#39;/path/to/cmd&#39;, &#39;arg1&#39;, &#39;arg2&#39;] # the external command to runtimeout_s = 10 # how many seconds to wait try: p = subprocess.run(cmd, timeout=timeout_s)except subprocess.TimeoutExpired: print(f&#39;Timeout for {cmd} ({timeout_s}s) expired&#39;)Stopping a subprocess and its children on timeoutThe situation gets more complicated when the external command may launch one or several child processes. In order to be able to stop the child processes as well as the parent, it is necessary to use the Popen constructor. Note: The following only applies to UNIX-like operating systems. (Read: it won’t work on Windows.)The reason for using the Popen constructor for this scenario is that it can be instructed to launch a new session for the external command. Then, the whole process group belonging to the external command can be terminated on timeout. A process group is simply a group of processes that can be controlled at once (via signals), while a session is a collection of process groups. Here are the official definitions, taken from the POSIX.1-2008 standard: 3.296 Process Group - A collection of processes that permits the signaling of related processes. Each process in the system is a member of a process group that is identified by a process group ID. A newly created process joins the process group of its creator. 3.343 Session - A collection of process groups established for job control purposes. Each process group is a member of a session. A process is considered to be a member of the session of which its process group is a member. A newly created process joins the session of its creator. A process can alter its session membership; see setsid(). There can be multiple process groups in the same session.The reason for using a session instead of a process groupReading the above definitions, one may wonder why should we bother with creating a new session instead of simply using a new process group for the external command. That’s an excellent question! It is technically possible, but not advisable. In order to create a process group, we’d need to call os.setpgrp() (which uses the setpgrp() system call). However, there are two problems with this approach: setpgrp() is marked as obsolete and may be removed in future versions (check the man page); the only way to call os.setpgrp() from within the Popen constructor is to pass it to the preexec_fn parameter, which is not thread-safe.The Python documentation for Popen() states the following: Warning: The preexec_fn parameter is not safe to use in the presence of threads in your application. The child process could deadlock before exec is called. If you must use it, keep it trivial! Minimize the number of libraries you call into.In the note following the warning, it is mentioned that: The start_new_session parameter can take the place of a previously common use of preexec_fn to call os.setsid() in the child.The workaround, therefore, is to simply create a new session by setting the start_new_session argument of the Popen constructor to True. According to the Python documentation, it is the equivalent of using preexec_fn=os.setsid (based on the setsid() system call), but without the un-thread-safe warning.ImplementationWith all the above explanations, the implementation is straight-forward:import osimport signalimport subprocessimport syscmd = [&#39;/path/to/cmd&#39;, &#39;arg1&#39;, &#39;arg2&#39;] # the external command to runtimeout_s = 10 # how many seconds to wait try: p = subprocess.Popen(cmd, start_new_session=True) p.wait(timeout=timeout_s)except subprocess.TimeoutExpired: print(f&#39;Timeout for {cmd} ({timeout_s}s) expired&#39;, file=sys.stderr) print(&#39;Terminating the whole process group...&#39;, file=sys.stderr) os.killpg(os.getpgid(p.pid), signal.SIGTERM)The Popen interface is different than that of the convenience subprocess.run() function. The timeout needs to be specified in Popen.wait(). If you want to capture stdout and stderr, you need to pass them to the Popen constructor as subprocess.PIPE and then use Popen.communicate(). Regardless of the differences, whatever can be done with subprocess.run() can also be achieved with the Popen constructor.When the timeout set in Popen.wait() has elapsed, a TimeoutExpired exception is raised. Then, in line 15, we send a SIGTERM to the whole process group (os.killpg()) of the external command (os.getpgid(p.pid)).That’s it. Happy infanticide! (Err… I was referring to child processes :grin:)Further reading subprocess (Python documentation) signal (Python documentation) Signals (Wikipedia) POSIX.1-2008 standard POSIX.1-2008 definitions" }, { "title": "Stopping a Python systemd service cleanly", "url": "/posts/stopping-python-systemd-service-cleanly/", "categories": "Python, systemd", "tags": "python, systemd, service", "date": "2021-06-26 01:00:00 +0200", "snippet": "Suppose you are running a Python systemd service that opens some file descriptors (these can be regular files, named pipes, sockets, and so on). When the service is stopped, it needs to finish cleanly by closing and/or removing the associated resources. This post presents two manners in which the service may be stopped gracefully.First, we will look at how a Python script my_service.py may be ran as a systemd service. Next, we will discuss the general form of that Python script. Finally, we will see how to stop the service gracefully.Running a Python script as a systemd serviceAn executable can be made into a systemd service by creating a unit (configuration) file, also known as a .service file (see the systemd.service man page). The .service files are stored in a specific location and have a certain format.Unit file locationThere are actually three places where unit files may be stored: /etc/systemd/system/: system-specific; take precedence over run-time unit files /run/systemd/system/: run-time; take precedence over default unit files /usr/lib/systemd/system/: default; may be overwritten when the system updatesIf you create your own systemd service, place the .service unit file in /etc/systemd/system/.Unit file formatA unit file (for a service) has three sections: [Unit], [Service] and [Install]. You can read more on unit file anatomy. For this example, let us assume a very simple my-service.service file:[Unit]Description=My test serviceAfter=network.target[Service]User=alexType=simpleExecStart=/usr/bin/python /home/alex/services/my_service.py[Install]WantedBy=multi-user.targetUsing the serviceFirst, we need to add the new service and to reload systemd:sudo ln -sf ~/services/my-service.service /etc/systemd/system/my-service.servicesudo systemctl daemon-reloadThen we can enable the service (this way it will be ran each time the system boots) and start it:sudo systemctl enable my-service.servicesudo systemctl start my-service.serviceIf my_service.py is configured to log information (and it should!), we can check the system logs with journalctl:journalctl -u my-service.serviceAdd an -f to the previous command if you want to follow the journal as it updates, just like with tail -f.The danger zoneRecall the original assumption: my_service.py opens file descriptors and uses the underlying resources. Whenever the service stops running (through sudo systemctl stop my-service.service, for example), it must do so gracefully by closing the open resources first.Before diving into the possible solutions, let us first take a look at the general structure of the my_service.py script.The structure of the Python serviceThe Python service (my_service.py) may be a TCP server, client, or any other process that needs to run as a daemon. For the purpose of this example, let us suppose that the service uses a standard event loop and opens a named pipe in /tmp to read from it. Instead of doing something useful, our example service will just sleep and then log something when it wakes up. The general structure is as follows (possible exceptions from the os module are not caught for brevity purposes):import loggingimport osimport sysimport timeclass MyService: FIFO = &#39;/tmp/myservice_pipe&#39; def __init__(self, delay=5): self.logger = self._init_logger() self.delay = delay if not os.path.exists(MyService.FIFO): os.mkfifo(MyService.FIFO) self.fifo = os.open(MyService.FIFO, os.O_RDWR | os.O_NONBLOCK) self.logger.info(&#39;MyService instance created&#39;) def _init_logger(self): logger = logging.getLogger(__name__) logger.setLevel(logging.DEBUG) stdout_handler = logging.StreamHandler() stdout_handler.setLevel(logging.DEBUG) stdout_handler.setFormatter(logging.Formatter(&#39;%(levelname)8s | %(message)s&#39;)) logger.addHandler(stdout_handler) return logger def start(self): try: while True: time.sleep(self.delay) self.logger.info(&#39;Tick&#39;) except KeyboardInterrupt: self.logger.warning(&#39;Keyboard interrupt (SIGINT) received...&#39;) self.stop() def stop(self): self.logger.info(&#39;Cleaning up...&#39;) if os.path.exists(MyService.FIFO): os.close(self.fifo) os.remove(MyService.FIFO) self.logger.info(&#39;Named pipe removed&#39;) else: self.logger.error(&#39;Named pipe not found, nothing to clean up&#39;) sys.exit(0)if __name__ == &#39;__main__&#39;: service = MyService() service.start()If my_service.py is ran in a terminal, we can stop it by hitting Ctrl+C (registered as SIGINT):python test_service.py INFO | MyService instance created INFO | Tick INFO | Tick^C WARNING | Keyboard interrupt (SIGINT) received... INFO | Cleaning up... INFO | Named pipe removedHow to stop the Python service gracefullyIn the previous section we’ve seen that the named pipe is removed as expected if my_service.py is executed in a console. However, if we run it as a systemd service, stopping it via systemctl will result in an improper shutdown of our service: the named pipe is not removed :scream:This happens because, by default, the kill signal sent by systemd when using systemctl stop is SIGTERM, not SIGINT, therefore we cannot catch it as a KeyboardInterrupt.Here are two solutions for this problem.Use SIGINT instead of SIGTERMThe most immediate solution is to instruct systemd to send a SIGINT (registered as a keyboard interrupt) instead of the default SIGTERM. This is done by adding the following line to the [Service] section of the my-service.service unit file:KillSignal=SIGINTThis way, whenever we stop or restart the service with systemctl, the signal sent to kill my_service.py is SIGINT and it is caught by the except block in lines 32-34.Use a SIGTERM handlerThe other solution is to register a signal handler for SIGTERM. For this, we will need to import signal and instruct Python to do something useful when receiving a SIGTERM. We add the following method to the MyService class: def _handle_sigterm(self, sig, frame): self.logger.warning(&#39;SIGTERM received...&#39;) self.stop()Note the two arguments sig and frame: although not used explicitly, they must be present because this is the method that we will register for handling SIGTERM. If they are absent we get a TypeError when a SIGTERM is received. We add the following line to the __init__() method: signal.signal(signal.SIGTERM, self._handle_sigterm)If we check the system log with journalctl -u my-service.service we see the following:juin 26 18:35:17 phantom systemd[1]: Started My test service.juin 26 18:35:17 phantom python[558725]: INFO | MyService instance createdjuin 26 18:35:22 phantom python[558725]: INFO | Tickjuin 26 18:35:27 phantom python[558725]: INFO | Tickjuin 26 18:35:32 phantom python[558725]: WARNING | SIGTERM received...juin 26 18:35:32 phantom python[558725]: INFO | Cleaning up...juin 26 18:35:32 phantom python[558725]: INFO | Named pipe removedjuin 26 18:35:32 phantom systemd[1]: Stopping My test service...juin 26 18:35:32 phantom systemd[1]: test-service.service: Succeeded.juin 26 18:35:32 phantom systemd[1]: Stopped My test service.ConclusionThat’s it! You can now use either of the two methods to stop your Python systemd service gracefully: either tell systemd to kill it with a SIGINT or, better yet, install a custom SIGTERM handler.There’s a caveat with both approaches if the service launches more than one process. The systemd.kill man page explains that by default (when KillMode=control-group) all the processes launched by the unit file will receive SIGTERM (or SIGINT if we use KillSignal=SIGINT as explained here). However, if they fail to stop, they will be knocked-out with SIGKILL. In such situations, one should be extra-careful with proper shutdown and cleanup.Further reading systemd.service man page systemd.unit man page Anatomy of a systemd unit file systemd.kill man page" }, { "title": "How to fix Python logger printing the same entry multiple times", "url": "/posts/fix-python-logger-printing-same-entry-multiple-times/", "categories": "Python, logging", "tags": "python, logging", "date": "2021-06-24 00:00:00 +0200", "snippet": "The previous post explained how to get a simple colored formatter for your custom logger using the Python logging module. This one explains why a logger may print the same record multiple times, and how to fix this.The scenarioLet us suppose you already have the logger from the previous post up and running. Now, the idea is to share it across several modules and/or classes.Suppose your logger is defined in logger.py as follows:import loggingimport datetimedef get_logger(): # Create custom logger logging all five levels logger = logging.getLogger(__name__) logger.setLevel(logging.DEBUG) # Define format for logs fmt = &#39;%(asctime)s | %(levelname)8s | %(filename)s:%(lineno)2d | %(message)s&#39; # Create stdout handler for logging to the console (logs all five levels) stdout_handler = logging.StreamHandler() stdout_handler.setLevel(logging.DEBUG) stdout_handler.setFormatter(CustomFormatter(fmt)) # Create file handler for logging to a file (logs all five levels) today = datetime.date.today() file_handler = logging.FileHandler(&#39;my_app_{}.log&#39;.format(today.strftime(&#39;%Y_%m_%d&#39;))) file_handler.setLevel(logging.DEBUG) file_handler.setFormatter(logging.Formatter(fmt)) # Add both handlers to the logger logger.addHandler(stdout_handler) logger.addHandler(file_handler) return loggerSuppose you also have a file called module.py where you define three classes, A, B, and C, each one using the same logger:from logger import get_loggerclass A: def __init__(self): self.logger = get_logger() self.logger.warning(&#39;This is from class A&#39;)class B: def __init__(self): self.logger = get_logger() self.logger.warning(&#39;This is from class B&#39;)class C: def __init__(self): self.logger = get_logger() self.logger.warning(&#39;This is from class C&#39;)def main(): a = A() b = B() c = C() if __name__ == &#39;__main__&#39;: main()The problemThe problem is immediately apparent when running module.py:2021-06-24 00:38:02,055 | WARNING | module.py: 7 | This is from class A2021-06-24 00:38:02,055 | WARNING | module.py:13 | This is from class B2021-06-24 00:38:02,055 | WARNING | module.py:13 | This is from class B2021-06-24 00:38:02,055 | WARNING | module.py:19 | This is from class C2021-06-24 00:38:02,055 | WARNING | module.py:19 | This is from class C2021-06-24 00:38:02,055 | WARNING | module.py:19 | This is from class CInstead of one log record for each of the three classes, we get one for class A as expected, but two for class B and three for class C. :confounded:Why does this happen?The logging documentation ensures us that logging.getLogger() returns the same logger instance each time this function is called: All calls to this function with a given name return the same logger instance. This means that logger instances never need to be passed between different parts of an application.So why does this happen? The answer is that although we get the same logger, each time we call our get_logger() function from logger.py we are actually attaching distinct handlers to it.Two solutionsDon’t worry, there are two fixes for this problem. In both cases we get only one printed line per record, as expected:2021-06-24 00:51:40,057 | WARNING | module.py: 7 | This is from class A2021-06-24 00:51:40,057 | WARNING | module.py:13 | This is from class B2021-06-24 00:51:40,057 | WARNING | module.py:19 | This is from class CImport the same logger every timeWe can simply create the logger in logger.py and import it directly in our module, without ever having to call get_logger(). Here is how logger.py changes:import loggingimport datetimedef get_logger(): ... return loggerlogger = get_logger()Everything is just as before, except that we create the logger in logger.py (it’s a global variable, yes, I know).And here is how module.py changes:from logger import loggerclass A: def __init__(self): self.logger = logger self.logger.warning(&#39;This is from class A&#39;)class B: def __init__(self): self.logger = logger self.logger.warning(&#39;This is from class B&#39;)class C: def __init__(self): self.logger = logger self.logger.warning(&#39;This is from class C&#39;)def main(): a = A() b = B() c = C()if __name__ == &#39;__main__&#39;: main()We just use the same variable in each of the three classes and the problem goes away, since no unnecessary handlers are created. However, this solution is not ideal since it involves (potentially many) modifications, and furthermore we can’t be sure that in two months from now we’ll still remember that we were not supposed to call get_logger() directly.Check if handlers are presentThe best solution is to check whether any handlers are already attached before adding them to the logger. This fix only involves changing logging.py:import loggingimport datetimedef get_logger(): ... if not logger.hasHandlers(): logger.addHandler(stdout_handler) logger.addHandler(file_handler) return loggerProblem fixed. Happy logging!Further reading logging (Python documentation) Python logging tutorial at Real Python" }, { "title": "Make your own custom color formatter with Python logging", "url": "/posts/make-your-own-custom-color-formatter-with-python-logging/", "categories": "Python, logging, color", "tags": "python, logging, formatter, ansi codes", "date": "2021-06-23 01:00:00 +0200", "snippet": "LoggingThere comes a time in the life of a Python package when proper logs beat print()ing to standard output :smiley: The standard Python library offers the versatile logging module, and if that does not fit your needs there’s this elegant package called loguru. In this article I will only be addressing the standard library logging module.This tutorial explains how to get up and running with logging. You basically have the choice between the basic logging configuration and creating your own custom logger, more easily adapted to meet your specific requirements.The scenarioLet us suppose you need to log both to standard output and to a file. Furthermore, you want your console output to be colored. If your intention is to avoid bringing new dependencies to your project (otherwise you’d use loguru, or at the very least colorama), you can do this with a bare-bones custom logging.Formatter class and with ANSI escape codes. Sounds fun? Let’s dive right in.The loggerHere is what your logger might look like:import loggingimport datetime# Create custom logger logging all five levelslogger = logging.getLogger(__name__)logger.setLevel(logging.DEBUG)# Define format for logsfmt = &#39;%(asctime)s | %(levelname)8s | %(message)s&#39;# Create stdout handler for logging to the console (logs all five levels)stdout_handler = logging.StreamHandler()stdout_handler.setLevel(logging.DEBUG)stdout_handler.setFormatter(CustomFormatter(fmt))# Create file handler for logging to a file (logs all five levels)today = datetime.date.today()file_handler = logging.FileHandler(&#39;my_app_{}.log&#39;.format(today.strftime(&#39;%Y_%m_%d&#39;)))file_handler.setLevel(logging.DEBUG)file_handler.setFormatter(logging.Formatter(fmt))# Add both handlers to the loggerlogger.addHandler(stdout_handler)logger.addHandler(file_handler)First, we create a custom logger (line 5) and set it to log everything (line 6, from debug through critical messages).Every log record should display the time and date, the message level and the message (line 9). Notice that we align the message level on 8 characters (this way the five possible strings for levelname, namely DEBUG, INFO, WARNING, ERROR and CRITICAL are all right-aligned).Next, we set up two handlers, one for console output (lines 12-14) and the other one for logging to a file (lines 17-20). Both handlers log all five levels of messages and both use the log format we’ve just discussed. The file handler creates a new log file every day and names it appropriately (lines 17-18). However, the console handler should have the ability to print every level in a distinct color, which is why we will be using the CustomFormatter class presented below.Finally, in lines 23-24, we add the two handlers to our logger and we’re ready to go.A custom color formatterFor building our own custom formatter, we will extend the logging.Formatter class, give it the log format we want, and instruct it to print out each message level in a distinct color. ANSI escape codes for 8-color, 16-color and 256-color terminals may be found here.Here is how my custom color formatter looks like:class CustomFormatter(logging.Formatter): &quot;&quot;&quot;Logging colored formatter, adapted from https://stackoverflow.com/a/56944256/3638629&quot;&quot;&quot; grey = &#39;\\x1b[38;21m&#39; blue = &#39;\\x1b[38;5;39m&#39; yellow = &#39;\\x1b[38;5;226m&#39; red = &#39;\\x1b[38;5;196m&#39; bold_red = &#39;\\x1b[31;1m&#39; reset = &#39;\\x1b[0m&#39; def __init__(self, fmt): super().__init__() self.fmt = fmt self.FORMATS = { logging.DEBUG: self.grey + self.fmt + self.reset, logging.INFO: self.blue + self.fmt + self.reset, logging.WARNING: self.yellow + self.fmt + self.reset, logging.ERROR: self.red + self.fmt + self.reset, logging.CRITICAL: self.bold_red + self.fmt + self.reset } def format(self, record): log_fmt = self.FORMATS.get(record.levelno) formatter = logging.Formatter(log_fmt) return formatter.format(record)And here it is in practice:logger.debug(&#39;This is a debug-level message&#39;)logger.info(&#39;This is an info-level message&#39;)logger.warning(&#39;This is a warning-level message&#39;)logger.error(&#39;This is an error-level message&#39;)logger.critical(&#39;This is a critical-level message&#39;)The ANSI escape codes can obviously be substituted with colorama, if extra dependencies are not an issue.Further reading logging (Python documentation) Python logging tutorial at Real Python ANSI escape codes for colored terminal output" }, { "title": "Autofocus of the Logitech C920 webcam in Linux", "url": "/posts/autofocus-of-the-logitech-c920-webcam-in-linux/", "categories": "Linux, webcam", "tags": "linux, webcam", "date": "2021-02-26 22:43:00 +0100", "snippet": "In a previous post I wrote about how I set up my webcam on Linux. It turned out it was actually suffering from random disconnects which made it very unreliable for professional video calls. I also couldn’t get more than 0.5 fps if I recorded with it, so I switched to the (very expensive for what it’s worth) Logitech C920 HD Pro.Too expensiveThe Logitech C920 does have its advantages: It works on Linux out of the box It doesn’t seem to randomly disconnect (so far) Allows recording 1080p at 30 fpsBut apart form that I actually find its video sensor inferior to that of the cheap Chinese webcam: The contrast is off no matter what I do The colors seem artificial (although with enough tuning of the saturation and white balance temperature you can get something decent) The viewing angle is large, not extra largeIt also lacks some features with respect to the cheap Chinese webcam: It doesn’t swivel (if you want to rotate it, you have to rotate your screen) It doesn’t come with a privacy shutter It doesn’t come with a tripodBut I guess this is the “package” you get when buying into a “reputable” brand like Logitech… anyway, I digress. The real issue is…Bad autofocusThe autofocus on this webcam is horrible! I did myself a favor and promptly turned it off. With the v4l-utils package installed, do this (assuming your Logitech C920 is /dev/video0):v4l2-ctl -d /dev/video0 --set-ctrl=focus_auto=0v4l2-ctl -d /dev/video0 --set-ctrl=focus_absolute=0Add the above lines to a script to run automatically each time you log in (put it in /etc/profile or add it as one of the scripts to run in /etc/profile.d/). If the image is not sharp enough, you can also alter the sharpness parameter (see below).Other settingsTo see the other settings that are available for the Logitech C920 webcam:v4l2-ctl -d /dev/video0 --list-ctrls-menusYou can manually tune the brightness, contrast, saturation, white balance temperature, sharpness, exposure and gain settings with v4l2-ctl. The pan and tilt don’t seem to work.If you need a graphical user interface, you can use guvcview.ConclusionAll in all it’s not a bad webcam. I just wish the sensor was as powerful as the one in the Chinese webcam but without its stability (random disconnect) issue." }, { "title": "Mercurial branch how-to", "url": "/posts/mercurial-branch-howto/", "categories": "Tools, Mercurial", "tags": "mercurial, version control", "date": "2021-02-17 23:30:00 +0100", "snippet": "This is a quick how-to on named branches in Mercurial. Be sure to check out the official documentation on branches on the Mercurial wiki, the visual explanation on the different types of branches by Steve Losh and the named branches tutorial by Mark Heath first.So now that you concluded that clones and bookmarks are not the solution to your branching problem, you want to create a named branch. For the purpose of this example, assume the new branch is called dev.Creating a named branchIf you want to branch from a previous changeset, update to that revision number first. Suppose you’re at revision 10 and you want to branch from revision 5:hg up 5Now you’re still on the default branch but you just went back in time from revision 10 to revision 5.It’s time to create the new dev branch. It will be created from the current changeset if you haven’t used hg up as above:hg branch devWhen a branch is created, it automatically becomes the current one. You can check this if you want with hg branch.The list of existing branches is viewable with hg branches. However, the dev branch will not be listed there as long as there are no commits to it. So change something, then commit. Now hg log shows your new commit as being on the dev branch.Switching branchesIf you want to go back to the default branch, use:hg up defaultChange something there, commit, then come back to the dev branch:hg up devWhat happens if you want to switch branches when your current branch contains uncommitted changes? Mercurial does not allow this. You can either use the shelve extension or create a patch. I’m going with the patch solution. If we’re on the dev branch with uncommitted changes, here is how to create a patch before switching to the default branch:hg diff &amp;gt; dev.patchIn order to switch, we must tell Mercurial to discard uncommitted changes (-C), which is OK since we’ve already saved them as dev.patch:hg up -C defaultWhen going back from the default to the dev branch, we need to import the uncommitted changes:hg up devhg import --no-commit dev.patchViewing the differencesTo view the differences between two branches branch1 and branch2, use:hg diff -r branch1:branch2If we only have two branches (default and dev in our example), we can exclude the current branch. Suppose we’re on the dev branch and we want to see the differences with respect to default:hg diff -r defaultIf we are only interested in differences between two branches for a particular file:hg diff -r branch1:branch2 fileFor our example, we are on the dev branch and we want to see how file differs with respect to the same file in the default branch:hg diff -r default fileThat’s all! Happy branching!" }, { "title": "Fix the look of KDE apps in other desktop environments", "url": "/posts/fix-kde-theme-in-xfce-gnome/", "categories": "Linux, desktop environment", "tags": "xfce, kde, qt5", "date": "2021-02-15 19:30:00 +0100", "snippet": "The problemEver re-installed your OS but kept your /home partition and got to experience some weird visual artifacts? If your desktop environment is XFCE for instance and your KDE apps (such as okular, konsole, spectacle or gwenview) look bad, then you’d normally solve this with Kvantum Manager. Kvantum is used for styling Qt apps. It worked great out of the box for the Manjaro clean installs I’ve done so far, but the same cannot be said about the latest (re-) install where I just kept my /home partition and installed Manjaro onto a brand new SSD.The solutionAgain, out of the box, Kvantum Manager works great… until it doesn’t. I might have forgotten to install a particular Qt theme. Instead of tracking down that particular package, an alternative solution is to install qt5ct. As explained on this Arch Linux wiki page, qt5ct provides another way to style KDE apps from within a desktop environment other than KDE. So this should work for XFCE, as well as Gnome and what have you.Just install it:sudo pacman -S qt5ctNext, you need to make an environment variable available globally to specify that it is qt5ct that should be used as the Qt platform abstraction. This can be achieved by adding the following line to /etc/profile:export QT_QPA_PLATFORMTHEME=qt5ctNow launch qt5ct and select the desired theme.Log out and log in again and your KDE apps should now be better integrated visually into your non-KDE desktop environment." }, { "title": "Learning Unreal Engine 4&amp;#58; Dungeon prison breakout", "url": "/posts/learning-ue4-dungeon-prison-breakout/", "categories": "Unreal Engine 4, learning", "tags": "ue4, game design", "date": "2021-01-28 19:00:00 +0100", "snippet": "The whole Mass Effect trilogy was made using Unreal Engine 3! ‘Nuff said! I guess I’ll belearning Unreal Engine 4, then :grin: No, wait. The real reason is that, unlike Unity, UE4 runs on Linux. But none of this would matter if I wasn’t dead curious about game engines to start off, which I am.I chose to embark on this journey with the Udemy Unreal Engine C++ Developer course by Ben Tristem and the GameDev.tv team. Of course this is just to get one’s fingers dipped. In order to have a better understanding of game development, you’d need a lot more than just a single course: solid grasp on game design principles and game mechanics level design specific to 3D games: 3D modelling and sculpting (e.g. Blender), 3D environments specific to Unreal Engine 4: be able to use both C++ and blueprints character animation visual and sound effectsAnd if you ever plan on going the solo route, on top of those technical skills you’d need to create and manage your indie game dev studio, as well as to effectively market your games.As far as I’m concerned, I have zero intention of going that way. I’m just curious about game development in general and fascinated by what can be achieved. After so much time of dissecting how video games are built, I just thought I’d take a crack at building something myself.Enter UE4Despite being so powerful and versatile, it is alas very poorly documented! But since I’m dead set on using Linux and I refuse to learn Godot as my first game engine, Unreal Engine 4 is my only option. I’ll figure it out along the way, right? …right?I went more than halfway through the Udemy course when I got my first real challenge: using what I had just learned to make an actually playable demo level. So what exactly had I learned? The course starts off by explaining how to set up Unreal Engine 4. Then a cursory introduction to C++ takes place in the form of speeding you through writing a simple console application. The first actual contact with the Unreal Editor is through a console-based game that is actually implemented in a virtual terminal inside a 3D environment. “Building escape”. This is the chapter for which I made the demo below. It’s also the real introductory chapter to Unreal Engine 4, teaching you: The basics of Unreal classes and components What static meshes are How to build basic geometry using BSP How to set up basic lighting What collision is How to create a grab/release component for the default pawn How to create a basic actor component with a precise role (e.g. for opening and closing a door) How to add basic sound effects Building escape final challengeThe Udemy course then sends you off spiraling into the dark abyss, giving you the challenge to create an actual playable level, as polished as you want it to be. Challenge accepted!Game designThe level is supposed to have the player solve a series of puzzles by manipulating objects in the game environment in order to escape an enclosed space. My choice of asset pack went with the Medieval Dungeon pack from the Unreal Marketplace. This resulted in creating a sadistic dungeon prison environment from which the player must free herself.The player can exit the dungeon by placing four “magic cubes” in the appropriate locations, as well as a “magic crystal”. When all of the five items are in place, the dungeon doors open and the game is over.My demo levelHere is the Youtube link to the playable level: Level designBelow is a simplified level design document for the dungeon prison breakout level (most of the props are not shown). The player starts in the prison cell located in the bottom right corner of the map:With the help of this document, I will attempt to explain how the level plays. In order to get the cubes and the crystal, the player goes through a certain number of interactions: In the prison cell where the player first finds herself, two wooden planks must be moved to uncover a magic cube. This magic cube activates a pressure plate that opens the gate of the prison cell. A magic cube is out in the open in the “main hall”, where four statues have empty statue stands in front of them; when a cube is placed on the correct empty statue stand, the corresponding statue is “activated” with a sound, a particle effect and a light source. Another cube can be found inside a wooden coffin in the torture hall, right in front of the prison cells. In the memorial chamber (accessible through the main hall), a ceramic pot may be moved in order to uncover a key. The key opens one of the remaining prison cells. Entering this prison cell, a big stone can be moved in order to gain access to the adjacent cell. From the adjacent cell the player climbs on a platform that allows a jump to the final prison cell. In this last prison cell, two small stones can be used to activate the pressure plate that opens the gate of the prison cell, and a magic cube may be dragged outside of the cell along the way. The big stone in the cell that can be opened with the key can be exchanged with the cube on the pressure plate in the player’s cell. Now all the four cubes should be in place on the initially empty statue stands in front of the statues in the main hall. The last key to the puzzle is a crystal that must be placed on a fifth statue stand in the middle of the four stands with the magic cubes. The crystal can be accessed by removing the stone coffin lids in the mortuary chamber, accessible through the main hall.My learning challengesWhile building this level I came across some interesting challenges. Most of them involve blueprints, an alien visual scripting language designed to torment the souls of UE4 newbies. At times it’s frustrating as I feel like I have no idea what I’m doing :stuck_out_tongue_winking_eye:Outline for interactive itemsI wanted to guide the player by giving her a visual cue for objects that she can interact with. The idea is to use a custom depth stencil value and a post-processing volume. Every interactive object has its own blueprint. There are actually two distinct custom stencil values that I use, because I wanted to make the key really stand out since it is very small. I used this tutorial to get started.Flexible C++ components for doorsI wanted to have doors open and close according to a variety of conditions and behave a certain number of ways, for example: Once open, some doors must remain that way (the gate to the prison cell in the middle). Some doors are activated by the player pawn (the doors to the mortuary and the memorial chambers). Some doors are activated by another actor (the key for the gate to the prison cell in the middle). Some doors are activated by the total mass on the pressure plate (the gate to the player’s prison cell). Some doors are activated by the presence of several actors in a single trigger volume (the gate to the last prison cell). Some doors are activated by the presence of several actors in several trigger volumes (the gates for the dungeon’s exit need the four cubes and the crystal in place).I achieved this by exposing many variables to the Unreal Editor and by adopting a modular class design. The base class implements basic behavior (opens and closes a door at a given angle and speed). It is extended by two derived classes that describe how certain actors are expected to trigger the conditions for controlling the door.First contact with particle systemsI created a very simple particle system following this tutorial. Its role is to emphasize that the cubes and the crystal have been placed in the proper locations. The particle system is handled by a C++ component that I attach to the static meshes that must be emphasized. In order to activate the particle system when the right conditions are met, I struggled with a few nasty crashes before I understood that setting the location of the particle system (SetRelativeLocation()) can only be done in BeginPlay(), not in the component’s constructor, since at that point the owner’s location is unknown.Playing a sound when an item is droppedInitially I had naively added two audio components for items that the player can interact with: one was played on grab, the other on release. However, playing a sound when the object is released is not the same as when it hits the floor. From this tutorial I learned how to make the sound play only when a hit event (collision) occurs. But this wasn’t the full answer to my problem, since every time the player moved around with an item attached to the physics handle and the item collided with something in the environment, the sound would play. I ended up exposing a C++ variable in the grab/release component to the blueprint editor in order to check which actor is currently attached to the physics handle. In the blueprint I implemented the desired behavior: if a collision is registered for an actor and if that actor is no longer attached to the physics handle of the player pawn, only then play the “drop” sound. It’s not perfect but it was an interesting exercise!Resources used Models/meshes: The Medieval Dungeon asset pack from the Epic Marketplace The mossy stone mesh and material from Quixel Surfaces (from Quixel): Castle wall Marble detail Sounds (from Freesound): Ambient track: https://freesound.org/people/DrMinky/sounds/166187/ Pick up sound used for cubes, rocks etc.: https://freesound.org/people/Mediaman57/sounds/347149/ Drop sound used for cubes, rocks etc.: https://freesound.org/people/Bird_man/sounds/275160/ Drop sound used for stone coffin lids: https://freesound.org/people/Robinhood76/sounds/503554/ Drop sound for planks and wooden coffin lid: https://freesound.org/people/kingsrow/sounds/194692/ Shattered cups sound: https://freesound.org/people/tezzza/sounds/21612/ Ceramic click sound: https://freesound.org/people/Mafon2/sounds/371278/ Key pick up sound: https://freesound.org/people/BeezleFM/sounds/512137/ Key drop sound: https://freesound.org/people/Kyanite_/sounds/432913/ Crystal pick up sound: https://freesound.org/people/DWOBoyle/sounds/474179/ Magic activation sound: https://freesound.org/people/kneekoo/sounds/548497/ Wooden door open sound: https://freesound.org/people/joedeshon/sounds/117416/ Wooden door close sound: https://freesound.org/people/joedeshon/sounds/117415/ Metal door open sound: https://freesound.org/people/LittleRobotSoundFactory/sounds/270461/ Metal door close sound: https://freesound.org/people/newagesoup/sounds/339369/ ConclusionCompleting my “dungeon prison breakout” level was a very interesting and challenging journey. I’ve come a long way since I enrolled in this course, but there are so many things I’m yet to discover. I leave this little project behind me with a few small regrets: The landscape outside the dungeon: that’s not a landscape, it’s an abomination. I need to learn how to do this properly, how to sculpt the environment, use brushes, add foliage and so on. Destructible meshes cannot be moved, so if I wanted the ceramic pot to break when thrown I’d need to hot-swap the movable mesh with the destructible mesh when the player releases it from the physics handle. I’m not sure yet how to do that. The main hall feels empty (it’s too big for the props that I’ve sparsely placed in the level). The particle system is ugly. The lighting is fake. The shadows of the ceiling chandeliers should not be seen on the floor. Some volumetric fog could add to the general creepy feeling I wanted the dungeon to convey.But it’s time to move on with the course. “Toon Tanks”, here I come!" }, { "title": "Download UE4 assets from the Epic Games Marketplace using Linux", "url": "/posts/download-from-unreal-engine-4-marketplace-in-linux/", "categories": "Unreal Engine 4, assets", "tags": "linux, ue4", "date": "2020-12-15 21:00:00 +0100", "snippet": "It is an extremely frustrating experience to have an Epic Games account (for Unreal Engine 4) but not be able to download assets from the Marketplace because… Linux. :angry:The problem with Linux and the UE4 MarketplaceThe Unreal Engine itself is technically supported on Linux: while you cannot download a pre-packaged version (unless your favorite distro maintainers are really cool), you can link your GitHub account to your Epic Games account in order to gain read access to the Unreal Engine 4 repository. From there, you can clone the UE4 release that you need and compile it from source.But figure this: your Epic Games account also gives you access to the Unreal Engine Marketplace. You can use your browser to connect, browse the marketplace and get free assets or buy non-free ones. Therein lies the problem, you see. You can only “link” them to your account. You cannot download those assets on Linux using the browser. The download button tries to open the UE4 Editor and since the Linux version does not come with the marketplace bundled, you won’t be able to download those assets.You can build your UE4 projects on Linux. You just can’t get assets for them from the Epic Games Marketplace… on Linux.There is a solutionAnd here is where Lutris comes to the rescue! Lutris is an open-source platform for playing games on Linux. Among the many games that you can download in their Windows version to install in Linux through Wine (provided that you have them in your Steam or GOG libraries), you can also download certain game store clients such as Origin or Epic Games.Epic Games launcher through LutrisInstall Lutris and launch it from a Python 3.8+ environment. Alternatively, ensure the default Python version is 3.8+. This is very important, because if you use an older Python version the install will seemingly complete but the Epic Games launcher will not exist.In Lutris, search for “epic games” and install the Epic Games Store. Once finished, check that you have your EpicGamesLauncher.exe executable in your Epic Games install path. For this example, let’s suppose you installed the Epic Games Store in ~/Programs/epic-games-store. Then make sure that ~/Programs/epic-games-store/drive_c/Program\\ Files\\ \\(x86\\)/Epic\\ Games/Launcher/Portal/Binaries/Win32/EpicGamesLauncher.exe exists.You don’t need to install the Windows version of the Unreal Engine through Wine/Lutris in order to download assets, you just need a UE4 project. And what better way to get your assets imported directly into your Linux projects than to symlink your Unreal Projects directory to the virtual Wine file system?Here is how to do it. Suppose you store your Linux UE4 projects in ~/Documents/Unreal Projects. You just need to create a link from your hypothetical Windows My Documents to your actual Unreal Projects folder in Linux:ln -sf \\ ~/Documents/Unreal\\ Projects \\ ~/Programs/epic-games-store/drive_c/users/YOUR_USERNAME/My\\ Documents/Unreal\\ Projects(Don’t forget to replace YOUR_USERNAME with your user name and to backslash-escape spaces in path names.)Completely close the Epic Games Store and Lutris and launch them again. Connect to your Epic Games account, then go to Unreal Engine &amp;gt; Library. Your downloadable assets are in your Vault (see below):Now select an asset from the Vault and click “Add to project”. A new window will open asking you to which project to add the asset, but your projects might not be visible. Select the “Show all projects” checkbox, then select your project and from the drop-down list select the version of the engine for that particular project:Now you’re all set! The asset pack is downloaded to the Content/ folder of your UE4 project." }, { "title": "Definitely not the definitive guide to Mercurial merge", "url": "/posts/simple-mercurial-merge/", "categories": "Tools, Mercurial", "tags": "mercurial, version control", "date": "2020-12-12 00:00:00 +0100", "snippet": "Oh no, not another how to!Sure, there is a ton of documentation out there when it comes to version control. Take Mercurial for instance, there are excellent guides out there on merging changes.But sometimes I just need a very simple workflow to merge changes in the same repo between two machines. Enter bad memory into the game and the only solution is this kind of quick and dirty how to.The calm before the stormMy ~/.hgrc contains the option to let me merge manually instead of using third-party tools. This way, conflicts are signaled between &amp;lt;&amp;lt;&amp;lt; and &amp;gt;&amp;gt;&amp;gt; symbols, just like in Git. This is the option in question:[ui]merge=internal:mergeAll hell breaks looseNow just merrily do your pull and… uh-oh:searching for changesadding changesetsadding manifestsadding file changesadded 1 changesets with 1 changes to 1 files (+1 heads)new changesets a3256593884f (1 drafts)(run &#39;hg heads&#39; to see heads, &#39;hg merge&#39; to merge)Now the repo has two heads that can be viewed with hg heads. From there, select the head to merge with. For example, suppose the tip of the working copy is changeset 8, and the one pulled from remote is 9. In this case, you’d merge with revision 9:hg merge -r 9In return, you might get something like this if there are any conflicts:merging my_filewarning: conflicts while merging my_file! (edit, then use &#39;hg resolve --mark&#39;)0 files updated, 0 files merged, 0 files removed, 1 files unresolveduse &#39;hg resolve&#39; to retry unresolved file merges or &#39;hg merge --abort&#39; to abandonOpen the troublesome my_file and resolve the conflict. Let’s say it looks like this:This is my file&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt; working copyThis was edited locally=======This was edited in upstream&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; merge revSuppose we want to discard the local change. Then we’d edit the file above like this:This is my fileThis was edited in upstreamAfter rain comes sunshineNow we tell hg that everything is fine:hg resolve --markWe commit the merge:hg commit -m &quot;merged&quot;And we’re done!" }, { "title": "How to squash two non-consecutive commits in Mercurial", "url": "/posts/how-to-squash-two-non-consecutive-commits-in-mercurial/", "categories": "Tools, Mercurial", "tags": "mercurial, version control", "date": "2020-12-11 18:15:00 +0100", "snippet": "The problemSuppose you want to combine two commits in Mercurial. However, they are not consecutive. What to do? histedit to the rescue!Suppose hg log shows that your last 4 revisions are the following:3: more stuff on Y2: stuff on X1: stuff on Y0: stuff on ZAnd suppose you want to squash what you commited on Y into a single revision, like this:2: stuff + more stuff on Y1: stuff on X0: stuff on ZReorder revisionsThe first step is to reorder the revision history in order to make the revisions to be squashed become consecutive (stuff on Y and more stuff on Y):hg histeditSelect the revision you want to move (1: stuff on Y) and move it down (press capital J). Why down? Well, hg log is reverse chronological so the latest revision on top, while hg histedit is chronological so the latest revision is at the bottom. Confusing, I know. Just commit (press c) and now your hg log should show the reordered revisions:3: more stuff on Y2: stuff on Y1: stuff on X0: stuff on ZSquash the two commitsSince the revisions on Y are now consecutive, we can finally “fold” them (they might have called it “squash”, it would have been more intuitive). However, we must tell Mercurial from which revision to start: we want revision number 2 in the log above, since it is the one on top of which the other one will be “folded”:hg histedit 2Then select revision 3 (more stuff on Y) and select “fold” (press f). Commit (press c) and edit the commit message (e.g., stuff + more stuff on Y) and you should now have the hg log that you wanted all along:2: stuff + more stuff on Y1: stuff on X0: stuff on Z" }, { "title": "Solve audio issues on Lenovo Thinkpad T14s", "url": "/posts/solve-audio-issues-on-lenovo-thinkpad-t14s/", "categories": "Linux, audio", "tags": "linux, manjaro, audio", "date": "2020-12-10 01:00:00 +0100", "snippet": "I spent more than an hour on this issue. I just got a Lenovo T14s and my sound card was not detected with alsa-lib 1.2.4-3 on Manjaro Linux. I was getting a “dummy output” in PulseAudio’s Volume Control (pavucontrol).After trying various things, what solved the problem was installing sof-firmware and rebooting. Whew!" }, { "title": "How to migrate user settings and data between Linux machines on a LAN", "url": "/posts/migrate-user-settings-between-linux-machines/", "categories": "Linux, command line", "tags": "linux, manjaro, migration", "date": "2020-12-09 20:26:00 +0100", "snippet": "Ever had to set up a new Linux machine (for example your work laptop), and wanted to import the exact same settings that you use on your main (or home) machine? Maybe some data as well?Some steps of this guide are Manjaro Linux (and, by extension, Arch Linux) specific, but some of the general ideas could be transplanted to other distros as well. Your mileage may vary with respect to my specific setup and needs. Some of the steps below assume the two machines are in a local area network (LAN).Here is what we will be covering: Using the same mouse and keyboard to control the two machines, provided they are conveniently placed on a desk side by side. Setting up OpenSSH server on the new machine to be able to copy files from the “old” one. Making a list of packages installed on the new machine that we also need on the new machine. This can save a lot of typing! Copying user settings from the old to the new machine.In this post, let’s say we want to migrate settings and files from a machine with hostname desktop (LAN IP 192.168.1.28) to another machine with hostname laptop (LAN IP 192.168.1.24).Share mouse and keyboardFirst things first. If we’re talking about a LAN and the two machines are side by side on a single desk, it’s handy to use the “main” one’s keyboard and mouse to control both. For this you can use synergy. After installing Synergy on both machines, the steps are as follows: Make each machine know the other’s name. It’s not mandatory but it’s more user-friendly to connect to desktop than to 192.168.1.28. To do this, edit each machine’s /etc/hosts file by adding a line with the other’s machine LAN IP followed by its hostname. For example, on the main desktop machine (IP 192.168.1.28) I would add 192.168.1.24 laptop to /etc/hosts. To get the LAN IP, examine the output of ip addr (or ifconfig for other Linux distros). Edit /etc/synergy.conf on the main (desktop) machine. You need to tell it where the other machine is, physically. I have my laptop to the left of my desktop, so my /etc/synergy.conf file looks like this: section: screens desktop: laptop: end section: links desktop: left = laptop laptop: right = desktop end Start the Synergy server on the main machine (desktop in my case) by running synergys. This is the machine whose mouse and keyboard will control the other. Start the Synergy client on the new machine (laptop in my case) by running synergyc desktop. This means that this machine will connect its Synergy client to the Synergy server running on dekstop (where the Synergy server must already be running).That’s all. Now you can use only one mouse and keyboard for both machines.Copy files to new machineOnce keyboard and mouse input are available through your main device on the new machine, you can start copying files comfortably (i.e. without being endangered by scoliosis). OpenSSH server needs to be installed on the new machine first, though. In Manjaro and Arch Linux:alex@laptop$ sudo pacman -S opensshNow to configure it, edit /etc/ssh/sshd_config on the new machine (laptop) as follows (replace the ListenAddress with the LAN IP of your new machine):ListenAddress 192.168.1.24ListenAddress 127.0.0.1PermitRootLogin noMaxAuthTries 3I also like to enable logging such that I can check my SSH logs with journalctl -u sshd. For this, edit /etc/ssh/sshd_config to add the following (or uncomment these lines under the Logging section):SyslogFacility AUTHLogLevel INFOThen you need to start OpenSSH server on the new machine:alex@laptop$ sudo systemctl start sshd.serviceThe first time you connect to the new machine, you will be asked to check the host fingerprint.To copy files from the main to the new machine, use scp.alex@desktop$ scp ~/doc.txt alex@laptop:~If you want to copy a directory over to the new machine, just use the -r switch with scp:alex@desktop$ scp -r wallpapers/ alex@laptop:~/PicturesInstall the same packages on the new machineBefore starting any package install, it is best to update the mirror list with the fastest mirrors. On the new machine, run:alex@laptop$ sudo pacman-mirrors -f 10This will determine the 10 fastest mirrors and update /etc/pacman.d/mirrorlist.Now generate the list of installed software on the old machine and copy it over to the new machine:alex@desktop$ pacman -Qqen &amp;gt; pkglist.txtalex@desktop$ scp pkglist.txt alex@laptop:~Be sure to remove what you don’t need, for example NVidia drivers if the new machine does not have an NVidia graphics card. (In my case, the original list contained 399 packages, of which I only wanted to install 61 to the new machine.)On the new machine, install the packages listed in ~/pkglist.txt:alex@laptop$ sudo pacman -S --needed - &amp;lt; ~/pkglist.txt If, by chance, you have installed KDE’s Baloo file indexer as a dependency, do yourself a favor and disable that monstrosity:alex@laptop$ balooctl disableCopy user settings over to the new machineIf you use the same desktop environment on both machines (this example assumes we’re using XFCE), you can attempt the following method. It is important to replace the files on the new machine from an actual TTY, NOT from the graphic session. First, back up the destination folders on the new machine:alex@laptop$ cp -fr ~/.config/xfce4/ ~/.config/xfce4.bckalex@laptop$ cp -fr ~/.local/share/xfce4 ~/.local/share/xfce4.bckThen, prepare a temporary folder for the XFCE configuration files. You don’t want to be copying them while XFCE is up and running:alex@laptop$ mkdir ~/tmp/alex@laptop$ mkdir ~/tmp/.config ~/tmp/.local/shareThen, copy them over from the main machine to the temporary folders on the new machine:alex@desktop$ scp -r ~/.config/xfce4/ alex@laptop:~/tmp/.configalex@desktop$ scp -r ~/.local/share/xfce4/ alex@laptop:~/tmp/.local/share/Now log out from the new machine, then open a TTY (Ctrl + Alt + F1, Ctrl + Alt + F2, etc.). From the TTY, first remove the default XFCE configuration, then move the new one in its place. Finally, restart (do a full reboot):alex@laptop$ rm -fr ~/.config/xfce4alex@laptop$ rm -fr ~/.local/share/xfce4alex@laptop$ mv ~/tmp/.config/xfce4 ~/.configalex@laptop$ mv ~/tmp/.local/share/xfce4 ~/.local/sharealex@laptop$ sudo rebootAfter reboot, your old settings should be applied to the new machine (but keep in mind that some adjustments might be necessary). If everything is FUBAR-ed, then just log out, switch to TTY and rename the two xfce4.bck directories to xfce4.ConclusionThis guide for migrating user data and settings might be useful for quickly migrating the most important stuff between two Arch Linux-like distros. Happy set up!" }, { "title": "Prevent screen tearing in Linux using the NVidia driver", "url": "/posts/prevent-screen-tearing-in-linux-nvidia-driver/", "categories": "Linux, video", "tags": "linux, manjaro, nvidia", "date": "2020-12-06 01:00:00 +0100", "snippet": "I spent the whole afternoon for this very easy to fix problem. I needed to install the proprietary NVidia driver instead of the open-source one (because Unreal Engine 4 and because DaVinci Resolve, that’s why). However my desktop was utterly useless afterwards because of an obscenely low refresh rate that was literally making my head spin. The horrible screen tearing had nothing to do with the falsely reported 144 Hz refresh rate of my desktop. The open-source Nvidia driver was actually capable of providing this refresh rate, but not the proprietary NVidia one… out of the box.Worse than all was the fact that this was happening with the latest driver (video-nvidia-455xx) and not many people seemed to have this issue.After spending an extremely frustrating afternoon, I found the solution:You can either add the following line directly to your nvidia.conf file (at /etc/X11/mhwd.d/nvidia.conf in Manjaro Linux) under the Screen section (adjust the resolution and the refresh rate to your screen’s specs):Option &quot;metamodes&quot; &quot;2560x1440_144 +0+0 {ForceFullCompositionPipeline=On}&quot;Or you can launch nvidia-settings as root (because it needs to be able to write the new settings to nvidia.conf) and enable the “Force Full Composition Pipeline” option.(Rant: I don’t know what’s worse, the VLC or the NVidia Settings UI…) Voila. The end." }, { "title": "Getting the most out of your webcam on Linux", "url": "/posts/getting-the-most-out-of-your-webcam-on-linux/", "categories": "Linux, webcam", "tags": "linux, webcam", "date": "2020-12-04 19:38:00 +0100", "snippet": "[UPDATE February 26 2021: This webcam didn’t fare so well after all. I switched to a Logitech C920 after three months due to unacceptable random disconnects.]So… I bought a Chinese webcam. And it’s not that bad, now that it works. See, the first time I plugged it in, dmesg wouldn’t stop complaining:[65184.538621] usb 2-9.5: 3:1: cannot set freq 16000 to ep 0x83Some frequency couldn’t be assigned to something in the webcam’s hardware. End result: my webcam didn’t provide any /dev/video0 device. Not cool.Getting the webcam to work under LinuxI was seriously considering returning it to Amazon, but I first needed to check out whether it worked on Windows. Unsurprisingly, it did. Surprisingly, when Chinese vendors say their device is plug-and-play, what they mean is Plug. Wait for OS to install drivers. Play (eventually). Lesson learned!After making sure the webcam was functional in Windows 7, I rebooted to Linux and, lo and behold, the webcam was recognized with no problems. This means that the Windows drivers must have also initialized the webcam by actually writing a frequency to its registers. Linux was content enough with this change, since I finally obtained what I wanted in dmesg, that is the golden line stating that the camera was finally providing a video device:[77945.854333] input: HD Web Camera: HD Web Camera as /devices/pci0000:00/0000:00:14.0/usb2/2-9/2-9.5/2-9.5:1.0/input/input33Checking the webcam’s videoIt was time to take a look through the webcam’s lens. Instead of firing up a Google Meet call, you can quickly check out how your video looks like with a handy little tool called cheese. It can also be used record videos or take pictures through the camera. However, for some weird reason, when I attempt to record from the webcam with cheese, the video stops after a few seconds and sometimes even VLC cannot read it. See below Recording from webcam for possible solutions.Adjusting the webcam’s videoThe default settings of my webcam were on the overexposed side. You can view and alter these settings using v4l2-ctl which is part of the v4l-utils package:$ v4l2-ctl -d /dev/video0 --list-ctrls brightness 0x00980900 (int) : min=1 max=255 step=1 default=128 value=128 contrast 0x00980901 (int) : min=1 max=255 step=1 default=128 value=128 saturation 0x00980902 (int) : min=1 max=255 step=1 default=128 value=128 hue 0x00980903 (int) : min=0 max=255 step=1 default=128 value=0 white_balance_temperature_auto 0x0098090c (bool) : default=1 value=1I needed to adjust the brightness to 80 and the contrast to 150:$ v4l2-ctl -d /dev/video0 --set-ctrl=brightness=80$ v4l2-ctl -d /dev/video0 --set-ctrl=contrast=150Once you’ve found the settings that work for you, you can save them to a bash script and have your desktop environment execute it on login. For example, save this to ~/bin/setup_webcam.sh:#!/usr/bin/bashv4l2-ctl -d /dev/video0 --set-ctrl=brightness=80v4l2-ctl -d /dev/video0 --set-ctrl=contrast=150Make the script executable:$ chmod +x ~/bin/setup_webcam.shThen add it to your autostart applications. For example in XFCE you would go Settings &amp;gt; Session and Startup &amp;gt; Application Autostart and add a new entry to run the command ~/bin/setup_webcam.sh on login.Checking the webcam’s micSuppose you only wanted to record audio with the webcam’s integrated mic. A fast way to do this from the command line is:arecord -f cd test.wavIf that file comes out as silent when you play it back, it might just be that the microphone is muted or disabled. The XFCE Pulseaudio Volume Control applet (provided by the pavucontrol package) is great for this: Go to Pulseaudio Volume Control &amp;gt; Input Devices and: Ensure the mic volume is at 100%; Enable the “set as fallback” button. Go to Pulseaudio Volume Control &amp;gt; Configuration and make sure your webcam uses an input profile other than “Off” (you might have to test them one by one if unsure).Great, but what if you want to use arecord to capture the output of your soundcard? In this case you’d need to temporarily disable the webcam microphone. First go to Pulseaudio Volume Control &amp;gt; Configuration and select the “Off” input profile for the webcam, then launch arecord as before.To switch back to using the microphone, select the correct input profile for the webcam in the Configuration tab and also enable the “set as fallback” button on the Input Devices tab.Recording desktop with webcam audio and/or videoI haven’t looked too far into this since I think I already found the perfect app for desktop recording: VokoscreenNG, provided by the vokoscreen package. With it, you can record your desktop or part of it, in several ways: without sound and without webcam with sound and without webcam: with sound from the webcam microphone with sound from the sound output device with sound from both without sound and with webcam overlay with sound and with webcam overlay: with sound from the webcam microphone with sound from the sound output device with sound from both …although sound on the recorded video does get to get choppy when using both the webcam mic and the output sound device at the same time.Recording from webcamI thought this was the easiest part of all, but nooo, it can’t be that simple. As I mentioned in the beginning, I cannot record through the webcam with cheese as the video simply freezes. Next, I tried the option of using vlc. With VLC you can go to Media &amp;gt; Open Capture Device… and: select “Video camera” for capture mode specify the video device name (typically, /dev/video0) take down caching to 0 ms in “show more options” select the aspect ratio and the frame rate in “advanced options”Before you can start recording, however, you need to check “advanced controls” under the View menu (this makes the big red record button show up). Yes, the UI/UX in VLC is just horrendous! (In contrast, VokoscreenNG does a really cool job for the interface.)However, when I record through the webcam with VLC, I get unacceptable frame drops. The video is choppier than chopped salad. So, as ugly as it may seem, I rely on mencoder:$ mencoder tv:// -tv driver=v4l2:width=800:height=600:device=/dev/video0:fps=30:forceaudio:alsa:adevice=hw.3,0 -ovc lavc -lavcopts vcodec=mpeg4:vbitrate=1800 -ffourcc xvid -oac mp3lame -lameopts cbr=128 -o output.aviConclusionIn this post I detail the solutions that work best for me and my low-cost webcam, enabling me to make the most of its camera and its integrated mic. Depending on your needs and inclinations, some of the following tools may prove useful: cheese v4l-utils pavucontrol arecord vokoscreen vlc mencoder" }, { "title": "How to check the SSH host key fingerprint", "url": "/posts/how-to-check-the-ssh-host-key-fingerprint/", "categories": "Linux, security", "tags": "linux, ssh", "date": "2020-09-28 01:00:00 +0200", "snippet": "When using SSH to authenticate to a remote machine, password authentication can and should be replaced with SSH key pairs.To generate your public and private SSH key, run:$ ssh-keygen -t rsaEnter file in which to save the key (/home/alex/.ssh/id_rsa):Created directory &#39;/home/alex/.ssh&#39;.Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /home/alex/.ssh/id_rsa.Your public key has been saved in /home/alex/.ssh/id_rsa.pub.You shouldn’t omit the passphrase, as it adds an extra layer of security. Your private key is id_rsa (and is optionally protected by a passphrase) and your private key is id_rsa.pub. Now you just copy over the public key to the remote machine. If the private key on your machine matches the public key on the remote machine, voila, you’ve got yourself a secure connection.All this is fine. However, there’s something that bothers me to no end. I cannot count the number of times I’ve stumbled across this kind of tutorial where authors just blatantly ignore checking whether the host they connect to is indeed the intended one. There’s a message that is displayed the first time you connect to a SSH server, and there’s a reason for this too. It goes something like this: The authenticity of host ‘example.com (11.22.33.44)’ can’t be established. ECDSA key fingerprint is &amp;lt;some long string&amp;gt;.Are you sure you want to continue connecting (yes/no)?The reason behind this message is that the key fingerprint you’re about to accept after due verification is added to your ~/.ssh/known_hosts file. When this fingerprint changes, this might mean something changed on the server side, or that the server has been compromised through a man-in-the-middle attack. It is up to you to ensure you’re always connecting to the machine you think you are connecting to.So how do you check whether the server key fingerprint is valid? You either have access to it physically and run the command below, or you ask the sysadmin to do it for you:for i in /etc/ssh/*pub ; do ssh-keygen -l -f $i ; doneOne of those fingerprints must match the one that your client machine reports. Otherwise you should not proceed." }, { "title": "Multiprocessing in Python with shared resources", "url": "/posts/multiprocessing-in-python-with-shared-resources/", "categories": "Python, concurrency, subprocess", "tags": "python, subprocess, multiprocessing, lock", "date": "2019-04-17 02:00:00 +0200", "snippet": "The problemIn the previous post on parallelism in Python, we have seen how an external Python script performing a long computation can be ran in parallel using Python’s multiprocessing module. If you haven’t done so already, take your time to read that post before this one.Here we elaborate on the scenario presented in the previous post: As before, we have an external Python script worker.py that performs a long computation. As before, worker.py is launched several times in parallel using a multiprocessing pool. As before, the computations performed by the different worker instances are independent from each other. Here comes the novelty: although the different computations are independent, they need to access (read and update) a shared resource.The figure below shows a shared resource (SR) in yellow, that needs to be accessed by the tasks in grey (arrows). Some tasks are ran in parallel on the four available CPUs.What we need to do is enable each task to access the shared resource only if no other task is currently accessing it. This can be achieved by using a synchronization mechanism called a lock.The worker scriptFirst let us briefly see what is the task that we will be running in parallel. The worker.py script does just that, it performs a long “computation” (sleeping) and outputs a message at the end (for more explanations see the previous post):import sysimport timedef do_work(n): time.sleep(n) print(&#39;I just did some hard work for {}s!&#39;.format(n))if __name__ == &#39;__main__&#39;: if len(sys.argv) != 2: print(&#39;Please provide one integer argument&#39;, file=sys.stderr) exit(1) try: seconds = int(sys.argv[1]) do_work(seconds) except Exception as e: print(e)The main scriptWhat we will be doing now is launching 100 processes in parallel on as many threads as we have CPUs. Each process launches worker.py as a Python subprocess. As we have seen above, the worker script sleeps for a given number of seconds.The shared resourceHere is where the shared resource come into play. At the end of each “computation”, the worker process accesses this shared resource in both read and write mode. For the purpose of this example, let us imagine the shared resource is a list of results. The worker process needs to read the resource and update it with a certain value only if the value is not yet present in the list. Note: The more observant may argue that a list updated only with values that are not already included in the list is the equivalent of a set. This is correct, however: the Python multiprocessing module only allows lists and dictionaries as shared resources, and this is only an example meant to show that we need to reserve exclusive access to a resource in both read and write mode if what we write into the shared resource is dependent on what the shared resource already contains. The scriptLet us see the main script main.py right now and we’ll get into some details below:import subprocessimport multiprocessing as mpfrom tqdm import tqdmNUMBER_OF_TASKS = 100progress_bar = tqdm(total=NUMBER_OF_TASKS)def work(sec_sleep, processed_values, lock): seconds = int(sec_sleep) % 10 + 1 command = [&#39;python&#39;, &#39;worker.py&#39;, str(seconds)] subprocess.call(command) with lock: if seconds not in processed_values: processed_values.append(seconds)def update_progress_bar(_): progress_bar.update()if __name__ == &#39;__main__&#39;: tasks = [str(x) for x in range(1, NUMBER_OF_TASKS + 1)] pool = mp.Pool() manager = mp.Manager() lock = manager.Lock() shared_list = manager.list() for i in tasks: pool.apply_async(work, (i, shared_list, lock,), callback=update_progress_bar) pool.close() pool.join() print(shared_list)ExplanationJust like in the previous post, we define a pool of tasks that we want to parallelize. Although the aim is to eventually run 100 processes (NUMBER_OF_TASKS is 100, see lines 5 and 23), we cannot effectively run them all at the same time. For true parallelism, each task should be handled by a separate CPU, and the tasks should be ran at the same time. This is why we define the pool of tasks as holding as many processes as there are CPU threads at line 24 (this is the default behavior for mp.Pool() with no argument). If you want to specify a different number of processes with respect to the available number of CPU threads you may use the cpu_count() method in the multiprocessing module or in the os module (for example, mp.cpu_count() - 1).Once the multiprocessing pool is defined, we want to get stuff done. But before calling apply_async() on the pool’s processes, we first need to create both the shared resource that we’ve been talking about and the lock that will ensure that only one process may access the shared resource at a given time. Unlike in real life, if you want to get stuff done in Python’s multiprocessing module, you actually do need a Manager. We first create this manager, then use it to create the lock and the shared_list (lines 25-27).In lines 29-31, we finally apply asynchronously the work() method to the pool of processes with the task at hand (i), the shared resource (shared_list) as well as the multiprocessing synchronization mechanism (lock). We use the callback update_progress_bar() in order to, well, update the tqdm progress bar.Here is how the work() function handles the shared resource. It launches the external script worker.py using the Python subprocess module. The external script is ran with an argument representing the number of seconds (from 1 to 10) for which to run the long computation. Once the subprocess finishes, the work() method accesses the shared resource using the multiprocessing lock. In lines 13-15, the lock is acquired in order to ensure exclusive access to the shared list processed_values. Then if the number of seconds that the subprocess was called with is not already present in this list, we update the list with this value and we release the lock. Note that with lock is a shorthand notation for saying “acquire the lock before doing something, then do something, and finally release the lock after doing something”.Parallelization in practiceHere is the output of our main.py script, truncated for brevity:$ python main.py 0%| | 0/100 [00:00&amp;lt;?, ?it/s]I just did some hard work for 2s! 1%| | 1/100 [00:02&amp;lt;03:21, 2.04s/it]I just did some hard work for 3s! 2%|█ | 2/100 [00:03&amp;lt;02:49, 1.73s/it]I just did some hard work for 4s! 3%|█▊ | 3/100 [00:04&amp;lt;02:26, 1.51s/it]I just did some hard work for 1s!I just did some hard work for 5s! 5%|██▌ | 5/100 [00:05&amp;lt;01:54, 1.21s/it]I just did some hard work for 6s! 6%|███▌ | 6/100 [00:06&amp;lt;01:47, 1.14s/it]I just did some hard work for 2s!I just did some hard work for 7s! 8%|████▎ | 8/100 [00:07&amp;lt;01:27, 1.05it/s]I just did some hard work for 3s!I just did some hard work for 8s! 10%|██████ | 10/100 [00:08&amp;lt;01:13, 1.23it/s][snip] 99%|██████████████████████████████████████████████████████ | 99/100 [01:12&amp;lt;00:01, 1.24s/it]I just did some hard work for 10s!100%|██████████████████████████████████████████████████████| 100/100 [01:14&amp;lt;00:00, 1.46s/it][2, 3, 4, 1, 5, 6, 7, 8, 9, 10]Notice how several worker processes that have been sleeping for different amounts of time finish at the same time, for example between 3% and 5% there are two workers that finished: they respectively performed a 1s-long and a 5s-long computation.The last line of the output shows the shared resource shared_list: it contains the amount of time in seconds for which the computations lasted, one item per amount of time, in the order in which the processes have been completed. No value appears twice.This example shows that the execution of the worker.py script has been parallelized on several CPU threads and that every process successfully accessed the shared resource, by reading and updating it.Further reading subprocess (Python documentation) multiprocessing (Python documentation) Parallel processing in Python (Frank Hofmann on stackabuse) multiprocessing – Manage processes like threads (Doug Hellmann on Python Module of the Week)" }, { "title": "Run a Python script as a subprocess with the multiprocessing module", "url": "/posts/run-python-script-as-subprocess-with-multiprocessing/", "categories": "Python, concurrency, subprocess", "tags": "python, subprocess, multiprocessing", "date": "2019-04-17 01:00:00 +0200", "snippet": "The problemSuppose you have a Python script worker.py performing some long computation. Also suppose you need to perform these computations several times for different input data. If all the computations are independent from each other, one way to speed them up is to use Python’s multiprocessing module.This comes down to the difference between sequential and parallel execution. Suppose you have the tasks A, B, C and D, requiring 1, 2, 3 and 4 seconds, respectively, to complete. When ran sequentially, meaning one after the other, you’d need 10 seconds in order for all tasks to complete, whereas running them in parallel (if you have 4 available CPU cores) would take 4 seconds, give or take, because some overhead does exist.Before we continue, it is worth emphasizing that what is meant by parallel execution is each task is handled by a separate CPU, and that these tasks are ran at the same time. So in the figure above, when tasks A, B, C and D are run in parallel, each of them is ran on a different CPU.The worker scriptLet us see a very simple example for worker.py; remember that it performs long computations:import sysimport timedef do_work(n): time.sleep(n) print(&#39;I just did some hard work for {}s!&#39;.format(n))if __name__ == &#39;__main__&#39;: if len(sys.argv) != 2: print(&#39;Please provide one integer argument&#39;, file=sys.stderr) exit(1) try: seconds = int(sys.argv[1]) do_work(seconds) except Exception as e: print(e)worker.py fails if it does not receive a command-line argument that can be converted to an integer. It then calls the do_work() method with the input argument converted to an integer. In turn, do_work() performs some hard work (sleeping for the specified number of seconds) and then outputs a message:$ python worker.py 2I just did some hard work for 2s!(Just in case you were wondering, if do_work() is called with a negative integer, then it is the sleep() function that complains about it.)The main scriptLet us now see how to run worker.py from within another Python script. We will create a file main.py that creates four tasks. As shown in the figure above, the tasks take 1, 2, 3 and 4 seconds to finish, respectively. Each task consists in running worker.py with a different sleep length:import subprocessimport multiprocessing as mpfrom tqdm import tqdmNUMBER_OF_TASKS = 4progress_bar = tqdm(total=NUMBER_OF_TASKS)def work(sec_sleep): command = [&#39;python&#39;, &#39;worker.py&#39;, sec_sleep] subprocess.call(command)def update_progress_bar(_): progress_bar.update()if __name__ == &#39;__main__&#39;: pool = mp.Pool(NUMBER_OF_TASKS) for seconds in [str(x) for x in range(1, NUMBER_OF_TASKS + 1)]: pool.apply_async(work, (seconds,), callback=update_progress_bar) pool.close() pool.join()The tasks are ran in parallel using NUMBER_OF_TASKS (4) processes in a multiprocessing pool (lines 20-26). When we refer to the tasks being ran in parallel, we mean that the apply_async() method is applied to every task (line 23). The first argument to apply_async() is the method to execute asynchronously (work()), the second one is the argument for work() (seconds), and the third one is a callback, our update_progress_bar() function.The work() method (lines 10-12) calls our previous script worker.py with the specified number of seconds. This is done through the Python subprocess module.As for tqdm, it is a handy little package that displays a progress bar for the number of items in an iteration. It can be installed through pip, conda or snap.Parallelization in practiceHere is the output of our main.py script:$ python main.py 0%| | 0/4 [00:00&amp;lt;?, ?it/s]I just did some hard work for 1s! 25%|███████████████ | 1/4 [00:01&amp;lt;00:03, 1.02s/it]I just did some hard work for 2s! 50%|██████████████████████████████ | 2/4 [00:02&amp;lt;00:02, 1.02s/it]I just did some hard work for 3s! 75%|█████████████████████████████████████████████ | 3/4 [00:03&amp;lt;00:01, 1.01s/it]I just did some hard work for 4s!100%|████████████████████████████████████████████████████████████| 4/4 [00:04&amp;lt;00:00, 1.03s/it]As you can see, the four tasks finished in about 4 seconds, meaning that the execution of the worker.py script has successfully been parallelized.The next post Multiprocessing in Python with shared resources iterates on what we have just seen in order to show how we can parallelize external Python scripts that need to access the same shared resource.Further reading subprocess (Python documentation) multiprocessing (Python documentation) Parallel processing in Python (Frank Hofmann on stackabuse) multiprocessing – Manage processes like threads (Doug Hellmann on Python Module of the Week)" }, { "title": "Bitwise nuggets&amp;#58; rotate a number to the left using bit precision", "url": "/posts/bitwise-nuggets-rotate-number-to-the-left-on-bit-precision/", "categories": "C/C++, bitwise", "tags": "c/c++, algorithms, binary", "date": "2019-04-03 03:00:00 +0200", "snippet": "Here we discuss how to rotate a number to the left by k positions, using bit precision. (In a previous post we’ve seen the same problem, but the rotation involved byte precision.)What does that even mean? We want to left-shift the number by k bits, but the most significant k bits that overflow as a result of the left-shift operation must be saved and added to the k least significant bits of the left-shifted number (these bits are zero after the left-shift). In addition, the rotation has bit precision, meaning we left-shift on the precise number of bits that the number requires for its representation.Let us see an example to better visualize the rotation to the left. Suppose we want to rotate the number 100 to the left by 3 positions. As shown below, when using bit precision, we expect to obtain 38:Since we’re using bit precision, the actual overflow when 100 is left-shifted by 3 positions is 110 (i.e. decimal 6).Here are the steps for solving this problem: determine the number of bits that the number requires compute the overflow, or the k MSB of the number left-shift the number by k positions add the overflow to the left-shifted numberFirst, we need a helper function to count the number of bits needed to represent a given number. Here is the idea: while the number is non-zero, we divided it by two (in other words, we right-shift it by 1 position) and increment the number of bits that we’ve counted so far.// Determine the number of bits that the given `number` requires.unsigned int count_total_bits(unsigned int number){ unsigned int bits = 0; while (number) { number &amp;gt;&amp;gt;= 1; ++bits; } return bits;}We can now implement rotation to the left using bit precision:// Rotate the given `number` to the left by `k` positions. Rotation takes place on// the precise number of bits needed to represent the `number`.unsigned int rotate_left_bit_precision(unsigned int number, unsigned int k){ // Determine the number of bits needed to represent the `number`. unsigned int precision = count_total_bits(number); // Overflowing bits are the most significant ones. Right-shift by precision - k bits. unsigned int overflow = number &amp;gt;&amp;gt; (precision - k); // Left-shift `number` by `k` bits. unsigned int left_shifted = number &amp;lt;&amp;lt; k; // Clear the unneeded bytes. if (precision &amp;lt; CHAR_BIT * sizeof(unsigned int)) left_shifted &amp;amp;= (unsigned int) ((1 &amp;lt;&amp;lt; precision) - 1); // Add the overflow. return left_shifted | overflow;}At lines 6 we determine the precision, i.e. the number of bits required to represent the number. We use the precision for determining the overflow bits at line 9. Then we shift the number by k positions to the left at line 12. At lines 15-16, we ensure that the MSB are zeroed out if the number is represented on less than 32 bits. Finally, at line 19 we add the overflow to the left_shifted number using the logical OR operator.Here are some examples of left rotation on bit precision in action:rotate_left_bit_precision( 100, 3) = 38rotate_left_bit_precision( 244, 3) = 167rotate_left_bit_precision( 356, 10) = 0rotate_left_bit_precision( 2019, 4) = 1599rotate_left_bit_precision( 983396, 8) = 91376rotate_left_bit_precision(3422643215, 5) = 2150400505Want to see more bitwise logic? There’s a whole repository on my GitHub on bit fiddling." }, { "title": "Bitwise nuggets&amp;#58; clear the first k most significant bits", "url": "/posts/bitwise-nuggets-clear-the-k-msb/", "categories": "C/C++, bitwise", "tags": "c/c++, algorithms, binary", "date": "2019-04-03 01:00:00 +0200", "snippet": "Here we discuss how to clear the first k most significant bits (MSB) in an integer. This is a more intuitive variation of the clear MSB up to a given position problem that we have seen earlier.What does that even mean? Well, in a number, bits are numbered starting from 0, where the bit at position 0 is the least significant bit (or LSB for short). Take the number 2019 for instance; its LSB (at position 0) is 1 and its MSB (at position 10) is also 1:pos: 10 0 v v2019 = 11111100011 ^ ^ MSB LSBClearing the k MSBs in a number would mean zero-ing them out while leaving the LSBs untouched. For example, if we were to clear the first 3 MSBs in number 2019 up, we would get 227:k: 3 v2019 = 11111100011 | v clear the 3 MSBsk: 3 v 227 = 00011100011The idea is to apply a mask to the integer, where the mask is all zeroes for the k most significant bits, i.e. the bits we want to clear. The remaining mask is all ones. We obtain the mask by left-shifting 1 by the difference between the total number of bits and k, then subtracting 1 (to get all ones). The mask is applied by AND-ing it with the number. It has the effect of preserving the LSBs and of clearing (zeroing) the first k MSBs.We first need count_total_bits(), a helper function to count the total number of bits in a number. Using this function, we can now clear the k most significant bits as follows:// Clears the first `k` most significant bits in `number`.int clear_most_significant_bits(int number, unsigned int k){ unsigned int n_bits = count_total_bits(number); return number &amp;amp; ((1 &amp;lt;&amp;lt; (n_bits - k)) - 1);}Here is what becomes of number 2019 when we clear its MSBs up to positions 0 through 11 (recall that the MSB of 2019 is at position 10):clear_msb(2019, 0) = 2019 = 11111100011clear_msb(2019, 1) = 995 = 01111100011clear_msb(2019, 2) = 483 = 00111100011clear_msb(2019, 3) = 227 = 00011100011clear_msb(2019, 4) = 99 = 00001100011clear_msb(2019, 5) = 35 = 00000100011clear_msb(2019, 6) = 3 = 00000000011clear_msb(2019, 7) = 3 = 00000000011clear_msb(2019, 8) = 3 = 00000000011clear_msb(2019, 9) = 3 = 00000000011clear_msb(2019, 10) = 1 = 00000000001clear_msb(2019, 11) = 0 = 00000000000Want to see more bitwise logic? There’s a whole repository on my GitHub on bit fiddling." }, { "title": "Bitwise nuggets&amp;#58; check if a number is a power of 2", "url": "/posts/bitwise-nuggets-check-if-a-number-is-a-power-of-two/", "categories": "C/C++, bitwise", "tags": "c/c++, algorithms, binary", "date": "2019-04-02 02:00:00 +0200", "snippet": "Here we discuss how to determine whether a given number is a power of 2.As we know, a number is a power of 2 if it has only one of its bits set to 1. Such numbers have a very interesting property that we use all the time for creating bit masks: if we subtract 1 from a power of 2, we get a sequence of 1s starting from the next most significant bit with respect to the bit that is set in out input number.If we apply the logical AND operator to the input number and this sequence of 1s, we get 0. For a number that is not a power of 2, applying the AND operator to the number and the number from which we subtract 1 will always result in a value different from zero.Let us see a couple of examples to better visualize what this means.Here, we can see that 64 is a power of 2 since the bitwise AND with 63 yields all zeros:When a number is not a power of 2, the bitwise AND between that number and the number from which we subtract 1 will always yield something other than zero:Here is how this algorithm can be implemented in C:#include &amp;lt;stdbool.h&amp;gt;// Determines whether the specified number is a power of two.bool is_power_of_two(int number){ if (number == 0) return false; return (number &amp;amp; (number - 1)) == 0;}Want to see more bitwise logic? There’s a whole repository on my GitHub on bit fiddling." }, { "title": "Bitwise nuggets&amp;#58; insert a number inside another one", "url": "/posts/bitwise-nuggets-insert-a-number-inside-another-number/", "categories": "C/C++, bitwise", "tags": "c/c++, algorithms, binary", "date": "2019-04-02 01:00:00 +0200", "snippet": "Here we discuss how to insert a number m into a number n between positions i and j.Let us see an example to better visualize what this means. Suppose we have the number n = 1040 and that we want to insert the number m = 19 into it, between positions i = 2 and j = 6. As shown below, by doing so we obtain the number 1100:We could go about this in a number of different ways. We’ll just do lazy here :laughing:, meaning we make two very generous assumptions: The number of bits between i and j is indeed the actual number of bits in number m. There are enough bits in n for inserting m into it.With that out of the way, we can now focus on the task at hand. The tricky part is to zero-out the bits in number n between positions i and j (in yellow in the figure above). To do this, we must create a bit mask that goes from 0 through j and that has two parts: The “left”-most part (between positions i and j) is all zeros (we want to zero-out this part of n). We can obtain it by left-shifting 1 by j + 1 bits, subtracting 1, and finally inverting (logical NOT) the mask. The “right”-most part (between positions 0 and i - 1) is all ones (we want to keep this part of n). We can obtain it by left-shifting 1 by i bits, then subtracting 1.Once that’s done, we must bring together the two parts of the mask using the logical OR operator.Next, we apply the mask to the number n, thus clearing its bits at positions i through j. Now the only thing that’s left is to “insert” m into n between these indexes, which we can do by left-shifting m by i bits, followed by applying the logical OR operator.Here is how this algorithm can be implemented in C:// Insert number `m` into number `n` between positions `j` through `i`.// Assumption 1: the number of bits between `j` and `i` is the number of bits of `m`.// Assumption 2: there are enough bits in `n` for inserting `m`.int insert_number_inside_another(int n, int m, int i, int j){ /* Create a mask that zeroes out bits from positions j through i (inclusive) in n when using the AND operator between n and the mask. The mask has the following form: Mask: 1 ... 1 0 ... 0 1 ... 1 Positions: |n|-1 j+1 j i i-1 0 */ int mask = ~((1 &amp;lt;&amp;lt; (j + 1)) - 1) | ((1 &amp;lt;&amp;lt; i) - 1); // Apply the mask to turn off bits betwene j and i, then insert m. return (n &amp;amp; mask) | (m &amp;lt;&amp;lt; i);}Whew, that long explanation for only 2 lines of actual code, who would have thought? :smile:Want to see more bitwise logic? There’s a whole repository on my GitHub on bit fiddling." }, { "title": "Bitwise nuggets&amp;#58; rotate a number to the left using byte precision", "url": "/posts/bitwise-nuggets-rotate-number-to-the-left-on-byte-precision/", "categories": "C/C++, bitwise", "tags": "c/c++, algorithms, binary", "date": "2019-04-01 02:00:00 +0200", "snippet": "Here we discuss how to rotate a number to the left by k positions, using byte precision. (In a following post we’ll see the same problem when bit precision is used.)What does that even mean? We want to left-shift the number by k bits, but the most significant k bits that overflow as a result of the left-shift operation must be saved and added to the k least significant bits of the left-shifted number (these bits are zero after the left-shift). In addition, the rotation has byte precision, meaning we left-shift on the number of bytes that the number requires for its representation.Let us see an example to better visualize the rotation to the left. Suppose we want to rotate the number 100 to the left by 3 positions. As shown below, when using byte precision, we expect to obtain 35:Since we’re using byte precision, the actual overflow when 100 is left-shifted by 3 positions is 011, not 11. It is possible to rotate a number on the number of bits it requires for its representation, but that is a subject for another time.Here are the steps for solving this problem: determine the number of bytes that the number requires compute the overflow, or the k MSB of the number left-shift the number by k positions if we go over the number of bytes used for representing the original number, zero-out the extra bits add the overflow to the left-shifted numberHere is how this algorithm can be implemented in C:#include &amp;lt;limits.h&amp;gt;// Rotate the given `number` to the left by `k` positions. Rotation takes place on// 1 through 4 bytes, depending on how many the `number` needs for its// representation.unsigned int rotate_left_byte_precision(unsigned int number, unsigned int k){ // number of bits multiple of CHAR_BIT needed to represent `number` unsigned int precision = 0; // number of bytes needed to represent `number` (maximum: 4) unsigned int number_of_bytes = 1; while (!precision) { unsigned int cmp = (unsigned int) ((1 &amp;lt;&amp;lt; (CHAR_BIT * number_of_bytes)) - 1); if (number &amp;lt;= cmp || ++number_of_bytes == 4) precision = CHAR_BIT * number_of_bytes; } // Overflowing bits are the `precision - k` most significant ones. unsigned int overflow = number &amp;gt;&amp;gt; (precision - k); // Left-shift `number` by `k` bits. unsigned int left_shifted = number &amp;lt;&amp;lt; k; // Clear the unneeded bytes. if (precision &amp;lt; CHAR_BIT * sizeof(unsigned int)) left_shifted &amp;amp;= (unsigned int) ((1 &amp;lt;&amp;lt; precision) - 1); // Add the overflow. return left_shifted | overflow;}At lines 14-18 we determine the precision, i.e. the number of bits multiple of 8 (CHAR_BIT) required to represent the number. We need the precision in order to determine the overflow bits at line 21. At lines 27-28, we ensure that the rotation takes place only on the number of bytes that are required to represent the original number. Finally, at line 31 we add the overflow to the left_shifted number using the logical OR operator.Here are some examples of left rotation on byte precision in action:rotate_left_byte_precision( 100, 3) = 35rotate_left_byte_precision( 244, 3) = 167rotate_left_byte_precision( 356, 10) = 36869rotate_left_byte_precision( 2019, 4) = 32304rotate_left_byte_precision( 983396, 8) = 91151rotate_left_byte_precision(3422643215, 5) = 2150400505Want to see more bitwise logic? There’s a whole repository on my GitHub on bit fiddling." }, { "title": "Bitwise nuggets&amp;#58; clear the least significant bits up to a given position", "url": "/posts/bitwise-nuggets-clear-lsb-up-to-position/", "categories": "C/C++, bitwise", "tags": "c/c++, algorithms, binary", "date": "2019-04-01 01:00:00 +0200", "snippet": "Here we discuss how to clear the least significant bits (LSB) in an integer up to a given position pos (including pos). (Check out this post for clearing the MSBs up to a given position.)What does that even mean? Well, in a number, bits are numbered starting from 0, where the bit at position 0 is the least significant bit (or LSB for short). Take the number 2019 for instance; its LSB (at position 0) is 1 and its MSB (at position 10) is also 1:pos: 10 0 v v2019 = 11111100011 ^ ^ MSB LSBClearing the LSBs in a number up to a given position would mean zero-ing them out while leaving the MSBs untouched. For example, if we were to clear the LSBs in number 2019 up to and including position 6, we would get 1920:pos: 6 0 v v2019 = 11111100011 | v clear LSB up to (and including) pos 6pos: 6 0 v v1920 = 11110000000The idea is to apply a mask to the integer, where the mask is all zeros for the pos + 1 least significant bits, i.e. the bits we want to clear. We obtain the mask by left-shifting 1 by pos + 1 bits, then subtracting 1 (to get all ones), and finally inverting (logical NOT) the whole mask. The mask is applied by AND-ing it with the number. It has the effect of preserving the MSBs starting at position pos + 1 and of clearing (zeroing) LSBs up to and including position pos.Here is how this can be implemented in C:// Clears the least significant bits in `number` up to the bit at// position `pos` (inclusive).int clear_least_significant_bits_up_to_pos(int number, int pos){ return number &amp;amp; ~((1 &amp;lt;&amp;lt; (pos + 1)) - 1);}Here is what becomes of number 2019 when we clear its LSBs up to positions 0 through 11 (recall that the MSB of 2019 is at position 10):clear_least_significant_bits_up_to_pos(2019, 0) = 2018 = 11111100010clear_least_significant_bits_up_to_pos(2019, 1) = 2016 = 11111100000clear_least_significant_bits_up_to_pos(2019, 2) = 2016 = 11111100000clear_least_significant_bits_up_to_pos(2019, 3) = 2016 = 11111100000clear_least_significant_bits_up_to_pos(2019, 4) = 2016 = 11111100000clear_least_significant_bits_up_to_pos(2019, 5) = 1984 = 11111000000clear_least_significant_bits_up_to_pos(2019, 6) = 1920 = 11110000000clear_least_significant_bits_up_to_pos(2019, 7) = 1792 = 11100000000clear_least_significant_bits_up_to_pos(2019, 8) = 1536 = 11000000000clear_least_significant_bits_up_to_pos(2019, 9) = 1024 = 10000000000clear_least_significant_bits_up_to_pos(2019, 10) = 0 = 00000000000Want to see more bitwise logic? There’s a whole repository on my GitHub on bit fiddling." }, { "title": "Bitwise nuggets&amp;#58; clear the most significant bits up to a given position", "url": "/posts/bitwise-nuggets-clear-msb-up-to-position/", "categories": "C/C++, bitwise", "tags": "c/c++, algorithms, binary", "date": "2019-03-31 03:00:00 +0200", "snippet": "Here we discuss how to clear the most significant bits (MSB) in an integer up to a given position pos (including pos). (Check out this post for clearing the LSBs up to a given position, or this one for clearing only the first k MSBs.)What does that even mean? Well, in a number, bits are numbered starting from 0, where the bit at position 0 is the least significant bit (or LSB for short). Take the number 2019 for instance; its LSB (at position 0) is 1 and its MSB (at position 10) is also 1:pos: 10 0 v v2019 = 11111100011 ^ ^ MSB LSBClearing the MSBs in a number up to a given position would mean zero-ing them out while leaving the LSBs untouched. For example, if we were to clear the MSBs in number 2019 up to and including position 6, we would get 35:pos: 6 0 v v2019 = 11111100011 | v clear MSB up to (and including) pos 6pos: 6 0 v v 35 = 00000100011The idea is to apply a mask to the integer, where the mask is all ones for the pos least significant bits, i.e. the bits we want to keep. We obtain the mask by left-shifting 1 by pos bits, then subtracting 1 (to get all ones). The mask is applied by AND-ing it with the number. It has the effect of preserving the LSBs and of clearing (zeroing) the MSBs up to and including position pos.Here is how this can be implemented in C:// Clears the most significant bits in `number` up to the bit at// position `pos` (inclusive).int clear_most_significant_bits_up_to_pos(int number, int pos){ return number &amp;amp; ((1 &amp;lt;&amp;lt; pos) - 1);}Here is what becomes of number 2019 when we clear its MSBs up to positions 0 through 11 (recall that the MSB of 2019 is at position 10):clear_most_significant_bits_up_to_pos(2019, 0) = 0 = 00000000000clear_most_significant_bits_up_to_pos(2019, 1) = 1 = 00000000001clear_most_significant_bits_up_to_pos(2019, 2) = 3 = 00000000011clear_most_significant_bits_up_to_pos(2019, 3) = 3 = 00000000011clear_most_significant_bits_up_to_pos(2019, 4) = 3 = 00000000011clear_most_significant_bits_up_to_pos(2019, 5) = 3 = 00000000011clear_most_significant_bits_up_to_pos(2019, 6) = 35 = 00000100011clear_most_significant_bits_up_to_pos(2019, 7) = 99 = 00001100011clear_most_significant_bits_up_to_pos(2019, 8) = 227 = 00011100011clear_most_significant_bits_up_to_pos(2019, 9) = 483 = 00111100011clear_most_significant_bits_up_to_pos(2019, 10) = 995 = 01111100011clear_most_significant_bits_up_to_pos(2019, 11) = 2019 = 11111100011Want to see more bitwise logic? There’s a whole repository on my GitHub on bit fiddling." }, { "title": "Bitwise nuggets&amp;#58; get bit at position", "url": "/posts/bitwise-nuggets-get-bit-at-position/", "categories": "C/C++, bitwise", "tags": "c/c++, algorithms, binary", "date": "2019-03-31 01:00:00 +0100", "snippet": "Here is how to obtain the bit at a given position pos in an integer. Bit positions start at 0, and the bit at position 0 is the least significant bit (LSB).The idea is to apply a mask to the integer, where the mask is all zeros except for a bit set at 1 at position pos. We obtain the mask by left-shifting 1 by pos bits. The mask is applied by AND-ing it with the number. If the result is 0, it means the bit at pos is also 0, otherwise its value is 1.Here is the process described above, step-by-step, for getting the bit at position 6 in the number 2019:mask: 1mask &amp;lt;&amp;lt; 6: 10000002019: 111111000112019 &amp;amp; mask: 00001000000We see that 2019 &amp;amp; mask is different than 0, so the bit at position 6 in 2019 is 1.Let’s now get the bit at position 3 in 2019:mask: 1mask &amp;lt;&amp;lt; 3: 10002019: 111111000112019 &amp;amp; mask: 00000000000Now the result is 0, so the bit at position 3 in 2019 is also 0.Here is how this can be implemented in C:// Returns the bit at position `pos` in the input `number`.// The LSB is at position 0.unsigned int get_bit_at_position(int number, int pos){ return (number &amp;amp; (1 &amp;lt;&amp;lt; pos)) != 0;}Want to see more bitwise logic? There’s a whole repository on my GitHub on bit fiddling." }, { "title": "Bitwise nuggets&amp;#58; count set bits", "url": "/posts/bitwise-nuggets-count-set-bits/", "categories": "C/C++, bitwise", "tags": "c/c++, algorithms, binary", "date": "2019-03-31 00:00:00 +0100", "snippet": "If we want to count the number of set bits (i.e. bits that are 1) in an int, we can check whether its least significant bit (LSB) is 1, count it as set if applicable, then right-shift the int by one position until we’ve seen the number of bits in an int.Here is how this can be implemented in C:#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;limits.h&amp;gt;// Returns the number of &quot;on&quot; bits (bits set to 1) in the input `number`.unsigned int count_set_bits(int number){ unsigned int n_bits_on = 0; int value = number; for (size_t i = 0; i &amp;lt; CHAR_BIT * sizeof(int); i++) { if ((1 &amp;amp; value) == 1) ++n_bits_on; value &amp;gt;&amp;gt;= 1; } return n_bits_on;}int main(){ int numbers[] = {7, 2019, -1, -2}; for (int i = 0; i &amp;lt; 4; i++) printf(&quot;count_set_bits(%4d) = %2d\\n&quot;, numbers[i], count_set_bits(numbers[i]));}At line 11, we iterate for the number of bits in an int, which can also be written as CHAR_BIT (macro constant defined in limits.h that represents the number of bits in a char, i.e. 8) multiplied by the number of bytes in an int (which is sizeof(int)).Here is the output of the above program:count_set_bits( 7) = 3count_set_bits(2019) = 8count_set_bits( -1) = 32count_set_bits( -2) = 31Want to see more bitwise logic? There’s a whole repository on my GitHub on bit fiddling." }, { "title": "Bitwise nuggets&amp;#58; count total bits", "url": "/posts/bitwise-nuggets-count-total-bits/", "categories": "C/C++, bitwise", "tags": "c/c++, algorithms, binary", "date": "2019-03-30 02:00:00 +0100", "snippet": "If we want to count the total number of bits in an integer, we can divide that number by two until it becomes zero, counting a bit at each step.Here is how this can be implemented in C:#include &amp;lt;stdio.h&amp;gt;// Determine the number of bits that the given `number` requires.unsigned int count_total_bits(unsigned int number){ unsigned int bits = 0; while (number) { number &amp;gt;&amp;gt;= 1; ++bits; } return bits;}int main(){ int numbers[] = {7, 2019, -1, -2}; for (int i = 0; i &amp;lt; 4; i++) printf(&quot;count_total_bits(%4d) = %2d\\n&quot;, numbers[i], count_total_bits(numbers[i]));}At line 8, instead of dividing number by two, we right-shift it by 1 position (since the logical shift operation is not expensive).Here is the output of the above program:count_total_bits( 7) = 3count_total_bits(2019) = 11count_total_bits( -1) = 32count_total_bits( -2) = 32Want to see more bitwise logic? There’s a whole repository on my GitHub on bit fiddling." }, { "title": "Bitwise nuggets&amp;#58; invert the n least significant bits", "url": "/posts/bitwise-nuggets-invert-the-n-least-significant-bits/", "categories": "C/C++, bitwise", "tags": "c/c++, algorithms, binary", "date": "2019-03-30 00:00:00 +0100", "snippet": "Suppose we want to invert the n least significant bits in a number. For example:2019 = 11111100011 ||||2028 = 11111101100If we invert the least significant 4 bits in the number 2019, we obtain 2028.When we hear invert, we automatically think of XOR: 0 XOR 0 = 0 0 XOR 1 = 1 1 XOR 0 = 1 1 XOR 1 = 0We therefore need to XOR the input number with a mask of n bits that are all 1…1. To obtain this mask, we can left-shift 1 for n positions, then we subtract 1. Following our previous example:2019 : 11111100011mask = 1 &amp;lt;&amp;lt; 4 : 10000mask -= 1 : 011112019 ^ mask : 11111101100 = 2028Here is how this operation may be implemented in C:// Inverts the `n_bits` least significant bits in `number`// and returns the resulting number.int invert_n_lsb(int number, int n_bits){ return number ^ ((1 &amp;lt;&amp;lt; n_bits) - 1);}Want to see more bitwise logic? There’s a whole repository on my GitHub on bit fiddling." }, { "title": "Bitwise nuggets&amp;#58; convert an integer to a binary string", "url": "/posts/bitwise-nuggets-convert-int-to-binary-string/", "categories": "C/C++, bitwise", "tags": "c/c++, algorithms, binary", "date": "2019-03-30 00:00:00 +0100", "snippet": "When we want to display an int as a binary string, we need a utility function that builds the string representation of the integer. We do this from the least significant bit (LSB) up to the most significant bit (MSB) of the integer.The idea, at each step, is to check whether the LSB in the number is a 0 or a 1, and then to divide the number by 2 (i.e. to right-shift it by 1 position).Here is how we can get the binary string representation of an int in C:#include &amp;lt;limits.h&amp;gt;#include &amp;lt;stdio.h&amp;gt;// The binary string representation of the input `number` will be stored in// `binary`.void int_to_binary_string(int number, char *binary){ // 1 &amp;amp; number gives the value of the LSB in `number` for (int i = CHAR_BIT * sizeof(int) - 1; i &amp;gt;= 0; i--, number &amp;gt;&amp;gt;= 1) binary[i] = (1 &amp;amp; number) ? &#39;1&#39; : &#39;0&#39;; // null-terminate the string binary[CHAR_BIT * sizeof(int)] = &#39;\\0&#39;;}int main(){ char binary[CHAR_BIT * sizeof(int) + 1]; int numbers[4] = {7, 2019, -1, -2}; for (int i = 0; i &amp;lt; 4; i++) { int_to_binary_string(numbers[i], binary); printf(&quot;int_to_binary_string(%4d) = %s\\n&quot;, numbers[i], binary); }}Here, the int_to_binary_string() function takes a char *binary argument, which allows us to define a char array on the stack that we can pass to the function (rather than creating a char array on the heap through dynamic memory allocation and having to remember to free() the array when we’re done with it).CHAR_BIT is a macro constant defined in limits.h and represents the number of bits in a char (i.e. 8).The above program outputs:int_to_binary_string( 7) = 00000000000000000000000000000111int_to_binary_string(2019) = 00000000000000000000011111100011int_to_binary_string( -1) = 11111111111111111111111111111111int_to_binary_string( -2) = 11111111111111111111111111111110Want to see more bitwise logic? There’s a whole repository on my GitHub on bit fiddling." }, { "title": "How to read safely from stdin in C", "url": "/posts/how-to-read-safely-from-stdin-in-c/", "categories": "C/C++, string", "tags": "c/c++, stdin", "date": "2018-12-11 00:00:00 +0100", "snippet": "Ah, C and strings. :confounded:When reading from stdin, we can use fgets(str, n, stdin) to read at most n - 1 characters into a char array pointed to by str. We can also create a utility function to replace the newline character \\n with the null terminator \\0.The following is inspired from C Primer Plus by Stephen Prata, sixth edition, listing 11.10:#include &amp;lt;stdio.h&amp;gt;// Read at most `n` characters (newline included) into `str`.// If present, the newline is removed (replaced by the null terminator).void s_gets(char* str, int n){ char* str_read = fgets(str, n, stdin); if (!str_read) return; int i = 0; while (str[i] != &#39;\\n&#39; &amp;amp;&amp;amp; str[i] != &#39;\\0&#39;) i++; if (str[i] == &#39;\\n&#39;) str[i] = &#39;\\0&#39;;}int main(){ char my_string[10]; s_gets(my_string, 10); printf(&quot;my_string = %s\\n&quot;, my_string);}If we run the above program with the input test 12345, we obtain a char array of 9 characters followed by the null terminator \\0:my_string = test 1234" }, { "title": "Implementing a vector in C", "url": "/posts/implementing-a-vector-in-c/", "categories": "C/C++, data structures", "tags": "c/c++, vector", "date": "2017-12-21 00:00:00 +0100", "snippet": "Suppose we need a generic vector data structure in C, where by generic we mean it can handle any type of data. A vector uses an underlying array, therefore it supports index-based access to its elements. Moreover, the underlying array is resizable, meaning that memory space is not wasted uselessly. If the vector is full, adding a new element causes the underlying array to double its size. If the vector is 75% empty, the underlying array halves its size.How does a vector work?The ASCII figure below shows the example of a vector v, initially empty and with an initialcapacity of 4 items: -----------------when v is created : | | | | | ----------------- -----------------append 7 to v : | 7 | | | | ----------------- -----------------append 1 to v : | 7 | 1 | | | ----------------- -----------------append 5 to v : | 7 | 1 | 5 | | ----------------- -----------------append 9 to v : | 7 | 1 | 5 | 9 | ----------------- 0 1 2 3 4 5 6 7 ---------------------------------insert 2 at index 3 : | 7 | 1 | 5 | 2 | 9 | | | | &amp;lt;-- capacity doubles --------------------------------- 0 1 2 3 4 5 6 7 ---------------------------------insert 2 at index 3 : | 7 | 1 | 5 | 2 | 9 | | | | --------------------------------- 0 1 2 3 4 5 6 7 ---------------------------------remove item at index 3 : | 7 | 1 | 5 | 9 | | | | | --------------------------------- 0 1 2 3 4 5 6 7 ---------------------------------remove item at index 1 : | 7 | 5 | 9 | | | | | | --------------------------------- 0 1 2 3 -----------------remove item at index 0 : | 5 | 9 | | | &amp;lt;-- capacity is reduced by half since 75% empty -----------------Comparison with alternative data structuresA fixed-size array allows access to its elements in \\( O(1) \\) time. Adding items at the end of the array also takes \\( O(1) \\) time. However, insertion (other than at the end of the array) and deletion require \\( O(n) \\) time. As its name implies, a fixed-size array cannot change its size.A vector uses an underlying resizing array, meaning that its capacity is automatically adjusted to accommodate its elements.In contrast to an array, a linked list allows insertion and deletion in \\( O(1) \\) time, but accessing the kth element requires \\( O(n) \\) time.An array (a fixed-size array or a resizing array, i.e. a vector) should be used when indexing happens more often than insertion or deletion at arbitrary positions. A linked list is more appropriate when indexing happens rarely and when insertions and deletions are frequent.Resizing the vectorA vector starts out with an initial capacity, for which we can make an educated guess depending on the application. Let us suppose a good choice for an initial capacity is 4.When the 5th item is added to the vector, its capacity doubles, becoming 8. When the 9th item is added, the capacity doubles again, becoming 16, and so on. Doubling the vector capacity is thus performed only if it is absolutely necessary to do so.Halving the vector capacity is more tricky. The aim is to strike a good balance between array resizing operations performed via realloc() and not wasting too much memory space. Suppose a vector has 9 items and its capacity is 16. If we remove one item, it would be tempting to halve the capacity on the spot. But if a 9th item needs to be added right away, we would have to double the capacity yet again. The best bet is to halve the vector capacity when it is one quarter full, because this means we have been removing items from the vector for quite some time and it is reasonable to assume that the need to double the capacity will not arise any time soon. Continuing the example, a vector would keep its capacity of 16 items as long as it has at least 5 items. When it only has 4 items, its capacity becomes 8. Consider another example of a vector with 513 elements and capacity 1024. If we start removing items, the capacity shrinks to 512 when only 256 items remain. The capacity further shrinks to 256 when only 128 items remain, and so on.Vector definitionHere is a bare-bones definition of a vector in C:typedef struct { void **data; /* information stored in the vector */ size_t count; /* number of elements currently stored in the vector */ size_t capacity; /* maximum capacity of the vector */} Vector;We want this data structure to be generic, meaning it must be able to handle any type of item: integers, doubles, strings, as well as user-defined data structures. This is why items in a Vector are of type void *. As vector items are organized in an array, what we need for the vector data is a pointer to pointer to void (void **).We should also define the initial capacity of the vector. Note however that this choice is highly dependent on the application. Here, we will use an initial capacity of 4:const size_t VECTOR_INIT_CAPACITY = 4;The Vector implementation in libgcds (Library for Generic C Data Structures) defines the data structure as above, with the addition of several function pointers (structs with function pointers are the ancestors of classes; for the C ecosystem, it will just have to do). In this post the aim is to keep things simple and easy to understand, not to build a library, so we will just be defining stand-alone (“normal”) functions for the Vector API.A basic vector APIAny basic Vector API should have the following methods: A method to create a vector: Vector *vector_create() creates a Vector and returns a pointer to it, or the NULL pointer in case of failure. A method to free a vector: void vector_free(Vector *vector) frees the specified vector. A method to add an item at the end of a vector: int vector_add(Vector *vector, void *item) attempts to add the given item at the end of the vector, doubling the size of the underlying array if necessary. Returns 0 for success and -1 for failure. A method to insert an item at an arbitrary position: int vector_insert(Vector *vector, void *item, int index) attempts to insert the given item at a specified index in the vector, doubling the size of the underlying array if necessary. Returns 0 for success and -1 for failure. A method to delete an item at an arbitrary position: int vector_delete(Vector *vector, int index) attempts to delete the item at the specified index in the vector, halving the size of the underlying array if necessary. Returns 0 for success and -1 for failure.In the remainder of this section we will implement each of these methods in turn.vector_create()We start by allocating memory for a vector and return NULL if the allocation fails. Then we initialize the number of elements to 0 and the capacity to the initial capacity. We must also allocate memory for the underlying array vector-&amp;gt;data. If this is not possible, we free the vector pointer and return NULL. If everything went fine, the function returns a pointer to the brand new vector.Vector *vector_create(){ Vector *vector = (Vector *)malloc(sizeof(Vector)); if (!vector) return NULL; vector-&amp;gt;count = 0; vector-&amp;gt;capacity = VECTOR_INIT_CAPACITY; vector-&amp;gt;data = (void *)malloc(vector-&amp;gt;capacity * sizeof(void *)); if (!vector-&amp;gt;data) { vector_free(vector); return NULL; } return vector;}vector_free()If the pointer to Vector is not NULL, we attempt to deallocate its data, then the vector itself.void vector_free(Vector *vector){ if (vector) { if (vector-&amp;gt;data) free(vector-&amp;gt;data); free(vector); }}_vector_resize()Yes, _vector_resize() is not listed above. The reason for this is that this method is not part of the public API, but it is required for methods that may need to resize the underlying array: vector_add(), vector_insert() and vector_delete(). The client of the Vector API does not even need to know that this function exists. In order to keep it private to the implementation file of the vector (the .c file), we will be declaring it static.The function starts out by attempting to reallocate the vector’s underlying array data with the new capacity. Note: We use a new void ** pointer for this reallocation. This is important, because realloc() is not guaranteed to return a pointer to the memory location occupied by the array to be resized.static int _vector_resize(Vector *vector, size_t capacity){ void **data = realloc(vector-&amp;gt;data, capacity * sizeof(void *)); vector-&amp;gt;capacity = capacity; if (!data) return -1; if (data != vector-&amp;gt;data) vector-&amp;gt;data = data; data = NULL; return 0;}vector_add()Adding an item at the end of a vector can fail if the vector or its data is NULL, or if the resizing is unsuccessful. Resizing the underlying array is performed if there is no free slot in the vector to add the new item.int vector_add(Vector *vector, void *item){ if (!vector || !vector-&amp;gt;data) return -1; if (vector-&amp;gt;count == vector-&amp;gt;capacity) { if (_vector_resize(vector, 2 * vector-&amp;gt;capacity) == -1) return -1; } vector-&amp;gt;data[vector-&amp;gt;count++] = item; return 0;}vector_insert()Inserting an item at an arbitrary position in a vector can fail if the vector or its data is NULL, if the index is incorrect, or if the resizing is unsuccessful. As for vector_add(), resizing is performed if there is no free slot for the new item. In addition, every item in the vector after the position designated by index must be shifted by one position to the right. A special case is identified where insertion takes place at the end of the vector, in which case vector_add() is used directly. As we’ve seen above, vector_add() may also fail, so a check for its return code is equally performed.int vector_insert(Vector *vector, void *item, int index){ if (!vector || !vector-&amp;gt;data) return -1; if (index &amp;lt; 0 || index &amp;gt; vector-&amp;gt;count) return -1; if (index == vector-&amp;gt;count) { if (vector_add(vector, item) == -1) return -1; } else { if (vector-&amp;gt;count == vector-&amp;gt;capacity) { if (_vector_resize(vector, 2 * vector-&amp;gt;capacity) == -1) return -1; } for (int i = vector-&amp;gt;count; i &amp;gt; index; i--) vector-&amp;gt;data[i] = vector-&amp;gt;data[i-1]; vector-&amp;gt;data[index] = item; vector-&amp;gt;count++; } return 0;}vector_delete()Deleting an item at an arbitrary position in a vector can fail if the vector or its data is NULL, if the index is incorrect, or if the resizing is unsuccessful. Resizing the underlying array to half its capacity is performed if the vector is one quarter full after deletion. Every item in the vector after the position designated by index must be shifted by one position to the left.int vector_delete(Vector *vector, int index){ if (!vector || !vector-&amp;gt;data) return -1; if (index &amp;lt; 0 || index &amp;gt;= vector-&amp;gt;count) return -1; vector-&amp;gt;count--; for (int i = index; i &amp;lt; vector-&amp;gt;count; i++) vector-&amp;gt;data[i] = vector-&amp;gt;data[i+1]; if (vector-&amp;gt;count == vector-&amp;gt;capacity / 4 &amp;amp;&amp;amp; vector-&amp;gt;capacity &amp;gt; VECTOR_INIT_CAPACITY) { if (_vector_resize(vector, vector-&amp;gt;capacity / 2) == -1) return -1; } return 0;}An improved Vector APIFor all practical purposes, there is a high chance that the basic API we have just seen above is not sufficient. As the need arises, we may add several useful functions to our Vector API, such as: A method to check whether the vector contains a given item: bool vector_contains(Vector* vector, void* item) determines whether the vector contains the specified item. Returns true if the item exists, false otherwise. A method to determine the index of a given item in the vector: int vector_index(Vector* vector, void* item) determines the index of the specified item in the vector, or -1 if no such item exists. Note: In both cases that we do not actually examine the value of the item, since at this point we cannot even know what kind of items we are dealing with. We simply compare void pointers, which enables us to determine whether the given item exists in the vector’s data array.vector_contains()If the vector is not NULL, we iterate its data array and compare its every item against the specified one.bool vector_contains(Vector* vector, void* item){ if (!vector) return false; for (unsigned int i = 0; i &amp;lt; vector-&amp;gt;size; i++) if (vector-&amp;gt;data[i] == item) return true; return false;}vector_index()If the vector is not NULL, we iterate its data array until we find the specified item or until we hit the end of the array.int vector_index(Vector* vector, void* item){ if (!vector) return -1; for (unsigned int i = 0; i &amp;lt; vector-&amp;gt;size; i++) { if (vector-&amp;gt;data[i] == item) return (int) i; } return -1;}Examples of vectorsHere we will see how two clients may use the Vector API that we have just examined: one client creates a vector of integers, and the other one creates a vector of user-defined data structures.Example #1: A vector of integersSuppose we need a vector to handle integers. First, values 2, 4 and 6 are added at the end of the vector using vector_add(). The vector is [ 2 4 6 ]. Second, the values 1, 3 and 5 are inserted in between using vector_insert(), such that the vector becomes [ 1 2 3 4 5 6 ]. Finally, the last three values are deleted from the vector using vector_delete(). The vector is now [ 1 2 3 ]. The following program details these steps:#include &quot;vector.h&quot;#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;void vector_int_print(Vector *vector);int main(void){ int i; Vector *vector = vector_create(); if (!vector) { fprintf(stderr, &quot;Cannot allocate vector.\\n&quot;); exit(EXIT_FAILURE); } int even[3] = {2, 4, 6}; for (i = 0; i &amp;lt; 3; i++) vector_add(vector, &amp;amp;even[i]); vector_int_print(vector); /* [ 2 4 6 ] */ int odd[3] = {1, 3, 5}; vector_insert(vector, &amp;amp;odd[0], 0); vector_insert(vector, &amp;amp;odd[1], 2); vector_insert(vector, &amp;amp;odd[2], 4); vector_int_print(vector); /* [ 1 2 3 4 5 6 ] */ for (i = 5; i &amp;gt; 2; i--) vector_delete(vector, i); vector_int_print(vector); /* [ 1 2 3 ] */ vector_free(vector); return EXIT_SUCCESS;}void vector_int_print(Vector *vector){ printf(&quot;[ &quot;); for (size_t i = 0; i &amp;lt; vector-&amp;gt;count; i++) printf(&quot;%d &quot;, *((int *) vector-&amp;gt;data[i])); printf(&quot;]\\n&quot;);} Note: Checks for return codes from vector_add(), vector_insert() and vector_delete() should be performed, but have been omitted here for the sake of brevity.Example #2: A vector of user-defined data structuresSuppose we now need a vector to handle a user-defined data structure representing 2D points. We first add the points with coordinates (1, 10) and (3, 30) to the vector using vector_add(). We then insert the point (2, 20) in between using vector_insert(). The following program details these steps:#include &quot;vector.h&quot;#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;void vector_point_print(Vector *vector);typedef struct { int x; int y;} Point;int main(void){ Vector *vector = vector_create(); if (!vector) { fprintf(stderr, &quot;Cannot allocate vector.\\n&quot;); exit(EXIT_FAILURE); } Point p1 = {.x = 1, .y = 10}; Point p2 = {.x = 2, .y = 20}; Point p3 = {.x = 3, .y = 30}; vector_add(vector, &amp;amp;p1); vector_add(vector, &amp;amp;p3); vector_insert(vector, &amp;amp;p2, 1); vector_point_print(vector); /* [ (1, 10) (2, 20) (3, 30) ] */ vector_free(vector); return EXIT_SUCCESS;}void vector_point_print(Vector *vector){ printf(&quot;[ &quot;); for (size_t i = 0; i &amp;lt; vector-&amp;gt;count; i++) { Point *point = (Point *) vector-&amp;gt;data[i]; printf(&quot;(%d, %d) &quot;, point-&amp;gt;x, point-&amp;gt;y); } printf(&quot;]\\n&quot;);} Note: Checks for return codes from vector_add() and vector_insert() should be performed, but have been omitted here for the sake of brevity.Testing the implementationThis Vector implementation has been extensively tested using the cmocka testing framework. The tests are provided in the file vector-test.c.Install cmocka first. Then, to build the tests, run:gcc -Wall vector-test.c vector.c -g -o vector-test -lcmockaTo execute the tests, run:./test-vectorTo execute the tests using valgrind in order to detect memory leaks, run:valgrind --leak-check=full ./test-vectorThere should be no memory leaks :-)AvailabilityThe full Vector implementation along with the tests is available on GitHub." }, { "title": "(Anonymous) unions in C", "url": "/posts/anonymous-unions-in-c/", "categories": "C/C++, data types", "tags": "c/c++, union", "date": "2017-12-17 00:00:00 +0100", "snippet": "The first time I had to explain to students why a C union may sometimes come in handy, I came up with this example. As my students had only been exposed to C for about 15 hours, I needed to refrain from talking about standard use cases involving low-level operations where unions are very useful.The problemSuppose we have 2D segments defined by their endpoints, like this:typedef struct { double x; double y;} Point2D;typedef struct { Point2D start; Point2D end;} Segment;Now, suppose we are required to write a function that will project a given segment on the horizontal (X) axis, and another one that will project the segment on the vertical (Y) axis. In most cases, the projection of a segment on either of the axes is another segment.For example, in the figure at the right we have a segment with endpoints (1, 1) and (2, 2). (It will be referred to as “the red segment” later on.) Its projections on the X and Y axes will be: The segment with endpoints (1, 0) and (2, 0) on the horizontal axis (in pink); The segment with endpoints (0, 1) and (0, 2) on the vertical axis (in purple).However, there are two special edge cases: If the segment is vertical (its x coordinates for both endpoints are the same), then its projection on the horizontal (X) axis is a point. If the segment is horizontal (its y coordinates for both endpoints are the same), then its projection on the vertical (Y) axis is a point.For example, in the figure at the right we have a segment with endpoints (1, 2) and (2, 2). (This segment will be referred to as “the blue segment” later on.) Its projection on the horizontal axis is another segment, but its projection on the vertical axis is the point with coordinates (0, 2).Therefore, the result of either projection operation in terms of the data structures defined in the code snippet above can be either a Segment or a Point2D. And, as it so happens, one cannot have a function return different result types in a strongly typed language such as C.The solution: unionsEnter unions. They allow you to store different data types in the same memory space, but not at the same time. Like a struct, a union has members, but only one of them can store information at any given time. Why is this interesting, you ask? Here’s why: a union has the size of its largest member. This is very important when aiming to reduce the memory footprint of an application.Here is a first take for a union that stores the result of a segment projection operation:typedef union { Segment segment; Point2D point;} _Projection;Using the _Projection union above, when we project the red segment on the X and Y axes, we store the resulting segment in the segment member of the union. Conversely, when we project the blue segment on the X and Y axes, we store the resulting point in the point member of the union.That’s great, but how do we know in which member of the union our valuable information is being stored? We need some sort of hint to figure out if a given _Projection variable contains a segment or a point. This hint commonly goes by the name of flag and requires a structure of its own to live in. We cannot simply add the flag to the _Projection union directly since this would mean that such a union can only store one of three possible values: a segment, a point or a flag. For this reason we wrap the whole _Projection union into a struct, as follows:typedef struct { _Projection proj; bool is_segment;} Projection;(Don’t forget to #include &amp;lt;stdbool.h&amp;gt; for the bool type.)So how does this thing work? We could write something like the following:Projection p;p.is_segment = false;p.proj.point.x = 0;p.proj.point.y = 0;Even better: anonymous unionsI think you will agree that the access to proj is both tiring and ugly. We can avoid it if we nest the union directly inside the struct, without giving it a name. This is called an anonymous union. The catch is that anonymous unions are only available starting with C11. So let’s rewrite the data structure:typedef struct { union { Point2D point; Segment segment; }; bool is_segment;} Projection;It is now much easier to access, say, the point member:Projection p;p.is_segment = false;p.point.x = 0;p.point.y = 0;Practical usageGreat, so how do we use this? Let’s look at one of the two projection functions, for instance the one that projects a given segment on the vertical (Y) axis. We could write it as follows:/* * Projects &#39;segment&#39; on the vertical (Y) axis and returns the projection * result: a Point2D if &#39;segment&#39; is horizontal, or another Segment otherwise. */Projection vertical_projection(Segment segment){ Projection result; if (segment.start.y == segment.end.y) { result.is_segment = false; result.point.x = 0; result.point.y = segment.start.y; } else { result.is_segment = true; result.segment.start.x = result.segment.end.x = 0; result.segment.start.y = segment.start.y; result.segment.end.y = segment.end.y; } return result;}Testing the solutionLet’s test the vertical_projection() function on the red and blue segments above.The first thing to do is to define two general functions that will test whether a Projection respectively contains the specified Segment or Point2D. These functions will involve assertions, so we will need to #include &amp;lt;assert.h&amp;gt;. If an assertion fails, the program execution is aborted./* Checks whether the Projection contains the specified Point2D. */void assert_projection_is_point(Projection result, Point2D point){ assert(!result.is_segment &amp;amp;&amp;amp; result.point.x == point.x &amp;amp;&amp;amp; result.point.y == point.y);}/* Checks whether the Projection contains the specified Segment. */void assert_projection_is_segment(Projection result, Segment segment){ assert(result.is_segment &amp;amp;&amp;amp; result.segment.start.x == segment.start.x &amp;amp;&amp;amp; result.segment.start.y == segment.start.y &amp;amp;&amp;amp; result.segment.end.x == segment.end.x &amp;amp;&amp;amp; result.segment.end.y == segment.end.y);}These two general functions may now be used to test the specific examples we’ve seen above.The red segment must have the segment with endpoints (0, 1) and (0, 2) as its projection on the vertical axis (in purple in the figure):Segment red_segment = {{1, 1}, {2, 2}};Segment red_v_proj = {{0, 1}, {0, 2}};assert_is_segment(vertical_projection(red_segment), red_v_proj);The blue segment must have the point with coordinates (0, 2) as its projection on the vertical axis:Segment blue_segment = {{1, 2}, {2, 2}};Point2D blue_v_proj = {0, 2};assert_is_point(vertical_projection(blue_segment), blue_v_proj);Notes These examples do not use pointers as it was beyond the scope of the class. No student fell asleep during the class but they were all eerily quiet. I think they might find nested structures disturbing. The full implementation is available on GitHub." }, { "title": "Summing a column with awk", "url": "/posts/summing-a-column-with-awk/", "categories": "Linux, command line", "tags": "linux, awk", "date": "2016-04-28 01:00:00 +0200", "snippet": "Suppose you want to sum values on the nth column in a file. Here is how to do this using awk:awk &#39;{ sum += $&amp;lt;COL&amp;gt; } END { print sum }&#39; &amp;lt;FILE&amp;gt;Replace &amp;lt;COL&amp;gt; with the index of the column (the first one has index 1 and the last column can be referred to as NF). Replace &amp;lt;FILE&amp;gt; with the file name.Your file might look something like this: 1 2 3 4 5 6 7 8 910 11 12Here is the output for this file:$ awk &#39;{ sum += $1 } END { print sum }&#39; data.txt 22$ awk &#39;{ sum += $2 } END { print sum }&#39; data.txt 26$ awk &#39;{ sum += $3 } END { print sum }&#39; data.txt 30$ awk &#39;{ sum += $NF } END { print sum }&#39; data.txt30" }, { "title": "Function timeout in Python using the multiprocessing module", "url": "/posts/function-timeout-in-python-multiprocessing/", "categories": "Python, timeout", "tags": "python, multiprocessing", "date": "2016-02-08 00:00:00 +0100", "snippet": "The problemSometimes you may want to impose a timeout on a Python function. Why would you want to do such a thing? Let’s say you’re computing something but you know there are some hopeless scenarios where the computation just takes too long, and you’d be OK to just skip them and go on with the rest of the workflow.For an illustration, the figure below shows several tasks. Those that take longer than the specified timeout should be aborted (orange) and the remaining tasks that take a reasonable amount of time should be executed normally (green).There are several ways in which setting a timeout on a function may be achieved such that the execution continues past the timed-out method. We will be examining two solutions here: in the previous post we have used the signal module; in this post we will be using the multiprocessing module.Solution using the multiprocessing moduleJust like in the previous post, suppose we have a method that can be very time-consuming:import timedef do_stuff(n): time.sleep(n) print(&#39;slept for {}s&#39;.format(n))For the purpose of this example, we want to let this function do_stuff() run until it either completes or hits the 5-second mark, whichever event comes first. Actually, in the previous post, we let it run just below 6 seconds, because the argument to signal.alarm() is necessarily an integer. If that argument was 5, do_stuff() would not have been allowed to run for 5 seconds. Apart from the shortcomings of the signal-based solution, the multiprocessing module also solves this nagging issue; we can now use a non-integer timeout, for example 5.01 seconds.Although multiprocessing is the package that comes to mind when attempting to parallelize processes, its basic role is to simply spawn processes, as its name implies. (Processes spawned with multiprocessing may, but do not have to, be parallel.) We can set a timeout on the processes that are spawned, which is exactly what we are looking for here.The script below runs indefinitely. At each passage through the infinite loop, it randomly selects a duration between 1 and 10 seconds. It then spawns a new multiprocessing.Process that executes the time-consuming do_stuff() function for the random duration. If do_stuff() doesn’t finish in 5 seconds (actually, 5.01 seconds), the process terminates:import multiprocessing as mpimport randomimport timedef do_stuff(n): time.sleep(n) print(&#39;slept for {}s&#39;.format(n))def main(): max_duration = 5 while True: duration = random.choice([x for x in range(1, 11)]) print(&#39;duration = {}: &#39;.format(duration), end=&#39;&#39;, flush=True) process = mp.Process(target=do_stuff, args=(duration,)) process.start() process.join(timeout=max_duration + 0.01) if process.is_alive(): process.terminate() process.join() print(&#39;took too long&#39;)if __name__ == &#39;__main__&#39;: main()A multiprocessing.Process is spawned at line 18 with do_stuff() as its target and the random duration as argument for do_stuff(). Next, we start the process at line 19, and then we “join” it (meaning we wait for it to finish) at line 20, but with a twist: it is here that we actually specify the timeout. In other words, we wait for it to finish for the specified timeout. In lines 22-25 we check whether the process actually finished, in which case is_alive() returns false. If it is still running, we terminate the process and display a message on STDOUT.Here is the output of this script:duration = 7: took too longduration = 9: took too longduration = 2: slept for 2sduration = 5: slept for 5sduration = 2: slept for 2sduration = 6: took too longduration = 5: slept for 5sduration = 3: slept for 3sduration = 7: ^CNotes Simply spawning processes with the multiprocessing module does not mean we have parallelism. In order to do this we’d need to add tasks to a multiprocessing.Pool. This article or this one show examples of pools. Care must be taken when using terminate() to stop a process. Here is what the Python documentation has to say about it: Warning: If this method is used when the associated process is using a pipe or queue then the pipe or queue is liable to become corrupted and may become unusable by other process [sic]. Similarly, if the process has acquired a lock or semaphore etc. then terminating it is liable to cause other processes to deadlock. ConclusionIn this post we’ve seen another solution for setting a timeout on a function in Python, this time using the multiprocessing module. It is easy to implement and does not suffer from any of the drawbacks of the signal-based solution described in the previous post.Further reading multiprocessing (Python documentation) Parallel processing in Python (Frank Hofmann on stackabuse) multiprocessing – Manage processes like threads (Doug Hellmann on Python Module of the Week)" }, { "title": "Function timeout in Python using the signal module", "url": "/posts/function-timeout-in-python-signal/", "categories": "Python, timeout", "tags": "python, signal", "date": "2016-02-05 00:00:00 +0100", "snippet": "The problemSometimes you may want to impose a timeout on a Python function. Why would you want to do such a thing? Let’s say you’re computing something but you know there are some hopeless scenarios where the computation just takes too long, and you’d be OK to just skip them and go on with the rest of the workflow.For an illustration, the figure below shows several tasks. Those that take longer than the specified timeout should be aborted (orange) and the remaining tasks that take a reasonable amount of time should be executed normally (green).There are several ways in which setting a timeout on a function may be achieved such that the execution continues past the timed-out method. We will be examining two solutions here: in this post we will be using signal module; in the next post we will be using the multiprocessing module.Solution using the signal moduleWhat are signals?Signals are a form of inter-process communication that only applies to POSIX-compliant operating systems. Note that Microsoft Windows is not POSIX-compliant, so this solution cannot be used when running Python on Windows.Signals can be regarded as software interrupts sent from the kernel to a process in order to inform it that a special event took place. The process receiving the signal can choose to handle it in a specific way (if the program was written with this intention, that is). Otherwise, signals are handled in a default manner specified by the default signal handlers. For example, when you press Ctrl + C in your Linux terminal to stop a running program, you are in fact sending it the SIGINT signal. The default handler for SIGINT is to stop process execution.Check out this article for more information on handling UNIX signals in Python.Using signals to set a timeoutSuppose we have a method do_stuff() that can sometimes be very time-consuming. We’ll be keeping this very simple:import timedef do_stuff(n): time.sleep(n)Let’s say we only want to run do_stuff() to completion if it finishes in less than 6 seconds. With the signal module, this can be achieved if we set a timer (an “alarm”) for 6 seconds just before calling do_stuff(). If the timer runs out before the function completes, SIGALRM is sent to the process. We will therefore be using signal.alarm(6) to set a timer for 6 seconds before calling do_stuff(). Note that the argument to signal.alarm() must be an integer. Let’s check what happens:import signalimport timedef do_stuff(n): time.sleep(n) print(&#39;slept for {}s&#39;.format(n))def main(): signal.alarm(6) do_stuff(2) do_stuff(5) do_stuff(6)if __name__ == &#39;__main__&#39;: main()Here is the output:$ python timeout_signal.py slept for 2sAlarm clock$ echo $?142What happened? Well, the timer was set to 6 seconds and it finally ran out, one second before the second call to do_stuff() would have normally finished. The process exits with code 142 (SIGALRM). Let us change the main() function to reset the alarm after each call to do_stuff():def main(): signal.alarm(6) do_stuff(2) signal.alarm(0) signal.alarm(6) do_stuff(5) signal.alarm(0) signal.alarm(6) do_stuff(6) signal.alarm(0)Note that signal.alarm(delay) arms a timer for delay seconds. This means that if do_stuff() takes exactly delay seconds to complete, SIGALRM gets transmitted nonetheless.We now obtain:slept for 2sslept for 5sAlarm clockNext, we will define a handler for SIGALRM. A handler is a function that “handles a signal” in the specific way we instruct it to behave. User-defined handlers are used to override the default signal handlers. For example, suppose you want your program to ask the user to confirm her desire to quit the program when she presses Ctrl + C in the terminal. In this case you’d need a SIGINT handler that only exits upon confirmation. Note that signal handlers must respect a fixed prototype. To quote from the Python documentation: The handler is called with two arguments: the signal number and the current stack frame (…).Even if a a signal handler does not use these two arguments, they must be present in the handler’s prototype (and no other arguments may be passed). Here is our simple handler; it just throws a TimeoutError:def handle_timeout(sig, frame): raise TimeoutError(&#39;took too long&#39;)This handler only makes sense if it is registered for SIGALRM. Registering handle_timeout() for SIGALRM should be added to the main() function of the script above. Here is how to do it:signal.signal(signal.SIGALRM, handle_timeout)By re-running our script, we can see that it now stops with a TimeoutError:slept for 2sslept for 5sTraceback (most recent call last): File &quot;timeout_signal.py&quot;, line 31, in &amp;lt;module&amp;gt; main() File &quot;timeout_signal.py&quot;, line 26, in main do_stuff(7) File &quot;timeout_signal.py&quot;, line 10, in do_stuff time.sleep(n) File &quot;timeout_signal.py&quot;, line 6, in handle_timeout raise TimeoutError(&#39;took too long&#39;)TimeoutError: took too longThis is great, we have an exception now – and exceptions are something we can deal with in Python.Making execution continue past the timeoutNext, let’s handle the TimeoutError. We will change our script such that it loops indefinitely and at each iteration through the loop it attempts to do_stuff() for a random number of seconds between 1 and 10. If do_stuff() is called with 6 seconds or more, then SIGALRM is sent and handled by raising a TimeoutError. We catch that TimeoutError and continue execution until hitting Ctrl + C. As an added bonus, we also include a handler for SIGINT (Ctrl + C).import sysimport randomimport signalimport timedef handle_sigint(sig, frame): print(&#39;SIGINT received, terminating.&#39;) sys.exit()def handle_timeout(sig, frame): raise TimeoutError(&#39;took too long&#39;)def do_stuff(n): time.sleep(n)def main(): signal.signal(signal.SIGINT, handle_sigint) signal.signal(signal.SIGALRM, handle_timeout) max_duration = 5 while True: try: duration = random.choice([x for x in range(1, 11)]) print(&#39;duration = {}: &#39;.format(duration), end=&#39;&#39;, flush=True) signal.alarm(max_duration + 1) do_stuff(duration) signal.alarm(0) except TimeoutError as exc: print(&#39;{}: {}&#39;.format(exc.__class__.__name__, exc)) else: print(&#39;slept for {}s&#39;.format(duration))if __name__ == &#39;__main__&#39;: main()So how does the execution continue past the first timeout? As we’ve seen above, we installed a handler for SIGALRM (lines 12-13 and 22) that raises a TimeoutError. Exception handling is performed in the main() function inside an infinite loop (lines 26-36). If do_stuff() succeeds, the script displays a message informing the user for how long the function ran (lines 35-36). If the TimeoutError is caught, it is simply displayed and the script continues.Here is how the output might look like:duration = 3: slept for 3sduration = 1: slept for 1sduration = 10: TimeoutError: took too longduration = 7: TimeoutError: took too longduration = 5: slept for 5sduration = 9: TimeoutError: took too longduration = 2: slept for 2sduration = 5: slept for 5sduration = 1: slept for 1sduration = 6: TimeoutError: took too longduration = 2: slept for 2sduration = 10: ^CSIGINT received, terminating.DrawbacksWell, it works but there are two problems with this solution: As mentioned in the introduction to signals, this mechanism is only present on UNIX-like systems. If the script needs to run in a classic Windows environment, the signal module is not suitable. A SIGALRM can arrive at any time; however, its handler may only be ran between atomic instructions. By definition, atomic instructions cannot be interrupted. So if the timer runs out during such an operation, even though SIGALRM is sent, it won’t be handled until that long computation you’ve been trying to abort finally completes. Typically, when using external libraries implemented in pure C for performing long computations, the handling of SIGALRM may be delayed.ConclusionIn this post we’ve seen a simple solution involving UNIX signals that may be used in some situations to set a timeout on a Python function. However, this solution is less than ideal for two reasons: the operating system must be POSIX-compliant and it can only work between atomic operations. In the next post we will examine a better solution using the multiprocessing module.Further reading Signals (Wikipedia) signal (Python documentation) Handling UNIX signals in Python (Frank Hofmann on stackabuse)" }, { "title": "How to split files in Linux from the command line", "url": "/posts/how-to-split-files-in-linux-from-the-command-line/", "categories": "Linux, command line", "tags": "linux, split", "date": "2009-11-25 00:00:00 +0100", "snippet": "[I originally published this post on Blogspot.]It can be useful to split large files, or even smaller files and ensure all the resulting volumes have the same size. For this we will be using split.Splitting filesWe can split a larger file into smaller ones like this:split -b 100M fileThe previous command splits file into several 100 Mb volumes, called by default xaa, xab, xac and so on. These default names may be prefixed by a pattern:split -b 100k file pattern_The previous command splits file into several 100 Kb volumes, called pattern_aa, pattern_ab, pattern_ac and so on. If we want digits instead of letters, we can use the -d flag:split -db 1G file pattern.The previous command splits file into several 1 Gb volumes, called pattern.00, pattern.01, pattern.02 and so on.Joining filesTo join the volumes, we can cat the sorted file names and redirect them to an output file:cat `echo pattern.* | sort` &amp;gt; new_fileBoth the original file and new_file have the same MD5 sum; they are identical." }, { "title": "How to manually modify a .deb package", "url": "/posts/how-to-manually-modify-a-deb-package/", "categories": "Linux, command line", "tags": "linux, deb", "date": "2008-06-26 01:00:00 +0200", "snippet": "[I originally published this post on Blogspot.]Every now and then you might need to tweak a .deb package for testing purposes. For instance you just want to change the behavior of the postinst script. Here are the steps to extract, modify and repackage the .deb package.Step 1. Unpack with ar:ar x package.debYou obtain three files: debian-binary: ASCII text control.tar.gz: gzip compressed data. This archive contains the files that actually get installed on the system (in /etc, /opt or /usr for example). data.tar.gz: gzip compressed data. This archive usually contains: control: ASCII text md5sums: contains the MD5 sums for the files in data.tar.gz postinst: a script that is executed after installing the package postrm: a script that is executed after removing the package preinst: a script that is executed before installing the package prerm: a script that is executed before removing the package Some packages do not have pre/post install/removal scripts.Step 2. Unpack the archive(s) depending on which files you need to modify. To unpack both archives, run:mkdir extras-control extras-datatar -C extras-control/ -zxf control.tar.gztar -C extras-data/ -zxf data.tar.gzStep 3. Modify the file(s) you need to change. If you modified files that are included in data.tar.gz, you need to update their MD5 sum in extras-control/md5sums.Step 4. Repack control.tar.gz and/or data.tar.gz and remove the temporary directories:cd extras-controltar cfz control.tar.gz *mv control.tar.gz ..cd ../extras-datatar cfz data.tar.gz *mv data.tar.gz ..cd ..rm -fr extras*Step 5. Repackage the .deb package:ar r new_package.deb debian-binary control.tar.gz data.tar.gz Note: I haven’t had the chance to test this recently, but it would appear that the order of files in the last step (step 5) is important." }, { "title": "Converting .m4a and .wma to .mp3", "url": "/posts/converting-between-various-audio-formats/", "categories": "Linux, audio", "tags": "linux, mp3, m4a, wma", "date": "2008-02-25 00:00:00 +0100", "snippet": "[This is a synthesis of two posts I wrote on Blogspot in 2008.]I’ve compiled here two recipes for converting to .mp3.Convert .m4a to .mp3Install lame and faad, then cd into a directory containing .m4a files that you wish to convert to .mp3 and run:for x in *.m4a ; do faad -o - &quot;$x&quot; | lame -V 0 - &quot;${x%m4a}mp3&quot; ; doneConvert .wma to .mp3Install lame and mplayer, then cd into a directory containing .wma files that you wish to convert to .mp3 and run:for x in *.wma ; do mplayer -vo null -vc dummy -af resample=44100 -ao pcm:waveheader &quot;$x&quot; ; lame -m s audiodump.wav -o &quot;${x%wma}mp3&quot; ; rm audiodump.wav ; done" } ]
